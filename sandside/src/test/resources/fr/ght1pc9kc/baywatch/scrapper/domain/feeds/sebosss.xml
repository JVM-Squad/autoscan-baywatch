<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
                                           xmlns:content="http://purl.org/rss/1.0/modules/content/"
                                           xmlns:wfw="http://wellformedweb.org/CommentAPI/"
                                           xmlns:dc="http://purl.org/dc/elements/1.1/"
                                           xmlns:atom="http://www.w3.org/2005/Atom"
                                           xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
                                           xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
>

    <channel>
        <title>Le blog de Seboss666</title>
        <atom:link href="https://blog.seboss666.info/feed/" rel="self" type="application/rss+xml" />
        <link>https://blog.seboss666.info</link>
        <description>Les divagations d&#039;un pseudo-geek curieux</description>
        <lastBuildDate>Wed, 18 Nov 2020 17:00:47 +0000</lastBuildDate>
        <language>fr-FR</language>
        <sy:updatePeriod>hourly</sy:updatePeriod>
        <sy:updateFrequency>1</sy:updateFrequency>
        <generator>https://wordpress.org/?v=4.9.15</generator>
        <item>
            <title>Passage à la fibre : c&#8217;est mon tour !</title>
            <link>https://blog.seboss666.info/2020/11/passage-a-la-fibre-cest-mon-tour/</link>
            <comments>https://blog.seboss666.info/2020/11/passage-a-la-fibre-cest-mon-tour/#comments</comments>
            <pubDate>Wed, 18 Nov 2020 17:00:47 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Projets]]></category>
            <category><![CDATA[alternatives]]></category>
            <category><![CDATA[choix]]></category>
            <category><![CDATA[concurrence]]></category>
            <category><![CDATA[connexion]]></category>
            <category><![CDATA[débit]]></category>
            <category><![CDATA[fibre]]></category>
            <category><![CDATA[limitations]]></category>
            <category><![CDATA[Livebox]]></category>
            <category><![CDATA[manque]]></category>
            <category><![CDATA[orange]]></category>
            <category><![CDATA[performances]]></category>
            <category><![CDATA[réseau]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6416</guid>
            <description><![CDATA[Et dieu sait que je rageais d&#8217;être le dernier de la famille à ne pas être équipé. Mon propriétaire à fini par faire les travaux [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Et dieu sait que je rageais d&rsquo;être le dernier de la famille à ne pas être équipé. Mon propriétaire à fini par faire les travaux au mois de mai, au sortir du confinement, et début Août j&rsquo;ai vérifié quelles étaient mes options. Je suis rentré fin septembre et n&rsquo;ai pas traîné pas besoin de faire plusieurs épisodes je pense, enfin on verra bien.</p>
<p style="text-align: justify;"><span id="more-6416"></span></p>
<p style="text-align: justify;">Dans l&rsquo;Oise, et plus spécifiquement le réseau public de l&rsquo;Oise, la situation était particulière jusqu&rsquo;à début 2019, à savoir que seul SFR était disponible comme opérateur, contrairement à chez ma mère qui certes n&rsquo;avaient pas les options les plus sexy du monde, mais avait quand même du choix. Ici donc, Orange a débarqué par la suite, mais de manière un peu particulière, à savoir que tout le réseau public de l&rsquo;Oise n&rsquo;était pas « exploitable », ils n&rsquo;activaient les connexions que par plaques, correspondant peu ou prou aux secteurs dans lesquels les abonnements ADSL disparaissaient au profit d&rsquo;SFR. Une situation bien sale, mais si on a suivi les grandes étapes du plan THD on n&rsquo;est plus à un cadeau près pour que les utilisateurs souffrent et que les opérateurs s&rsquo;en mettent plein les poches (enfin surtout leurs actionnaires).</p>
<p style="text-align: justify;">Bref, étant dans un immeuble je devais de toute façon attendre que le boîtier de répartition soit posé à l&rsquo;intérieur avant de pouvoir prétendre à la fibre. Autant dire que quand j&rsquo;ai vu que c&rsquo;était possible d&rsquo;avoir autre chose qu&rsquo;SFR comme opérateur, j&rsquo;ai bondi sur l&rsquo;occasion. Oui car j&rsquo;ai été abonné mobile SFR pendant pas mal d&rsquo;années, j&rsquo;ai vu le service client se dégrader à la vitesse de la lumière et quand on voit ce qu&rsquo;ils font avec les abonnements, autant vous dire que c&rsquo;est pas demain la veille qu&rsquo;on me verra de nouveau approcher l&rsquo;opérateur au carré rouge.</p>
<h3 style="text-align: justify;">Le choix de l&rsquo;abonnement, la bonne surprise de l&rsquo;installation</h3>
<p style="text-align: justify;">Avec l&rsquo;univers Orange restant la seule possibilité, j&rsquo;ai fait le tour des forfaits et finalement, par rapport à ma situation actuelle, je me suis finalement tourné vers <a href="https://shop.sosh.fr/box-internet" target="_blank" rel="noopener">le forfait Sosh fibre</a>. Non seulement le tarif est plus intéressant que les autres offres Orange, mais en plus au mois de Septembre j&rsquo;ai bénéficié d&rsquo;une réduction pour ne payer que 15€ par mois pendant un an, encore plus intéressant ! Et l&rsquo;offre est sans engagement, ce qui sera pratique lorsque je vais déménager, ce qui est prévu dans moins d&rsquo;un an. Par contre, la contrepartie, c&rsquo;est que je n&rsquo;ai « que » 300Mbps de bande passante symétrique, largement suffisant pour moi tout seul, ce qui est de toute façon infiniment plus agréable qu&rsquo;un « maigre » 16/1 en ADSL.</p>
<p style="text-align: justify;">J&rsquo;ai pris rendez-vous quelques jours avant mon retour à l&rsquo;appartement, après six mois à soutenir ma mère qui s&rsquo;était littéralement démonté le dos (quand votre première vertèbre lombaire est décalée de plus d&rsquo;un centimètre, et qu&rsquo;en plus un morceau est cassé, oui, démonté c&rsquo;est le bon terme). Je chois de prendre rendez-vous le 25 septembre, d&rsquo;abord l&rsquo;après-midi, et après discussion avec Pierre-marie, je reprogramme tout de suite pour faire le matin, car avec les surprises du matin parfois les rendez-vous de l&rsquo;après-midi ne sont pas honorés. La box est partie moins de deux jours plus tard, et je reçois un texto pour me confirmer le rendez-vous du matin. Et un autre deux heures plus tard pour me confirmer le rendez-vous de l&rsquo;après-midi. C&rsquo;est des rigolos chez Orange dis donc, c&rsquo;est rassurant. La box est livrée dans un point relai à deux pas de la maison, puisqu&rsquo;il s&rsquo;agit du salon de coiffure chez qui mon ventirad avait déjà été livré, <a href="https://blog.seboss666.info/2019/09/on-change-le-pc-de-jeu-part-4/" target="_blank" rel="noopener">remember</a>.</p>
<p style="text-align: justify;">Mais quand je parle de bonne surprise de l&rsquo;installation, c&rsquo;est pour deux raisons. La première, c&rsquo;est que je reçois en fait un appel dès le lundi matin d&rsquo;une petite dame qui m&rsquo;explique, après m&rsquo;avoir demandé de confirmer que j&rsquo;avais bien pris rendez-vous pour le vendredi, que les techniciens peuvent en fait passer dans le quart d&rsquo;heure qui suit l&rsquo;appel, soit avec quatre jours d&rsquo;avance. Je n&rsquo;ai même pas encore pu récupérer la box car le salon de coiffure est fermé le lundi ! Pas grave me dit-on, les techniciens posent la prise, et on branche la boiboite dès que c&rsquo;est possible. Je stress juste un peu parce que je n&rsquo;ai même pas l&rsquo;ONT qui est livré avec la box, et que le technicien est sensé le configurer directement.</p>
<p style="text-align: justify;">La deuxième bonne nouvelle donc, c&rsquo;est l&rsquo;installation elle-même, contrairement aux prestataires qui ont posé le répartiteur et ont fait ça comme de salopards de première, avec le fil qui court sans alignement avec les goulottes existantes, les deux poseurs sont consciencieux, longent systématiquement tous les murs et encoignures, passent l&rsquo;étage par l&rsquo;endroit que voulait proposer le propriétaire, rentrent chez moi pile sous les poutres, et suivent là encore toute la longueur, passent comme il faut dans le salon, et suit la jonction mur/plafond pour aller poser la prise dans le coin de la pièce où la prise téléphonique existe déjà, ce qui était ce que je voulais. Le câble est blanc, les murs sont blanc, tout est presque invisible. Et tout est fait à la colle chaude, donc facile à refaire si besoin (le propriétaire voulait que ça soit fait en goulotte, ce que ne proposent pas les techniciens &#8212; allez voir les prix en magasin vous comprendrez). Le jour et la nuit par rapport à la pose du répartiteur donc.</p>
<h3 style="text-align: justify;">La Livebox 4, mais quelle horreur</h3>
<p style="text-align: justify;">Le lendemain donc, je fonce à la première heure récupérer la box (et prendre rendez-vous pour refaire la perruque du nounours au passage, parce qu&rsquo;il était temps). L&rsquo;installation est particulièrement simple, on branche l&rsquo;Ethernet, on branche le transfo, on allume, on attend, et quelques minutes de mise à jour plus tard, la box est démarrée et on reçoit un SMS validant l&rsquo;activation. Même pour un technicien qui s&rsquo;attend à devoir aller toucher du paramètre, un tel démarrage rapide et simple est appréciable.</p>
<p><a href="https://blog.seboss666.info/wp-content/uploads/2020/11/livebox_4_front.jpg" rel="lightbox[6416]"><img class="aligncenter size-medium wp-image-6449" src="https://blog.seboss666.info/wp-content/uploads/2020/11/livebox_4_front-300x153.jpg" alt="" width="300" height="153" srcset="https://blog.seboss666.info/wp-content/uploads/2020/11/livebox_4_front-300x153.jpg 300w, https://blog.seboss666.info/wp-content/uploads/2020/11/livebox_4_front-768x392.jpg 768w, https://blog.seboss666.info/wp-content/uploads/2020/11/livebox_4_front-1024x522.jpg 1024w, https://blog.seboss666.info/wp-content/uploads/2020/11/livebox_4_front.jpg 1400w" sizes="(max-width: 300px) 100vw, 300px" /></a></p>
<p style="text-align: justify;">Comme je n&rsquo;ai pas spécialement envie de tout péter direct, je tente simplement de relier le switch du bureau, qui raccorde mon PC de jeu et mon PC de boulot (eh oui, rentré chez moi, mais toujours télétravail), et je fais un test rapide. Ben ça tient ses promesses déjà en termes de débit et de latence, donc c&rsquo;est un bon point, et ça rend le boulot plus agréable (je vous jure que les 1Mbps montants de l&rsquo;ADSL, quand vous faites un <code>terraform plan</code> sur plus d&rsquo;une trentaine de ressources, ça tue la connexion). Je passe donc la semaine en mode hybride, la « grosse bertha » et le laptop pro sur la fibre, le reste encore sur la Freebox.</p>
<p style="text-align: justify;">Il faudra patienter encore un jour ou deux pour que je commence à faire l&rsquo;inventaire de ce que j&rsquo;ai à paramétrer pour retrouver un réseau dans le même état que précédemment. Je n&rsquo;ai pas grand chose et rien n&rsquo;est très isolé, mais je cherche à avoir le moins de choses possibles à reconfigurer. Choix est donc fait de changer l&rsquo;adresse IP de la Livebox pour coller à celle de la Freebox, à savoir 192.168.1.254. Eh oui, ça permet d&rsquo;éviter de reconfigurer tous les serveurs physiques et virtuels pour refaire les passerelles par défaut. Je me tourne vers le DHCP pour aligner également la plage d&rsquo;IP pour les clients (PC fixe, PC portables, smartphones&#8230;). Mauvaise nouvelle que je savais déjà, on ne peut pas contrôler les serveurs DNS qui sont utilisés par le réseau, il impose la box comme relai local, avec toutes les conneries de filtrage imposé qui vont avec. Encore une fois dans l&rsquo;urgence, je laisse comme ça.</p>
<p><a href="https://blog.seboss666.info/wp-content/uploads/2020/11/network_livebox_dhcp.png" rel="lightbox[6416]"><img class="size-medium wp-image-6450 aligncenter" src="https://blog.seboss666.info/wp-content/uploads/2020/11/network_livebox_dhcp-300x248.png" alt="" width="300" height="248" srcset="https://blog.seboss666.info/wp-content/uploads/2020/11/network_livebox_dhcp-300x248.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/11/network_livebox_dhcp-768x634.png 768w, https://blog.seboss666.info/wp-content/uploads/2020/11/network_livebox_dhcp.png 875w" sizes="(max-width: 300px) 100vw, 300px" /></a></p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2020/11/network_freebox_dhcp.png" rel="lightbox[6416]"><img class="aligncenter size-medium wp-image-6451" src="https://blog.seboss666.info/wp-content/uploads/2020/11/network_freebox_dhcp-300x281.png" alt="" width="300" height="281" srcset="https://blog.seboss666.info/wp-content/uploads/2020/11/network_freebox_dhcp-300x281.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/11/network_freebox_dhcp.png 644w" sizes="(max-width: 300px) 100vw, 300px" /></a>Au début avec la Freebox je m&rsquo;étais « amusé » à utiliser les baux DHCP statiques pour les VMs, ce qui est une énorme connerie, et je m&rsquo;en étais passé lors de la refonte du serveur pour le passage à k3s. Mais il restait une machine dissidente, à savoir le Raspberry Pi. Je suis passé vite fait dans les réglages de <a href="https://blog.seboss666.info/2016/12/openelec-libreelec-osmc-mais-cest-devenu-le-bordel-ma-pauvre-dame/" target="_blank" rel="noopener">LibreELEC</a> pour passer en manual, il propose par défaut de garder les paramètres déjà affectés par le DHCP, ce qui fait que via la télécommande on a rien à faire et c&rsquo;est tant mieux. Et oui, comme les partages NFS sont filtrés par IP, il n&rsquo;est évidemment pas question que le Pi change d&rsquo;IP tous les quatre matins.</p>
<p style="text-align: justify;">Quand j&rsquo;attaque les grosses opérations le weekend, c&rsquo;est le bordel. J&rsquo;essaie de pré-paramétrer les redirections de port dans l&rsquo;onglet NAT/PAT, mais pas moyen de rentrer manuellement les adresses IP pour les règles, la sélection ne se fait que via une liste déroulante qui est remplie avec les appareils que la box détecte. C&rsquo;est chiant au possible, ça veut donc dire que je dois tout reparamétrer APRÈS avoir tout débranché/rebranché. Et quand je finis par le faire, c&rsquo;est rigolo, parce que y&rsquo;a pas la moitié des noms des machines qui sont bons, tous les serveurs Linux ne sont pas identifiés mais ont un nom « PC-00 » à la place, pareil pour le laptop. Autre fait navrant, on peut indiquer le type d&rsquo;appareil s&rsquo;il n&rsquo;est pas correctement détecté, mais une fois encore, la liste déroulante ne propose pas d&rsquo;option serveur. Au mieux on a quand même une icône NAS qu&rsquo;il a fallu que j&rsquo;ajoute moi-même parce que le NAS, si son nom s&rsquo;affiche correctement, n&rsquo;est pas identifié en tant que stockage. Au final mes règles sont bien remises en place, mais quel manque d&rsquo;ergonomie en 2020&#8230; J&rsquo;ai fini par une bascule DNS et quelques minutes plus tard, j&rsquo;ai pu valider que tout refonctionnait comme avant. Mais beaucoup plus vite donc. Mais avec des limitations à faire sauter.</p>
<p style="text-align: justify;">Ah oui, alors la Freebox ne fait pas beaucoup mieux en la matière, mais on a bien une option activer/désactiver le pare-feu IPv6 (oui j&rsquo;ai bien de l&rsquo;IPv6, ouf), on ne l&rsquo;a même pas sur la Livebox. Au moins j&rsquo;ai pu valider que je ne pouvais pas joindre une machine en IPv6 de l&rsquo;extérieur, ce qui est ce que j&rsquo;avais avec Free. Donc toujours pas de possibilité de faire de l&rsquo;hébergement IPv6 chez soi, quand je vous dis que c&rsquo;est une honte en 2020&#8230; Au moins le NAT fonctionne comme attendu, pas comme chez ma mère où je n&rsquo;ai pas pu répliquer la même configuration de bastion que chez moi.</p>
<h3 style="text-align: justify;">On contourne rapidos les premières limitations</h3>
<p style="text-align: justify;">Le problème immédiat que je veux résoudre est le serveur DHCP. Comme c&rsquo;est impossible de faire quoi que ce soit avec, la solution est de le remplacer par un service adapté. Je n&rsquo;ai jamais eu à déployer de service DHCP, c&rsquo;est comme n&rsquo;importe quel service réseau et je pourrais tout à faire le mettre sur une des VMs. J&rsquo;ai pu voir des alternatives indiquant que sur certains NAS il existe un service DHCP qu&rsquo;on peut activer. Et oui, c&rsquo;est le cas sur Asustor, bon par contre le chemin pour s&rsquo;y rendre n&rsquo;est pas trivial. Il n’apparaît pas comme n&rsquo;importe quel service du NAS, il faut se rendre dans les paramètres, section réseau, sélectionner l&rsquo;interface réseau Ethernet, et cliquer enfin sur le bouton serveur DHCP. La page en question dispose là aussi d&rsquo;un bouton pour gérer les plages d&rsquo;IP à fournir aux clients, via une popup dédiée. C&rsquo;est donc compliqué à trouver, et pas ergonomique. Mais le fait est que j&rsquo;ai pu remettre la plage IP que j&rsquo;avais déjà, avec les résolveurs DNS que je veux (FDN pour l&rsquo;instant, bientôt la remise en service d&rsquo;un cache local ?), et indiquer la Livebox comme passerelle. On désactive le DHCP de la box, on active celui du NAS, et on teste avec le smartphone et le laptop (j&rsquo;ai eu plus de mal avec le PC de jeu, Windows mon amour).</p>
<p><a href="https://blog.seboss666.info/wp-content/uploads/2020/11/asustor_adm_dhcp.png" rel="lightbox[6416]"><img class="aligncenter size-medium wp-image-6452" src="https://blog.seboss666.info/wp-content/uploads/2020/11/asustor_adm_dhcp-300x87.png" alt="" width="300" height="87" srcset="https://blog.seboss666.info/wp-content/uploads/2020/11/asustor_adm_dhcp-300x87.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/11/asustor_adm_dhcp-768x223.png 768w, https://blog.seboss666.info/wp-content/uploads/2020/11/asustor_adm_dhcp-1024x298.png 1024w, https://blog.seboss666.info/wp-content/uploads/2020/11/asustor_adm_dhcp.png 1581w" sizes="(max-width: 300px) 100vw, 300px" /></a></p>
<p style="text-align: justify;">L&rsquo;autre problème que j&rsquo;ai est d&rsquo;ordre physique. Comme chez ma mère, la box et l&rsquo;ONT sont alimentés par des satanés transfos qui prennent une place monstre. J&rsquo;ai donc profité de cette migration pour réinstaller l&rsquo;onduleur, réorganiser les multiprises, pour avoir quelque chose de propre, qui couvre les appareils importants, en gérant la place monstrueuse que ça prend.j&rsquo;ai une multiprise de 6 points et pratiquement 4 sont bloqués à cause des deux blocs, je vous laisse imaginer la frustration.</p>
<h3 style="text-align: justify;">La Livebox doit mourir</h3>
<p style="text-align: justify;">C&rsquo;est pas pour demain, les politiques des opérateurs sont toujours d&rsquo;essayer de vous enfermer dans leur univers via cette box. Tout n&rsquo;est pas perdu, c&rsquo;est encore possible pour l&rsquo;instant, ça demande par contre du matériel dédié. Mais j&rsquo;aimerai bien retrouver certaines fonctionnalités qui sont utiles sur Freebox, comme la visualisation du trafic par port Ethernet de la box (non, ça n&rsquo;existe pas sur Livebox), une vraie gestion DHCP/DNS intégrée (pareil), un vrai pare-feu IPv4/IPv6 (bon là on est presque à égalité), et une observabilité par API pour retrouver mes infos dans Prometheus, <a href="https://github.com/saphoooo/freebox_exporter/" target="_blank" rel="noopener">qu&rsquo;on peut faire</a> avec la Freebox (jamais publié mon PoC, et tout est désormais détruit&#8230;). J&rsquo;envisage de tester le <a href="https://www.ui.com/edgemax/edgerouter-x/" target="_blank" rel="noopener">EdgeRouter X d&rsquo;Ubiquity</a>, certes ce n&rsquo;est pas OpenSource mais ça semble, pour une cinquantaine/soixantaine d&rsquo;euros, supporter tout ce dont j&rsquo;ai besoin, et même plus.</p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/11/passage-a-la-fibre-cest-mon-tour/feed/</wfw:commentRss>
            <slash:comments>2</slash:comments>
        </item>
        <item>
            <title>Huawei P20 Lite, deux ans après</title>
            <link>https://blog.seboss666.info/2020/11/huawei-p20-lite-deux-ans-apres/</link>
            <comments>https://blog.seboss666.info/2020/11/huawei-p20-lite-deux-ans-apres/#respond</comments>
            <pubDate>Mon, 16 Nov 2020 17:00:48 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Humeur]]></category>
            <category><![CDATA[Mobilité]]></category>
            <category><![CDATA[android]]></category>
            <category><![CDATA[autonomie]]></category>
            <category><![CDATA[conflit]]></category>
            <category><![CDATA[évolutions]]></category>
            <category><![CDATA[Huawei]]></category>
            <category><![CDATA[obsolescence]]></category>
            <category><![CDATA[sécurité]]></category>
            <category><![CDATA[smartphone]]></category>
            <category><![CDATA[solidité]]></category>
            <category><![CDATA[stabilité]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6237</guid>
            <description><![CDATA[Eh ouais, ça fait déjà plus de deux ans que j&#8217;ai acheté mon téléphone, vous savez celui qui collait pas du tout à ma checklist [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Eh ouais, ça fait déjà plus de deux ans que j&rsquo;ai acheté mon téléphone, vous savez celui qui collait pas du tout à ma checklist de prérequis. On avait déjà fait un premier point d&rsquo;étape <a href="https://blog.seboss666.info/2019/04/mon-p20-lite-presque-un-an-apres/" target="_blank" rel="noopener">au bout d&rsquo;un an</a>, comme il est toujours debout, il serait temps d&rsquo;en reparler après sa deuxième bougie <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p style="text-align: justify;"><span id="more-6237"></span></p>
<h3 style="text-align: justify;">Physiquement, RAS</h3>
<p style="text-align: justify;">Je suis quelqu&rsquo;un de pas spécialement stressé sur mon téléphone, mais avec sa protection en verre et sa coque silicone, autant dire que je fais un peu attention quand même. Le silicone c&rsquo;est la vie, pour les smartphones évidemment, sinon en dehors du latex je préfère le naturel <img src="https://s.w.org/images/core/emoji/11/72x72/1f600.png" alt="😀" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Plus sérieusement, le silicone transparent a quand même bien jauni, c&rsquo;est un phénomène que j&rsquo;avais déjà constaté avec la coque en silicone transparent qui était fournie avec le OnePlus X. Et la protection en verre a pris un peu cher, mais d&rsquo;une part c&rsquo;est dans un coin, de l&rsquo;autre, c&rsquo;est tellement léger que même écran allumé on le voit pas. Faut dire qu&rsquo;il est bien plaqué sur l&rsquo;écran, à part les coins supérieurs mais ça ne l&rsquo;a jamais dérangé. Si vraiment j&rsquo;étais capricieux, j&rsquo;en ai une toute neuve dans le tiroir de mon bureau <img src="https://s.w.org/images/core/emoji/11/72x72/1f600.png" alt="😀" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p style="text-align: justify;">Le truc qui était déjà chiant et qui l&rsquo;est toujours sur ce smartphone, c&rsquo;est la grille du haut parleur qu&rsquo;il faut régulièrement nettoyer des poussières et des inévitables crasses qui se collent dedans. Idem pour l&rsquo;unique trou du microphone encore plus minuscule. J&rsquo;ai pris l&rsquo;habitude de le faire avec une petite épingle de couture que m&rsquo;a laissé ma chère maman. C&rsquo;est le problème quand le téléphone passe son temps dans la poche d&rsquo;un jean&#8230;</p>
<h3 style="text-align: justify;">L&rsquo;autonomie : c&rsquo;est toujours bon, mais on sent du moins bien</h3>
<p style="text-align: justify;">C&rsquo;est une des bonnes surprises de ce téléphone deux ans après. L&rsquo;autonomie est encore très bonne malgré le fait que j&rsquo;ai multiplié les recharges, avec l&rsquo;utilisation intensive dans les transports et chez moi où ça capte pas super, je le recharge en temps normal tous les jours. Évidemment pendant le premier confinement, sans l&rsquo;utilisation dans les transports, je m&rsquo;en sers moins et il capte bien mieux, ce qui fait que je le recharge tous les deux jours.</p>
<div id="attachment_6338" style="width: 227px" class="wp-caption aligncenter"><a href="https://blog.seboss666.info/wp-content/uploads/2020/05/lapin_duracell.jpg" rel="lightbox[6237]"><img class="size-medium wp-image-6338" src="https://blog.seboss666.info/wp-content/uploads/2020/05/lapin_duracell-217x300.jpg" alt="" width="217" height="300" srcset="https://blog.seboss666.info/wp-content/uploads/2020/05/lapin_duracell-217x300.jpg 217w, https://blog.seboss666.info/wp-content/uploads/2020/05/lapin_duracell.jpg 300w" sizes="(max-width: 217px) 100vw, 217px" /></a><p class="wp-caption-text">Paie ta ref de vieux</p></div>
<p style="text-align: justify;">Il ne faudra malgré tout pas que je traîne pour acheter une batterie de rechange pour prévoir un futur démontage (chose que je n&rsquo;ai pas faite pour le OnePlus X en même temps, donc je sais pas si ça va durer). Ou que je change de téléphone si un futur modèle qui colle à mes critères, qui ont peu bougé, se présente. Mais j&rsquo;ai un doute.</p>
<h3 style="text-align: justify;">Logiciel : bugs, mises à jour&#8230;</h3>
<p style="text-align: justify;">La situation de Twidere est toujours compliquée, le logiciel est principalement en mode maintenance, c&rsquo;est donc au petit bonheur la chance par rapport aux évolutions de Twitter. Mais je n&rsquo;ai pas réinstallé l&rsquo;application officielle parce que franchement, vu le peu que j&rsquo;utilise Twitter sur le téléphone en fait, il fait suffisamment bien le boulot (j&rsquo;ai par contre récemment découvert qu&rsquo;il manquait les sondages, alors que ça fonctionnait avant, et c&rsquo;est la foire avec les messages privés. La gestion de l&rsquo;API est infernale, d&rsquo;ici à ce que je doive encore jouer avec les clés d&rsquo;API&#8230;).</p>
<p style="text-align: justify;">Là où j&rsquo;ai fait évoluer la configuration, c&rsquo;est sur la gestion d&rsquo;applications. F-Droid toujours au poste évidemment, mais Yalp n&rsquo;était plus maintenu et posait de plus en plus de problèmes avec certaines applications empaquetées en mode « instant app » qui génère plusieurs fichiers apk, que Yalp ne savait pas gérer. Celui-ci avait été forké pour donner <a href="https://f-droid.org/fr/packages/com.aurora.adroid/" target="_blank" rel="noopener">Aurora Store</a>, qui fonctionne pas mal et règle cette histoire de « split apk », mais qui peut encore avoir sporadiquement quelques difficultés avec la connexion anonyme. Avec les problèmes sur la gestion en arrière-plan des applications qui n&rsquo;a pas vraiment changé, je continue de déclencher manuellement les mises à jour. Quelques minutes le weekend pour vérifier ce qui traîne, la plupart du temps ça suffit largement quand on a déjà une bonne hygiène numérique. Aurora n&rsquo;est lui-même pas exempt de bug, j&rsquo;ai du rétrograder de version il y a quelques temps à cause d&rsquo;un problème avec la création de l&rsquo;API pour accéder au store Google, pas très pratique. Et F-Droid n&rsquo;est pas toujours très réactif dans les builds des nouvelles versions. C&rsquo;est rentré dans l&rsquo;ordre depuis.</p>
<p style="text-align: justify;">Un dernier bug méchant qui faisait chier et pour lequel j’attendais Fenix avec impatience, c&rsquo;est Firefox Mobile. Avec le bordel sur la mise en veille des applications, une fois sur deux, quand je veux rouvrir la fenêtre j&rsquo;avais un souci avec les cookies qui ne sont plus lus ni stockés, ce qui plante toutes les applis, FreshRSS en tête puisque c&rsquo;est son principal usage. J&rsquo;étais alors obligé de le fermer complètement et le relancer, ce qui prend de nombreuses secondes parce que la lourdeur était de mise. J&rsquo;ai eu l&rsquo;occasion de passer sur Firefox Beta maintenant que c&rsquo;est le <a href="https://blog.seboss666.info/2020/08/firefox-pour-android-le-renouveau-imparfait-une-fois-de-plus/" target="_blank" rel="noopener">Firefox Nouveau</a>, il n&rsquo;est à mon sens toujours pas au niveau fonctionnel de son précédesseur, mais au moins sa stabilité est bien meilleure qu&rsquo;avant. On va dire que je me répète, mais le niveau de finition, y&rsquo;a un truc qui m&rsquo;échappe forcément, comme la feignantise sur le support de WebRTC mis en lumière salement avec <a href="https://github.com/jitsi/jitsi-meet/issues/4758" target="_blank" rel="noopener">les problèmes de Jitsi Meet</a>. C&rsquo;est vrai que <a href="https://www.lesnumeriques.com/vpn/firefox-private-network-le-vpn-a-la-sauce-mozilla-pour-android-et-windows-10-n147389.html" target="_blank" rel="noopener">vendre un VPN hosté aux US</a> c&rsquo;est plus important que de respecter les standards ouverts pour lesquels on s&rsquo;est battu y&rsquo;a quelques années&#8230;</p>
<p style="text-align: justify;">Sinon dans l&rsquo;ensemble c&rsquo;est toujours très stable, je n&rsquo;ai pratiquement jamais de « force close » des applis (ça doit arriver une fois tous les deux mois, voire encore plus rarement). La fluidité est toujours globalement bonne, il arrive tout de même sur le switch d&rsquo;applications un peu lourdes que ça lag un poil. Reste les applis par défaut de Huawei qui sont vraiment pénibles parce qu&rsquo;on peut pas les désactiver et qu&rsquo;elles ne perdent pas une occasion de revenir sur le devant de la scène, je pense notamment à l&rsquo;application Musique qui empêche VLC de capturer les évènements casque correctement.</p>
<h3 style="text-align: justify;">Version d&rsquo;Android, sécurité : à la limite de la mention assez bien</h3>
<p style="text-align: justify;">Sur les mises à jour de l&rsquo;OS, le téléphone est toujours en version 9 d&rsquo;Android, je pense pas avoir droit un jour à la version 10, et la situation de Huawei avec l&rsquo;accès aux technologies US ne s&rsquo;arrange pas, d&rsquo;autant plus avec Donald Duck en tête de ligne (ouais il est pas beaucoup plus intelligent qu&rsquo;un canard ce mec alors&#8230;). L&rsquo;arrivée compliquée de Biden en remplacement ne devrait toutefois pas changer les choses dans un avenir proche. Les mises à jour de sécurité et les corrections de bug mineurs sont toujours au programme mais souvent avec de gros décalages (genre deux à trois mois), et là on sent que Huawei ne va pas faire beaucoup d&rsquo;efforts supplémentaires, quand il cherche à convaincre que <a href="https://www.frandroid.com/marques/huawei/694554_test-huawei-p40-avis-smartphone-haut-de-gamme" target="_blank" rel="noopener">son P40 et ses ersatz de services Google</a> sont suffisants dans un monde drogué au logiciel ricain; spoiler alert, c&rsquo;est raté. Et encore, il faudra que je fasse une vérification parce qu&rsquo;il parait que les constructeurs mentent parfois sur la réalité du niveau de patch appliqué. Ouais parce que vous comprenez, non contents de forcer les gens à acheter un nouveau téléphone en prétendant que c&rsquo;est le seul moyen possible pour avoir la dernière version d&rsquo;Android, en plus ils pipeautent sur le suivi de sécurité essentiel qu&rsquo;on leur demande de faire. Et Huawei ne serait ni le meilleur élève ni le pire en la matière.</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2020/11/screenshot_p20_updates_november.jpg" rel="lightbox[6237]"><img class="aligncenter size-medium wp-image-6445" src="https://blog.seboss666.info/wp-content/uploads/2020/11/screenshot_p20_updates_november-142x300.jpg" alt="" width="142" height="300" srcset="https://blog.seboss666.info/wp-content/uploads/2020/11/screenshot_p20_updates_november-142x300.jpg 142w, https://blog.seboss666.info/wp-content/uploads/2020/11/screenshot_p20_updates_november-768x1621.jpg 768w, https://blog.seboss666.info/wp-content/uploads/2020/11/screenshot_p20_updates_november-485x1024.jpg 485w, https://blog.seboss666.info/wp-content/uploads/2020/11/screenshot_p20_updates_november.jpg 1080w" sizes="(max-width: 142px) 100vw, 142px" /></a>Mise à jour déployée début novembre. Donc deux mois de retard sur les patches de sécu Android. On va se consoler en se disant que ça fait plus de deux ans et que c&rsquo;est déjà bien d&rsquo;en avoir encore ? Alors qu&rsquo;un Microsoft continue encore de fournir des mises à jour pour Windows 8.1 sorti&#8230; en 2013, et qui sera maintenu jusqu&rsquo;en 2023. Voilà&#8230;</p>
<p style="text-align: justify;">Par contre c&rsquo;est pénible, à l&rsquo;instar d&rsquo;un Windows 10 qu&rsquo;il est toujours compliqué de mater, il vous reboot dans la nuit pour appliquer les mises à jour sans vous demander la permission. Heureusement que le réveil est fonctionnel à ce moment-là parce que ce n&rsquo;est plus le cas de la connexion mobile qui attend le code de déverrouillage de la carte SIM. Imaginez un téléphone d&rsquo;astreinte qui vous fait ça en pleine nuit&#8230;</p>
<h3 style="text-align: justify;">Alors, le remplaçant ?</h3>
<p style="text-align: justify;">Forcément je me pose la question. Pas pour tout de suite, la situation mondiale actuelle ne donne pas envie de dépenser inutilement de l&rsquo;argent. Malgré la fin actée des mises à jour de l&rsquo;OS, le reste va continuer de fonctionner, et finalement, les vraies failles systèmes exploitables demandent d&rsquo;abord d&rsquo;attaquer les couches supérieures, qui elles sont encore mises à jour (Google Play Services, applications). Le matériel étant encore en très bon état, pas la peine de nourrir la montagne de déchets électroniques. Cette remarque est d&rsquo;ailleurs à garder, on pourrait s&rsquo;orienter vers un smartphone d&rsquo;occasion, de moins d&rsquo;un an idéalement, qui aura un support complet de LineageOS ? On pourrait rêver, mais qui sait&#8230;</p>
<p style="text-align: justify;">Le fait est qu&rsquo;il faudra bien à un moment donné se pencher sérieusement sur le problème. Entre la base même de l&rsquo;OS qui est toujours plus attachée à son initiateur, Google, les constructeurs qui continuent de faire des modèles jetables sous prétexte officiel d&rsquo;économies de fabrication (mais pas de prix d&rsquo;achat hein, faut pas déconner), sans parler de leurs saloperies de surcouches et applications maison qui sont là juste pour vous espionner un peu plus (Xiaomi étant le dernier en date à s&rsquo;être fait prendre <a href="https://www.frandroid.com/marques/xiaomi/706441_quand-la-collecte-de-donnees-fait-tache-sur-les-smartphones-xiaomi-abusive-non-anonymisee-et-mal-chiffree" target="_blank" rel="noopener">la main dans le pot de confiture</a>), ça devient compliqué de trouver une plateforme qui ne soit pas conçue dans un but malveillant, et surtout sur laquelle on ne VEUT pas que vous ayez le contrôle.</p>
<p style="text-align: justify;">Alors que c&rsquo;est toujours plus vital à mesure que le monde ouvert d&rsquo;Internet menace toujours plus de s&rsquo;écrouler face à ces requins&#8230;</p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/11/huawei-p20-lite-deux-ans-apres/feed/</wfw:commentRss>
            <slash:comments>0</slash:comments>
        </item>
        <item>
            <title>Où en est le blog ?</title>
            <link>https://blog.seboss666.info/2020/11/ou-en-est-le-blog/</link>
            <comments>https://blog.seboss666.info/2020/11/ou-en-est-le-blog/#respond</comments>
            <pubDate>Mon, 02 Nov 2020 17:00:43 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Editos]]></category>
            <category><![CDATA[chantier]]></category>
            <category><![CDATA[déménagement]]></category>
            <category><![CDATA[fibre]]></category>
            <category><![CDATA[motivation]]></category>
            <category><![CDATA[plugins]]></category>
            <category><![CDATA[ravalement]]></category>
            <category><![CDATA[temps]]></category>
            <category><![CDATA[wordpress]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6439</guid>
            <description><![CDATA[Eh ouais, ça fait un bout de temps que j&#8217;ai pas fait d&#8217;articles, et les 38 brouillons avancent tellement au ralenti que je ne sais [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Eh ouais, ça fait un bout de temps que j&rsquo;ai pas fait d&rsquo;articles, et les 38 brouillons avancent tellement au ralenti que je ne sais pas trop lequel sortira en premier, certains dépendant d&rsquo;abord de la sortie d&rsquo;autres, etc&#8230; Mais y&rsquo;a pas mal de facteurs et j&rsquo;aimerai faire un point rapide pour vous dire ce qui viendra dans un futur plus ou moins proche.</p>
<p style="text-align: justify;"><span id="more-6439"></span></p>
<h3 style="text-align: justify;">Le temps</h3>
<p style="text-align: justify;">Eh oui, c&rsquo;est le plus global des problèmes, ce blog est tenu sur le temps « libre », et du temps libre, je n&rsquo;en alloue pratiquement pas ces derniers temps. Je continue de faire la stricte maintenance nécessaire, qui ne sera bientôt plus suffisante, mais j&rsquo;y reviendrai, et c&rsquo;est à peu près tout.</p>
<p style="text-align: justify;">Le fait est que les journées sont chargées, et même si le transport a été pratiquement éliminé de mon temps de mon temps alloué au travail, ce qui va donc perdurer avec l&rsquo;annonce de ce deuxième confinement, je passe beaucoup de temps sur ma veille techno orientée boulot. Et en ce moment je suis aussi dans une phase de rattrapage de jeux que j&rsquo;ai laissé de côté, je viens de terminer Assassin&rsquo;s Creed Origins après 82h de jeu, et il y en a d&rsquo;autres qui suivront certainement avec pour certains le même genre de temps passé (99h sur Horizon Zero Dawn, vraiment faîtes ce jeu c&rsquo;est un bonheur).</p>
<div id="attachment_6441" style="width: 310px" class="wp-caption aligncenter"><a href="https://blog.seboss666.info/wp-content/uploads/2020/11/assassins_creed_origins_time_spent.jpg" rel="lightbox[6439]"><img class="size-medium wp-image-6441" src="https://blog.seboss666.info/wp-content/uploads/2020/11/assassins_creed_origins_time_spent-300x225.jpg" alt="" width="300" height="225" srcset="https://blog.seboss666.info/wp-content/uploads/2020/11/assassins_creed_origins_time_spent-300x225.jpg 300w, https://blog.seboss666.info/wp-content/uploads/2020/11/assassins_creed_origins_time_spent-768x576.jpg 768w, https://blog.seboss666.info/wp-content/uploads/2020/11/assassins_creed_origins_time_spent-1024x768.jpg 1024w" sizes="(max-width: 300px) 100vw, 300px" /></a><p class="wp-caption-text">Je vous mens pas hein <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p></div>
<p style="text-align: justify;">Il n&rsquo;y a pas que le blog qui en pâtit, j&rsquo;ai deux/trois bouquins qu&rsquo;il faut que je dépile aussi. Et pour l&rsquo;instant, je vois pas trop comment ça évoluerait dans un sens ou l&rsquo;autre. Il faut dire que même en faisant des prédictions sur trois semaines, on se fait couper la chique par un gouvernement en roue libre dans un pays qui semble tourner au désastre intellectuel et économique (même si on est encore loin du Liban&#8230;), et c&rsquo;est compliqué d&rsquo;en faire abstraction.</p>
<h3 style="text-align: justify;">La refonte/upgrade du WordPress</h3>
<p style="text-align: justify;">Il n&rsquo;y a quand même pas « rien ». En effet, après avoir abandonné l&rsquo;environnement docker pour les expérimentations sur le blog (trop contraignant pour un truc qu&rsquo;on bidouille toutes les deux minutes), j&rsquo;ai remonté une copie du blog à côté de celui-ci pour m&rsquo;atteler à quelques chantiers. Je ne vais pas avoir le choix, tant que je reste sur WordPress, il faut que je passe aux branches 5.x pour la sécurité; mais non, définitivement, après 1h d&rsquo;essais, l&rsquo;éditeur Gutemberg est juste une régression monumentale qui n&rsquo;a été conçue que pour plaire à ceux qui devraient utiliser un autre moteur de site pour faire leurs publications pourries. Pour l&rsquo;instant on a encore le <a href="https://wordpress.org/plugins/classic-editor/" target="_blank" rel="noopener">Classic Editor</a>, mais il y a d&rsquo;autres problèmes qui découlent de cette mise à jour.</p>
<p style="text-align: justify;">Eh oui, j&rsquo;ai un souci soit déjà présent, soit spécifique à WP5, avec quelques extensions. On m&rsquo;a remonté déjà y&rsquo;a un moment que le plugin pour la gestion des boutons de partage sur les réseaux sociaux ne fonctionnaient plus, et c&rsquo;est vrai, la partie du code PHP qui devrait être interprétée ne fonctionne plus, et comme je passais par une extension particulièrement générique pour faire pour ça, j&rsquo;imagine que c&rsquo;est lié à une sécurité supplémentaire au niveau de WordPress. C&rsquo;est pas un mal, mais du coup je dois revoir la copie. Autre souci, celui du partage automatique sur les réseaux sociaux. J&rsquo;utilisais jusque-là Microblog Poster, mais il est définitivement abandonné et apparemment le développeur, sans retirer son travail devenu inutile, semble peu enclin à faire son travail de support ne serait-ce que pour dire que c&rsquo;est plus la peine. Pire, la page pour acheter la version entreprise est toujours en ligne, on est donc désormais tombé dans l&rsquo;arnaque la plus flagrante. Le passage à WP5 fait aussi grimper la version de WpDiscuz, et cette nouvelle version me laisse pour le moins perplexe, j&rsquo;ai l&rsquo;impression que la seule forme d&rsquo;antispam restante est cette saloperie de reCaptcha de Google, sans gêne, ce qui ne m&rsquo;arrange pas le moins du monde. J&rsquo;ai aussi eu des soucis avec certaines fonctions que j&rsquo;avais intégrées au thème et qui font planter le blog, par exemple la suppression des query strings, et le defer pour le JavaScript fait mal aussi.</p>
<p style="text-align: justify;">Aussi, ça fait maintenant longtemps que j&rsquo;ai le même thème, et je cherche à le changer pour quelque chose de plus aéré. Mais j&rsquo;aimerai toutefois pouvoir ré-inclure de manière élégante un bouton de soutien à une association, j&rsquo;ai fini par retirer celui de la Quadrature après leurs dernières pitreries. La gestion des écrans très larges est encore trop absentes, il est vrai qu&rsquo;avec un Google qui vous tanne pour que votre site soit optimisé pour mobile, c&rsquo;est un peu contre-intuitif. Mais voir 60% de son espace d&rsquo;affichage inutilisé c&rsquo;est juste une honte. Et parce que je dois l&rsquo;avouer c&rsquo;est un mode qui me plait, je réfléchis à un thème sombre. Et pour l&rsquo;instant je trouve rien qui me plait vraiment, je suis aussi noyé sous la masse des thèmes « Freemium » ce qui me gonfle parce que la frontière entre la promesse et la réalité gratuite n&rsquo;est jamais claire, et j&rsquo;y passe déjà trop peu de temps pour en plus cramer du cash dans un thème à la durée de vie pas forcément plus importante. J&rsquo;exclus pas du coup de reporter ce point du thème pour une prochaine fois et livrer les évolutions du blog sous-jacentes, on le voit ces tests d&rsquo;évolution prennent un temps non négligeable sur celui que je peux allouer au blog il va falloir donc trancher.</p>
<h3 style="text-align: justify;">Les articles, leur vie, leur mort</h3>
<p style="text-align: justify;">Avec un tel délai dans l&rsquo;écriture et le peaufinage des articles, et des expérimentations qui vont souvent avec, il y a des dégâts. Je viens de voir repasser un tweet « teaser » ou je parlais de libération de routeur. Le Netgear a été salement briqué au premier essai et je n&rsquo;ai jamais réussi à reprendre la main. L&rsquo;autre routeur a du être remis en service en urgence lors de mon séjour prolongé chez ma mère suite au décalage de plus de deux mois de son opération du dos. Télétravail c&rsquo;est bien, avec du réseau fiable c&rsquo;est mieux. Je suis rentré chez moi mais maintenant le routeur n&rsquo;est plus disponible donc ce « projet » tombe à l&rsquo;eau.</p>
<p style="text-align: justify;">J&rsquo;avais dans les cartons la mise en place du Freebox Exporter pour Prometheus, sauf que j&rsquo;ai réinstallé le serveur from scratch dans l&rsquo;urgence à l&rsquo;occasion d&rsquo;un aller-retour éclair chez moi pendant le confinement, j&rsquo;avais bien commencé l&rsquo;écriture, et j&rsquo;ai réinstallé aussi les VMs from scratch donc j&rsquo;ai rien gardé. Et comme je n&rsquo;ai plus de Freebox en place, ça tombe à l&rsquo;eau. C&rsquo;est pas la box remplaçante qui fera honneur, car je suis passé à la fibre chez Sosh, et ça je vais vous en parler dans pas super longtemps parce qu&rsquo;on est sur une prestation à peine moins honteuse <a href="https://blog.seboss666.info/2019/02/la-fibre-chez-ma-mere-chapitre-3-on-tente-de-prendre-le-controle-du-reseau/" target="_blank" rel="noopener">que chez NordNet</a>.</p>
<p style="text-align: justify;">Je vous ai parlé <a href="https://blog.seboss666.info/2020/08/de-docker-swarm-a-kubernetes-avec-k3s/" target="_blank" rel="noopener">du cluster K3s</a> et j&rsquo;ai potentiellement des trucs à vous en redire, mais pour l&rsquo;instant, je suis coincé dans son « remplissage » par la gestion des backups. En effet, ce couillon de NAS Asustor ne sait pas supporter NFSv4, donc pas de gestion via le backup natif de Longhorn, pas sans faire de sales bidouilles. J&rsquo;étudie les alternatives mais je suis aussi coincé par les ressources matérielles du serveur qui m&#8217;empêchent un peu de déployer plus de VMs. Et les bonnes options de machines sous AMD en passif se font attendre. Le brouillon d&rsquo;article que j&rsquo;avais commencé qui parle de cette évolution matérielle vient d&rsquo;ailleurs de souffler sa première bougie&#8230;</p>
<h3 style="text-align: justify;">Le déménagement de l&rsquo;infra</h3>
<p style="text-align: justify;">Ah oui y&rsquo;a ça aussi, il est vraiment plus que temps que je déménage le site, Debian 8 c&rsquo;est vraiment la fin cette fois, même en ayant <a href="https://blog.seboss666.info/2020/06/un-peu-damour-pour-le-blog-et-la-vm-en-general/" target="_blank" rel="noopener">fait ce que je pouvais</a> pour corriger certaines tares; il est surtout temps que le serveur physique qui va sur ses huit ans prenne sa retraite (il ira grossir les rangs de l&rsquo;offre SYS d&rsquo;OVH, sachez-le leurs serveurs sont déjà des retraités). Et vu les niveaux de prix et la « fraîcheur » du matériel, je pense qu&rsquo;OVH ne sera pas l&rsquo;heureux élu du prochain hébergement. Tout ça aussi va prendre du temps qu&rsquo;il faudra trouver, mais possible que je parte chez Hetzner. J&rsquo;ai déjà fait une petite vérification ça pourra induire un poil de latence supplémentaire (genre une dizaine de millisecondes), parce que ce n&rsquo;est pas en France et que nos opérateurs préféreraient qu&rsquo;on fasse pas de l&rsquo;Internet chez eux, mais bon, pour avoir du matériel récent, et de l&rsquo;AMD par dessus le marché, sans que ça coûte deux fois le prix que je paie actuellement, pas le choix.</p>
<p style="text-align: justify;">Ben oui, j&rsquo;ai beau être passé à la fibre, pour certains éléments je n&rsquo;ai aucun intérêt à héberger ça directement chez moi, parce que pouvoir réparer 24/7, ce n&rsquo;est pas une option et chez moi, même confiné c&rsquo;est impossible. Comme il y a des gens dont c&rsquo;est le métier, autant leur faire confiance <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<h3 style="text-align: justify;">Stay Tuned, comme ils disent&#8230;</h3>
<p style="text-align: justify;">Donc voilà une partie des raisons pour lesquelles il n&rsquo;y a plus trop de bruit ici en ce moment. La bête n&rsquo;est tout de même pas encore morte, et il va falloir que je me réorganise un peu pour allouer quand même un peu plus de temps à vous partager les quelques rares trucs qui m&rsquo;ont intéressé, sur lesquels j&rsquo;ai bossé, ou que je compte faire sous un angle qui ne soit pas déjà vu et revu. En étant quatre mois à la bourre derrière mes confrères, sûr que c&rsquo;est pas toujours évident&#8230;</p>
<p><a href="https://blog.seboss666.info/wp-content/uploads/2020/11/t2_thumbs_up.jpg" rel="lightbox[6439]"><img class="aligncenter size-medium wp-image-6442" src="https://blog.seboss666.info/wp-content/uploads/2020/11/t2_thumbs_up-300x128.jpg" alt="" width="300" height="128" srcset="https://blog.seboss666.info/wp-content/uploads/2020/11/t2_thumbs_up-300x128.jpg 300w, https://blog.seboss666.info/wp-content/uploads/2020/11/t2_thumbs_up.jpg 590w" sizes="(max-width: 300px) 100vw, 300px" /></a></p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/11/ou-en-est-le-blog/feed/</wfw:commentRss>
            <slash:comments>0</slash:comments>
        </item>
        <item>
            <title>Résoudre les problèmes de Microsoft Teams avec KDE sous Linux</title>
            <link>https://blog.seboss666.info/2020/09/resoudre-les-problemes-de-microsoft-teams-avec-kde-sous-linux/</link>
            <comments>https://blog.seboss666.info/2020/09/resoudre-les-problemes-de-microsoft-teams-avec-kde-sous-linux/#comments</comments>
            <pubDate>Wed, 09 Sep 2020 16:00:30 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Astuces]]></category>
            <category><![CDATA[Humeur]]></category>
            <category><![CDATA[bug]]></category>
            <category><![CDATA[KDE]]></category>
            <category><![CDATA[linux]]></category>
            <category><![CDATA[microsoft]]></category>
            <category><![CDATA[noyau]]></category>
            <category><![CDATA[opengl]]></category>
            <category><![CDATA[team]]></category>
            <category><![CDATA[vidéo]]></category>
            <category><![CDATA[xrender]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6289</guid>
            <description><![CDATA[Microsoft a mis à disposition il y a plusieurs mois déjà son client Teams pour les linuxiens. Il est très proche fonctionnellement de la version [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Microsoft a mis à disposition il y a plusieurs mois déjà son client Teams pour les linuxiens. Il est très proche fonctionnellement de la version Windows, avec aussi peu de réglages que son homologue, et son statut de preview fait qu&rsquo;il est souvent à la bourre sur les toutes dernières évolutions introduites dans le client. Il a aussi d&rsquo;autres problèmes qui dépendent de l&rsquo;environnement de bureau dans lequel vous tournez, et ça a été mon cas avec KDE.</p>
<p style="text-align: justify;"><span id="more-6289"></span></p>
<h3 style="text-align: justify;">KDE mon amour (je l&rsquo;ai déjà faite, non ?)</h3>
<p style="text-align: justify;">KDE, c&rsquo;est l&rsquo;environnement qu&rsquo;on dit sympa pour les nouveaux utilisateurs parce que proche de Windows. Alors les gens qui disent ça n&rsquo;ont soit pas vu un Windows depuis longtemps, soit jamais utilisé KDE non plus. Parce que l&rsquo;environnement qui repose sur le toolkit graphique Qt est un bordel sans nom tellement il est configurable dans tous les sens. J&rsquo;en utilise moi-même probablement qu&rsquo;un petit tiers des capacités, et ce nombre est probablement surestimé.</p>
<p style="text-align: justify;">Je l&rsquo;ai quand même sélectionné quand j&rsquo;ai basculé mon laptop pro sous Linux, <a href="https://blog.seboss666.info/2019/09/les-challenges-quand-on-vire-windows-de-son-pc-de-boulot/" target="_blank" rel="noopener">j&rsquo;en avais parlé</a>, parce que maintenant que la génération 5 avait maturé, je me suis dit que ça serait suffisamment stable et je voulais voir ce qu&rsquo;ils en avaient fait après avoir apprécié la version 4. Globalement, c&rsquo;est fluide, en fonction des thèmes c&rsquo;est visuellement proche d&rsquo;un Windows mais avec quelques spécificités parce que bon sinon ça serait pas KDE (pour ceux qui veulent vraiment mimer y&rsquo;a l&rsquo;incognito mode de Kali :D). C&rsquo;est un environnement plaisant dont j&rsquo;ai pu modifier les aspects que je voulais pour le rendre plus fluide pour mes besoins, et c&rsquo;est finalement ce qu&rsquo;on demande en priorité à son environnement de bureau.</p>
<p style="text-align: justify;">Malgré tout, sur le Latitude 5470 j&rsquo;ai quand même eu quelques galères. La consommation mémoire est déjà un peu élevée, genre 800Mo à froid, sans rien de chargé. Ensuite, en fonction des mises à jour j&rsquo;ai déjà eu des soucis avec des freezes de l&rsquo;écran de verrouillage. Comprenez que l&rsquo;image est figée à l&rsquo;écran, mais la souris bouge, et si on saisit le mot de passe au clavier, ça fonctionne, juste on ne le voit pas. Et ça, aussi bien sur le noyau d&rsquo;origine à l&rsquo;installation (4.19 LTS) que celui que j&rsquo;ai sélectionné après, le 5.4 LTS. La solution était de rebasculer sur un TTY, et de revenir sur la session graphique pour qu&rsquo;il reprenne le dessin. Bizarre autant qu&rsquo;étrange, mais c&rsquo;était limité au login screen.</p>
<p style="text-align: justify;">J&rsquo;ai quand même pris un peu de temps pour chercher un peu. Kwin, qui est le composant responsable du dessin de tout ça, et qu&rsquo;on appelle à juste titre compositeur de fenêtres, dispose lui-même, à l&rsquo;image du reste de l&rsquo;environnement, de pas mal de réglages, sur les effets, et aussi sur un point important, le mode de rendu. Chez moi, et je n&rsquo;ai aucune idée de pourquoi, le mode de rendu sélectionné était OpenGL 2, alors que le pilote et le GPU intégré supportent, au moins sous Linux, OpenGL 3.3+ depuis la génération Haswell, c&rsquo;était en 2014. Vérification faite, depuis cet été Intel a validé OpenGL 4.6 pour tout ce qui est Broadwell+, ce qui est le cas de Skylake. Et dans les options proposées, je n&rsquo;ai qu&rsquo;un OpenGL 3.1. J&rsquo;ai donc tenté le coup, c&rsquo;est plus stable effectivement, mais rien de révolutionnaire sur la consommation CPU ou RAM. Moins de bug, c&rsquo;est toujours ça.</p>
<p></p><pre class="crayon-plain-tag">$ glxinfo
(...)
OpenGL vendor string: Intel
OpenGL renderer string: Mesa Intel(R) HD Graphics 520 (SKL GT2)
OpenGL core profile version string: 4.6 (Core Profile) Mesa 20.0.7
OpenGL core profile shading language version string: 4.60
OpenGL core profile context flags: (none)
OpenGL core profile profile mask: core profile
(...)</pre><p></p>
<p style="text-align: justify;">Ça n&#8217;empêche pas de temps en temps d&rsquo;avoir un énorme message d&rsquo;erreur sur fond noir me disant qu&rsquo;il faut déverrouiller la session via la ligne de commande dans un TTY justement, ceci dit c&rsquo;est assez rare pour ne pas poser plus de problème que ça.</p>
<h3 style="text-align: justify;">Tu voulais pas nous parler de Teams ?</h3>
<p style="text-align: justify;">Alors pourquoi je m&rsquo;attarde sur tout ça ? Déjà pour dire que l&rsquo;environnement sur lequel il s&rsquo;exécute a déjà quelques soucis graphiques avérés au moins par le passé. Ensuite parce qu&rsquo;évidemment, avec une utilisation toujours plus poussée de Teams voire même une utilisation exclusive depuis quelques mois maintenant, je ne peux pas me permettre d&rsquo;avoir un outil non fonctionnel. Certains éléments ne dépendent pas de moi, comme la téléphonie, dont la procédure de migration que j&rsquo;ai pu lire me donne encore des migraines tellement elle est complexe par rapport aux tests du début qui fonctionnaient bien mais qui, selon Microsoft, posaient « des problèmes de sécurité ». Pour d&rsquo;autres c&rsquo;est lié à mon PC et lui seul, donc autant chercher à agir.</p>
<p style="text-align: justify;">En dehors d&rsquo;une consommation CPU et RAM démesurée qui est régulièrement pointée du doigt et qui ne semble pas la priorité de Microsoft (ajouter les fonds custom sur les visio et les grilles 3&#215;3 « à la Zoom », c&rsquo;est tellement plus important), le principal problème que j&rsquo;ai rencontré est pratiquement impossible à capturer et visible uniquement par mes interlocuteurs : le partage d&rsquo;écran « clignote », et on voit régulièrement des bouts de fonds d&rsquo;écran par dessus les fenêtres, ce qui est particulièrement désagréable pour eux. Au début justement je pensais que c&rsquo;était dû à l&rsquo;OpenGL 2, mais le passage à OpenGL 3.1 n&rsquo;a rien réglé. Je me suis dit que j&rsquo;étais maudit, j&rsquo;ai repensé au fait qu&rsquo;Electron, qui est le framework applicatif utilisé pour développer Teams, repose sur Chromium, qui n&rsquo;utilise pas Qt mais GTK comme toolkit. Possible, après tout Pierre-Marie qui va me faire payer une taxe à chaque fois que je le cite l&rsquo;utilise sans souci avec Cinnamon, même si lui utilise la version non-officielle, donc la version d&rsquo;Electron pourrait jouer.</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2020/09/kde_render_mode.png" rel="lightbox[6289]"><img class="aligncenter size-medium wp-image-6405" src="https://blog.seboss666.info/wp-content/uploads/2020/09/kde_render_mode-300x178.png" alt="" width="300" height="178" srcset="https://blog.seboss666.info/wp-content/uploads/2020/09/kde_render_mode-300x178.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/09/kde_render_mode-768x454.png 768w, https://blog.seboss666.info/wp-content/uploads/2020/09/kde_render_mode-1024x606.png 1024w, https://blog.seboss666.info/wp-content/uploads/2020/09/kde_render_mode.png 1232w" sizes="(max-width: 300px) 100vw, 300px" /></a>Au passage dans les recherches, je vois que la consommation CPU peut être un peu réduite en désactivant l&rsquo;accélération matérielle. Me demandez pas pourquoi mais c&rsquo;est vrai, j&rsquo;ai décoché l&rsquo;accélération matérielle, redémarré l&rsquo;application et ça va un peu mieux. Ça reste toujours Bagdad sur le Core i5 en conférence audio/vidéo, mais bon, le reste du temps, c&rsquo;est à dire au « repos » il est beaucoup plus calme. Mais rien de mieux sur le partage d&rsquo;écran qui clignote toujours. Et en continuant de chercher, je finis par retomber sur cette histoire de mode de rendu.</p>
<p style="text-align: justify;">En effet, j&rsquo;ai évoqué différentes versions d&rsquo;OpenGL, mais il existe une dernière option pour Kwin qui s&rsquo;appelle <a href="https://en.wikipedia.org/wiki/X_Rendering_Extension" target="_blank" rel="noopener">Xrender</a>. Ce mode de rendu historique remonte à 2001 et déjà à l&rsquo;époque permettait d&rsquo;exploiter les capacités d&rsquo;accélération des cartes graphiques pour s&rsquo;occuper d&rsquo;un ou plusieurs aspects de l&rsquo;environnement de bureau. Il est toujours supporté sur les installations récentes qui reposent encore sur X.org, et c&rsquo;est mon cas. Certains semblent avoir réussi à calmer les glitches du partage d&rsquo;écran avec, et comme je n&rsquo;avais aucune information sur le fait que ça pourrait faire mal au CPU et/ou à la RAM, j&rsquo;ai tenté.</p>
<p style="text-align: justify;">Eh ben devinez quoi, c&rsquo;est la solution ! Donc pour avoir Teams + KDE + x  = partage d&rsquo;écran, x = Xrender. J&rsquo;étais content, j&rsquo;allais pouvoir repartager mon écran facilement, c&rsquo;est d&rsquo;autant plus important en ces temps de télétravail continu.</p>
<h3 style="text-align: justify;">Le retour de la vengeance des bugs bizarre de KDE</h3>
<p style="text-align: justify;">Et oui, tel un <a href="https://fr.wikipedia.org/wiki/Jason_Voorhees" target="_blank" rel="noopener">Jason Voorhees</a> qu&rsquo;on croit mort et qui revient toujours, un nouveau bug encore plus étrange est venu se mettre en travers de ma route : de manière très aléatoire, même si je pensais à un lien direct avec Teams, ce n&rsquo;est plus l&rsquo;écran de verrouillage qui freeze mais le bureau, carrément ! Je peux encore basculer entre les fenêtres avec Alt+Tab, mais plus question d&rsquo;utiliser le menu KDE ou la barre des tâches. Et même certaines fenêtres finissent par un peu souffrir et freezer elles aussi. La solution trouvée sur un forum est de « tuer » plasmashell et de le relancer dans la foulée. Ce qui fonctionne, mais pour un temps plus ou moins limité avant de devoir recommencer.</p>
<p style="text-align: justify;">Retour donc dans les méandres de la recherche sur le web, pour découvrir que cette fois-ci, c&rsquo;est la combinaison Xrender + noyau 5.14 qui semble problématique, et que 4.19 permettra de retrouver sa stabilité. Au point où j&rsquo;en étais j&rsquo;ai tenté. Et au bout d&rsquo;une semaine sans freeze avec moults partages d&rsquo;écrans et sessions audio/vidéo Teams, force est de constater que le résultat est là. Le prix à payer est que les noyaux plus récents disposent d&rsquo;améliorations de performances et/ou d&rsquo;autonomie qui ne sont pas critiques non plus, surtout en ce moment où le laptop est constamment relié au secteur.</p>
<h3 style="text-align: justify;">Un possible basculement sur XFCE ?</h3>
<p style="text-align: justify;">Par rapport à ce que j&rsquo;utilise de KDE, franchement je me pose la question. la version 4.14 a amélioré son support GTK 3, qui est le toolkit sur lequel repose la majorité de mes applications en dehors de KeepassXC et VLC. Firefox, Thunderbird, LibreOffice, Sublime Text, Terminator, Teams, la liste n&rsquo;est pas complète mais vous avez l&rsquo;idée. Le problème, c&rsquo;est que pouvoir basculer dessus demande tellement de changements sur le système que je me demande comment je vais procéder, la réinstallation étant probablement le mieux.</p>
<p style="text-align: justify;">En attendant, j&rsquo;ai retrouvé une stabilité nécessaire, ce qui une fois de plus nous montre bien que non, « Linux » c&rsquo;est pas pour tout le monde, quelque soit la qualité du matériel.</p>
<hr />
<p style="text-align: justify;">PS : j&rsquo;ai écrit cet article au mois de mai, il se trouve qu&rsquo;entre temps, j&rsquo;ai découvert une conséquence malencontreuse, à savoir que docker est cassé dans ce contexte, depuis la dernière mise à jour de Docker il y a une régression qui casse le dossier /var/run quand on tente un pull. Les détails et malheureusement la solution inapplicable dans mon cas sont <a href="https://github.com/moby/moby/issues/40008" target="_blank" rel="noopener">à consulter dans cette issue</a>. Une raison de plus pour passer sur container dockerless ?</p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/09/resoudre-les-problemes-de-microsoft-teams-avec-kde-sous-linux/feed/</wfw:commentRss>
            <slash:comments>1</slash:comments>
        </item>
        <item>
            <title>Quelques astuces diverses, dix-neuvième</title>
            <link>https://blog.seboss666.info/2020/09/quelques-astuces-diverses-dix-neuvieme/</link>
            <comments>https://blog.seboss666.info/2020/09/quelques-astuces-diverses-dix-neuvieme/#comments</comments>
            <pubDate>Sun, 06 Sep 2020 10:00:44 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Astuces diverses]]></category>
            <category><![CDATA[alpine]]></category>
            <category><![CDATA[AUR]]></category>
            <category><![CDATA[docker]]></category>
            <category><![CDATA[git]]></category>
            <category><![CDATA[icônes]]></category>
            <category><![CDATA[outlook]]></category>
            <category><![CDATA[terraform]]></category>
            <category><![CDATA[thunderbird]]></category>
            <category><![CDATA[Ubuntu]]></category>
            <category><![CDATA[wifi]]></category>
            <category><![CDATA[youtube-dl]]></category>
            <category><![CDATA[zstd]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6232</guid>
            <description><![CDATA[Ça faisait un bail en plus que je n&#8217;avais plus proposé de pot pourri de bidouilles directes et variées. C&#8217;est pas faute de bricoler, faut [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Ça faisait un bail en plus que je n&rsquo;avais plus proposé de pot pourri de bidouilles directes et variées. C&rsquo;est pas faute de bricoler, faut juste trouver le temps d&rsquo;avoir des choses utiles/intéressantes à proposer <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /><span id="more-6232"></span></p>
<h3 style="text-align: justify;">Désactiver le motd pourri d&rsquo;Ubuntu Server</h3>
<p style="text-align: justify;">J&rsquo;ai appris qu&rsquo;une Ubuntu pouvait s&rsquo;amuser à aller chercher des infos à l&rsquo;extérieur, et surtout en transmettre, pour vous afficher un message de bienvenue à la connexion SSH. C&rsquo;est sale, mais fort heureusement, il y a moyen de le désactiver, il faut modifier le fichier <span style="font-family: courier new, courier, monospace;">/etc/default/motd-news</span> :</p>
<p></p><pre class="crayon-plain-tag"># Enable/disable the dynamic MOTD news service
# This is a useful way to provide dynamic, informative
# information pertinent to the users and administrators
# of the local system
ENABLED=0</pre><p></p>
<p style="text-align: justify;">On l&rsquo;aura compris, c&rsquo;est le <span style="font-family: courier new, courier, monospace;">ENABLED=0</span> qui fait le taf. (<a href="https://ma.ttias.be/what-exactly-being-sent-ubuntu-motd/" target="_blank" rel="noopener">source</a>)</p>
<h3 style="text-align: justify;">youtube-dl, youtube, erreur 403</h3>
<p style="text-align: justify;">Alors que sur certaines vidéos je n&rsquo;ai aucun problème avec youtube-dl, il arrive de temps en temps que je prenne une belle erreur 403. Non pas que la vidéo soit privée (il sait me l&rsquo;afficher), mais c’est lié à un problème avec le cache interne de youtube-dl.</p>
<p style="text-align: justify;">Pour le réinitialiser, il suffit de relancer le téléchargement avec l&rsquo;option qui va bien :</p>
<p></p><pre class="crayon-plain-tag">$ youtube-dl -f 137+140 --rm-cache-dir https://www.youtube.com/watch?v=Og3JM8abqxI</pre><p></p>
<p style="text-align: justify;">Sinon, je vous conseille de chercher d&rsquo;abord dans <a href="https://github.com/ytdl-org/youtube-dl/issues" target="_blank" rel="noopener">les issues déjà présentes</a> sur le dépôt Github avant de vous lancer dans un gros débug méchant, la solution a de grandes chances d&rsquo;avoir déjà été proposées.</p>
<h3 style="text-align: justify;">Icones Paper, Manjaro : AUR !</h3>
<p style="text-align: justify;">J&rsquo;ai eu des soucis avec des icônes qui ne s&rsquo;affichaient plus correctement. Il s&rsquo;avère que le paquet community « paper-icon-theme-git » n&rsquo;a pas l&rsquo;air très maintenu. Et il existe une version AUR avec exactement le même nom (ce dont je ne suis pas fan, c&rsquo;est la fête aux conflits). Yay dispose cependant d&rsquo;un flag &lsquo;-a&rsquo; pour forcer l&rsquo;installation du paquet AUR plutôt que le paquet community :</p>
<p></p><pre class="crayon-plain-tag">$ yay -Ss paper-icon-theme
aur/paper-icon-theme 1.5.0-2 (+39 0.00%)
    Paper is an open source desktop theme and icon project by Sam Hewitt
aur/paper-icon-theme-git 805.8c7bf8d2-1 (+216 0.98%)
    Paper is an icon theme for GTK based desktops and fits perfectly the paper-gtk-theme
community/paper-icon-theme-git 746.04115106-1 (40.3 MiB 57.4 MiB)
    Paper is an icon theme for GTK based desktops and fits perfectly the paper-gtk-theme
 ~  blog  images 
$ yay -Sa paper-icon-theme-git
:: Checking for conflicts...
:: Checking for inner conflicts...
[Repo Make: 2]  ninja-1.10.0-1  meson-0.54.0-2
[Aur: 1]  paper-icon-theme-git-805.8c7bf8d2-1</pre><p></p>
<p style="text-align: justify;">Par la suite ça gueulera que le paquet local est plus récent que le paquet distant, mais c&rsquo;est pas grave <img src="https://s.w.org/images/core/emoji/11/72x72/1f600.png" alt="😀" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<h3 style="text-align: justify;">Docker, Alpine, telnet sont dans un bâteau&#8230;</h3>
<p style="text-align: justify;">J&rsquo;avais besoin de faire un test rapide de connexion au SMTP Free depuis le container gitea, qui est basé sur alpine. Pour avoir à disposition la commande telnet qui n&rsquo;es pas présente par défaut, il faut un petit paquet en plus :</p>
<p></p><pre class="crayon-plain-tag">/ # telnet smtp.free.fr 587
/bin/sh: telnet: not found
/ # apk add busybox-extras
fetch http://dl-cdn.alpinelinux.org/alpine/v3.11/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.11/community/x86_64/APKINDEX.tar.gz
(1/1) Installing busybox-extras (1.31.1-r9)
Executing busybox-extras-1.31.1-r9.post-install
Executing busybox-1.31.1-r9.trigger
OK: 59 MiB in 71 packages
/ # busybox-extras telnet smtp.free.fr 587
Connected to smtp.free.fr
220 smtp2-g21.free.fr ESMTP Postfix
QUIT
221 2.0.0 Bye
Connection closed by foreign host
/ #</pre><p></p>
<h3 style="text-align: justify;">Cloner un dépôt git sans son historique</h3>
<p style="text-align: justify;">Coup de main d&rsquo;un collègue de boulot qui migre nos Wiki vers un cluster OpenShift. Lors du build des images, il clone la source de mediawiki depuis Github, et constate que ça prend beaucoup trop de temps, et à raison : le dossier fait 1 Go !!! Dans ce contexte, on a pas besoin de l&rsquo;historique complet de git, on peut donc contourner ce problème avec l&rsquo;option <code>--depth</code> de git :</p>
<p></p><pre class="crayon-plain-tag">git clone --depth 1 https://github.com/wikimedia/mediawiki -b REL1_34</pre><p></p>
<p style="text-align: justify;">Comme ça on récupère l&rsquo;arborescence de la branche/tag/ref qu&rsquo;on indique, sans tout l&rsquo;historique git qui va avec et qui est inutile dans l&rsquo;image Docker finale <img src="https://s.w.org/images/core/emoji/11/72x72/1f609.png" alt="😉" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<h3 style="text-align: justify;">Thunderbird/Lightning : masquer les weekends</h3>
<p style="text-align: justify;">Je n&rsquo;utilise pas de calendrier perso, mais au boulot oui, mais par contre, contrairement à Outlook, Lightning m&rsquo;affiche les semaines complètes, ce qui ne m&rsquo;intéresse pas puisque les weekend je ne travaille pas. Il est tout de même possible de masquer ces weekends inutiles, mais c&rsquo;est pas intuitif. Il faut avoir le calendrier affiché, ouvrir le menu, Affichage, Calendar, Current view, Workweek days only. Et voilà <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<h3><a href="https://blog.seboss666.info/wp-content/uploads/2020/09/tb_lightning_view.jpg" rel="lightbox[6232]"><img class="aligncenter size-medium wp-image-6397" src="https://blog.seboss666.info/wp-content/uploads/2020/09/tb_lightning_view-300x169.jpg" alt="" width="300" height="169" srcset="https://blog.seboss666.info/wp-content/uploads/2020/09/tb_lightning_view-300x169.jpg 300w, https://blog.seboss666.info/wp-content/uploads/2020/09/tb_lightning_view-768x432.jpg 768w, https://blog.seboss666.info/wp-content/uploads/2020/09/tb_lightning_view-1024x576.jpg 1024w" sizes="(max-width: 300px) 100vw, 300px" /></a>ArchLinux/Manjaro : paquets AUR au format Zstd</h3>
<p style="text-align: justify;">J&rsquo;ai déjà parlé du format Zstd et de ses avantages et inconvénients. ArchLinux et par conséquent Manjaro passent petit à petit le format des paquets sur cet algo de compression. Mais au détour d&rsquo;une lourde mise à jour de Skype qu&rsquo;on installer par AUR, j&rsquo;ai vu que c&rsquo;était toujours l&rsquo;efficace mais très lent xz qui était toujours aux commandes. Pour corriger ça, direction le fichier /etc/makepkg.conf, et modifier les deux paramètres :</p>
<p></p><pre class="crayon-plain-tag">#On change l'extension pour préférer le format
PKGEXT='.pkg.tar.zst'
#On change les options pour maximiser l'utilisation du processeur pour la compression
COMPRESSZST=(zstd -T0 -c -z -q -)</pre><p></p>
<h3 style="text-align: justify;">Convertir les fichiers .msg pour Thunderbird sous Linux</h3>
<p style="text-align: justify;">Microsoft et ses formats pourris binaires&#8230; Ayant été contraint d&rsquo;utiliser Outlook pendant quelques années, j&rsquo;ai gardé quelques fichiers en local au format .msg, et il est encore fréquent d&rsquo;en trouver en pièce jointe de certains messages. On s&rsquo;en doute, c&rsquo;est un format maison que ne comprennent pas les autres clients mails, Thunderbird en tête.</p>
<p style="text-align: justify;">Heureusement, il existe un petit utilitaire qui permet de convertir msg en eml, <a href="https://github.com/mvz/email-outlook-message-perl" target="_blank" rel="noopener">écrit en perl</a>, un langage qui me résistera toujours je pense, mais qui permet semble-t-il pas mal de choses. Installable sur Arch/Manjaro via AUR, s&rsquo;appelle aussi <a href="https://packages.debian.org/buster/libemail-outlook-message-perl" target="_blank" rel="noopener">libemail-outlook-message-perl</a> sous Debian/Ubuntu.</p>
<h3 style="text-align: justify;">Afficher le détail de la connexion WiFi sous Linux</h3>
<p style="text-align: justify;">Incroyable, mais je n&rsquo;ai trouvé aucune information sur comment afficher les détails techniques de la connexion Wifi en cours : bande de fréquence, norme, canal, alors que NetworkManager a quand même bien mûri, je n&rsquo;ai que la puissance du signal. C&rsquo;est chiant, frustrant surtout quand on teste la Livebox 5 flambante neuve de la petite soeur qui vient de passer à la fibre.</p>
<p style="text-align: justify;">Le plus simple que j&rsquo;ai trouvé, c&rsquo;est wavemon, dispo sur Debian/Ubuntu et Arch/Manjaro, un utilitaire qui permet d&rsquo;afficher en ligne de commande les détails que je souhaitais :</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2020/08/wavemon.png" rel="lightbox[6232]"><img class="aligncenter size-medium wp-image-6386" src="https://blog.seboss666.info/wp-content/uploads/2020/08/wavemon-300x148.png" alt="" width="300" height="148" srcset="https://blog.seboss666.info/wp-content/uploads/2020/08/wavemon-300x148.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/08/wavemon-768x379.png 768w, https://blog.seboss666.info/wp-content/uploads/2020/08/wavemon.png 942w" sizes="(max-width: 300px) 100vw, 300px" /></a>Le débit et la bande de fréquence me font dire que je suis bien en WiFi AC, confirmant les bons débits que j&rsquo;expérimente sur la connexion <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<h3 style="text-align: justify;">Terraform : identifier les variables non-utilisées</h3>
<p style="text-align: justify;">Quand on fait évoluer un code terraform, il est possible que certaines variables soient devenues inutiles. Dans ce cas, pour les identifier et faire le ménage dans les déclarations (dans votre fichier variables.tf le plus souvent), vous pouvez exploiter ce petit one-liner :</p>
<p></p><pre class="crayon-plain-tag">$ for name in $(grep variable variables.tf | cut -d '"' -f 2); do grep $name *.tf | grep -v variable &gt;/dev/null || echo $name is unused; done
client is unused
$</pre><p></p>
<p style="text-align: justify;">Et ça suffira pour aujourd&rsquo;hui, mais on n&rsquo;est pas à l&rsquo;abri de voir d&rsquo;autres morceaux un peu plus costauds dans le futur (ou plus originaux <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /> )</p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/09/quelques-astuces-diverses-dix-neuvieme/feed/</wfw:commentRss>
            <slash:comments>2</slash:comments>
        </item>
        <item>
            <title>De Docker Swarm à Kubernetes avec k3s</title>
            <link>https://blog.seboss666.info/2020/08/de-docker-swarm-a-kubernetes-avec-k3s/</link>
            <comments>https://blog.seboss666.info/2020/08/de-docker-swarm-a-kubernetes-avec-k3s/#comments</comments>
            <pubDate>Tue, 25 Aug 2020 16:00:14 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Projets]]></category>
            <category><![CDATA[Sysadmin]]></category>
            <category><![CDATA[complexité]]></category>
            <category><![CDATA[consommation]]></category>
            <category><![CDATA[docker]]></category>
            <category><![CDATA[futur]]></category>
            <category><![CDATA[k3s]]></category>
            <category><![CDATA[kompose]]></category>
            <category><![CDATA[kubernetes]]></category>
            <category><![CDATA[migration]]></category>
            <category><![CDATA[rancher]]></category>
            <category><![CDATA[ressources]]></category>
            <category><![CDATA[stockage]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=5962</guid>
            <description><![CDATA[Après plusieurs mois d&#8217;attentes et de réflexion, je me suis enfin sorti les doigts du cul et j&#8217;ai changé le SSD du micro-serveur. Double espace [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Après plusieurs mois d&rsquo;attentes et de réflexion, je me suis enfin sorti les doigts du cul et j&rsquo;ai changé le SSD du micro-serveur. Double espace pour monter de nouvelles VMs, pour lesquelles j&rsquo;ai décidé non pas de rester sur Docker Swarm, mais de pleinement embrasser Kubernetes, via un projet très intéressant. Et comme souvent, voici le récit de ce voyage, parce qu&rsquo;il fût semé d’embûches, de celles qu&rsquo;on ne voit évidemment pas dans les tutos « hello world ».</p>
<p style="text-align: justify;"><span id="more-5962"></span></p>
<p style="text-align: justify;"><strong>Avertissement</strong> : <em>ceci n&rsquo;est pas un tuto complet, mais juste un gros retour d&rsquo;expérience avec les réflexions qui vont avec</em>.</p>
<p style="text-align: justify;">Kubernetes&#8230; Le projet initié par Google et libéré depuis est sur toutes les lèvres des décideurs informatiques capturés tels des lapins par les phares des marketeux des agences Web qui pensent pouvoir se passer de qualité. Il est vrai que comparé à du Docker pur, et même à Swarm, il a une quantité d&rsquo;avantages. Mais il a aussi ses inconvénients, et ça peut vite s&#8217;emballer.</p>
<p style="text-align: justify;">Je suis toujours aussi critique sur la conteneurisation des applications, et surtout de son usage souvent mauvais, à l&rsquo;image d&rsquo;un php accessible qui permet trop facilement de faire de la merde. Mais pour le manipuler depuis plus d&rsquo;un an et demi, force est de reconnaître que K8s (le nom abrégé de Kubernetes) me plaît beaucoup, bien que je lui trouve aussi des défauts. C&rsquo;est selon moi, à date évidemment, la meilleure implémentation d&rsquo;orchestration de conteneurs que l&rsquo;on puisse trouver.</p>
<p style="text-align: justify;">À l&rsquo;image du cluster Swarm qui était surtout à la base un moyen d&rsquo;entretenir mes compétences Docker, l&rsquo;évolution du cluster est donc un moyen d&rsquo;expérimenter et d&rsquo;entretenir mes compétences sur et autour de Kubernetes.</p>
<h3 style="text-align: justify;">Rancher, un acteur clé du monde de la conteneurisation</h3>
<p style="text-align: justify;"><a href="https://rancher.com/" target="_blank" rel="noopener">Rancher</a> est une société qui développe beaucoup d&rsquo;outils et de services centrés sur les containers. OS de supervision de cluster, orchestrateur docker, providers de stockage, et j&rsquo;en passe. Leur expertise dans ce domaine n&rsquo;est plus à faire, et beaucoup de leurs outils sont open source.</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2019/09/rancher_logo.png" rel="lightbox[5962]"><img class="aligncenter size-medium wp-image-6390" src="https://blog.seboss666.info/wp-content/uploads/2019/09/rancher_logo-300x44.png" alt="" width="300" height="44" srcset="https://blog.seboss666.info/wp-content/uploads/2019/09/rancher_logo-300x44.png 300w, https://blog.seboss666.info/wp-content/uploads/2019/09/rancher_logo-768x113.png 768w, https://blog.seboss666.info/wp-content/uploads/2019/09/rancher_logo-1024x151.png 1024w" sizes="(max-width: 300px) 100vw, 300px" /></a>C&rsquo;est un acteur de poids qui cherche en permanence de nouveaux moyens de mettre ces technos à la portée du plus grand nombre, des gros serveurs de data centers, aux petits auto hébergés comme moi qui voudraient aussi en profiter. Et dans cette catégorie, tous n&rsquo;ont pas un serveur comme le mien, qui n&rsquo;est déjà pas bien puissant, mais encore plus petit. D&rsquo;ailleurs on verra que finalement j&rsquo;utilise plusieurs projets liés venant de Rancher.</p>
<p style="text-align: justify;">Je vous recommande de vous intéresser à leurs produits, certains sont intéressants, comme l&rsquo;utilitaire qui permet de faire de la centralisation de la gestion de clusters, et ce quelque soit leur origine (maison, « cloud-provided », etc), parce que parfois, la ligne de commande c&rsquo;est chiant même quand on adore <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <em>(Ils ont aussi un catalogue de formations et de certifications qui peut vous intéresser)</em></p>
<h3 style="text-align: justify;">k3s, la réponse pour nano-pc</h3>
<p style="text-align: justify;">Un des reproches qu&rsquo;on fait souvent à k8s est sa lourdeur, à savoir que les composants permettant de faire le boulot consomment beaucoup de ressources eux-mêmes. Chez Microsoft ils nous indiquaient un chiffre, certes un peu au doigt mouillé, d&rsquo;une dizaine de pourcents pour les nœuds worker. Et les masters doivent aussi être si possible des brutes, surtout en mémoire vive (merci etcd). De manière général, on recommande que chaque machine du cluster dispose d&rsquo;au moins 4 coeurs et de 8Go de RAM. C&rsquo;est juste la capacité globale de mon micro-serveur actuellement, c&rsquo;est un peu compliqué.</p>
<p style="text-align: justify;">Et Rancher avait une cible : le Raspberry PI, un nano-pc disponibles aux alentours d&rsquo;une trentaine euros, sur architecture ARM, d&rsquo;abord conçu pour le monde de l&rsquo;éducation, mais qui a bien dépassé ce cadre (on en doute même du succès auprès de cette cible primaire, tant les bidouilleurs se sont jetés dessus). Avec environ 1Go de RAM pour les PI 3, il est évident qu&rsquo;il n&rsquo;est pas possible en l&rsquo;état de faire tourner la bête. Ils ont donc bossé, cherché comment réduire au maximum, parfois en allant jusqu&rsquo;à remplacer des composants du control plane par d&rsquo;autres plus légers.</p>
<p style="text-align: justify;"><a href="https://k3s.io/" target="_blank" rel="noopener">k3s</a> est né. Avec k3s vous pouvez monter un cluster Kubernetes à base de machines aussi peu puissantes que des Raspberry PI (3 et suivants), ce qui tombe bien puisque je déploie en général des machines virtuelles aux caractéristiques proches sur mon serveur. Je ne suis ni le premier ni le dernier à en parler, mais je vais m&rsquo;inspirer du travail déjà produit, ne serait que pour valider que c&rsquo;est réutilisable dans d&rsquo;autres situations. Et surtout, j&rsquo;ai des outils déjà déployés qu&rsquo;il faut que je transfère, car je n&rsquo;ai pas non plus envie de me paver les deux clusters en maintenance.</p>
<div id="attachment_6380" style="width: 310px" class="wp-caption aligncenter"><a href="https://blog.seboss666.info/wp-content/uploads/2019/09/pi_cluster.jpg" rel="lightbox[5962]"><img class="size-medium wp-image-6380" src="https://blog.seboss666.info/wp-content/uploads/2019/09/pi_cluster-300x295.jpg" alt="" width="300" height="295" srcset="https://blog.seboss666.info/wp-content/uploads/2019/09/pi_cluster-300x295.jpg 300w, https://blog.seboss666.info/wp-content/uploads/2019/09/pi_cluster-768x755.jpg 768w, https://blog.seboss666.info/wp-content/uploads/2019/09/pi_cluster.jpg 800w" sizes="(max-width: 300px) 100vw, 300px" /></a><p class="wp-caption-text">Spoiler, c&rsquo;est pas des Pi 4 <img src="https://s.w.org/images/core/emoji/11/72x72/1f61b.png" alt="😛" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p></div>
<p style="text-align: justify;">Et comme indiqué au début, j&rsquo;ai pas prévu de me faire mal avec des raspberry PI, j&rsquo;ai juste un micro-serveur dont j&rsquo;ai <a href="https://blog.seboss666.info/2017/01/le-futur-de-mon-infrastructure-personnelle/" target="_blank" rel="noopener">déjà parlé dans le passé</a>.</p>
<h3 style="text-align: justify;">Monter un cluster en mode « Infra as Code »</h3>
<p style="text-align: justify;">Parce que ça fait aussi partie des mes activités au boulot désormais, j&rsquo;avais envie de déployer tout le cluster en mode Infrastructure-as-Code. Rien de révolutionnaire, j&rsquo;ai visé l&rsquo;utilisation de <a href="https://www.terraform.io/" target="_blank" rel="noopener">Terraform</a> pour déployer mes machines, et d&rsquo;<a href="https://docs.ansible.com/" target="_blank" rel="noopener">Ansible</a> pour faire leur configuration de base.</p>
<p style="text-align: justify;">Je pensais faire la transition en douceur entre Docker Swarm et Kubernetes, mais quelques mésaventures avec le LVM de Proxmox VE m&rsquo;ont poussé à carrément réinstaller celui-ci dans sa dernière version et donc refaire les machines de zéro. Ce fut également l&rsquo;occasion de tout refaire à base de Debian 10 (dont j&rsquo;aurais sûrement l&rsquo;occasion de faire quelques remarques plus tard). Comme je suis toujours en télétravail prolongé chez ma mère, ça s&rsquo;est fait lors d&rsquo;un aller-retour rapide chez moi, car j&rsquo;ai dû aller au boulot chercher ma <a href="https://www.yubico.com/products/" target="_blank" rel="noopener">Yubikey</a>. J&rsquo;ai juste pris le temps de réinstaller Proxmox VE sur un SSD flambant neuf deux fois plus gros que celui d&rsquo;origine, et réinstaller le bastion à la main pour pouvoir faire tout le boulot à distance par la suite, j&rsquo;avais déjà à disposition mes rôles de bases d&rsquo;Ansible c&rsquo;est donc allé très vite.</p>
<p style="text-align: justify;">Déployer des machines avec Terraform suppose d&rsquo;avoir à disposition un template de machine à déployer. Au final j&rsquo;ai suivi la plupart des <a href="https://notamax.be/proxmox-v6-cluster-k8s-kubeadm-via-terraform-cloud-init/" target="_blank" rel="noopener">instructions partagées par Anthony</a> (et sur lequel j&rsquo;ai apporté une précision après avoir rencontré des soucis), après tout pourquoi réinventer la roue quand la solution existe déjà ? L&rsquo;article propose l&rsquo;installation bout-en-bout d&rsquo;un kube complet via kubeadm, je me suis juste inspiré de la partie Terraform car je compte bien rester sur du k3s. Je suis parti sur une base d&rsquo;un master/deux workers, et j&rsquo;ai cette fois déployé des machines à 2vCPU et 2 Go de RAM. La seule contrariété finalement que j&rsquo;ai rencontré c&rsquo;est que j&rsquo;étais à distance, et que l&rsquo;interface de Proxmox VE n&rsquo;est pas joignable de l&rsquo;extérieur. Je suis donc passé par un transfert de port via SSH pour exposer en local le port 8006, et c&rsquo;est localhost qui était désigné comme adresse dans la configuration du provider pour taper sur l&rsquo;API de Proxmox. Et pour l&rsquo;anecdote, l&rsquo;instance Consul qui me sert à stocker mes tfstate était déployée sur Docker Swarm, du coup dans l&rsquo;immédiat le tfstate reste en local sur mon poste.</p>
<p></p><pre class="crayon-plain-tag">$ ssh -L 8006:127.0.0.1:8006 root@pimousse.seboss666.ovh</pre><p></p>
<p style="text-align: justify;">Pour la partie configuration de base, comme je disais, j&rsquo;ai déjà mes rôles Ansible, que j&rsquo;ai remis à jour pour prendre en compte les changements effectués dans Debian 10. Certains paquets ont changé de nom ou ont disparu, d&rsquo;autres n&rsquo;étaient pas inclus de base dans l&rsquo;image utilisée pour le template, et j&rsquo;ai également eu à faire une ou deux modifications mineures dans l&rsquo;environnement bash (via <a href="https://gitlab.com/bersace/powerline.bash/" target="_blank" rel="noopener">powerline.bash</a>), en vue justement de pouvoir utiliser k3s par la suite.</p>
<p style="text-align: justify;">Pour l&rsquo;installation de k3s et la création du cluster lui-même, ça a été un peu plus compliqué. J&rsquo;avais ressorti un article d&rsquo;itwars et surtout le dépôt Github gardé après avoir lu <a href="https://blog.zwindler.fr/2019/03/21/deployer-en-5-minutes-un-cluster-kubernetes-sur-arm-avec-k3s-et-ansible/" target="_blank" rel="noopener">l&rsquo;article de Zwindler</a> sur une telle opération sur des machines Scaleway. Cette première version n&rsquo;avait que peu bougé, et surtout, j&rsquo;ai perdu du temps en recopiant tout plutôt qu&rsquo;en clonant, parce qu&rsquo;au passage j&rsquo;effectuais en direct mes propres changements dans les tâches, et ça avait abouti à un truc qui ne fonctionnait pas, en tout cas pas complètement. Avant de me rendre compte que le contenu du dépôt a <a href="https://github.com/rancher/k3s-ansible" target="_blank" rel="noopener">été repris et amélioré</a> de manière communautaire directement par Rancher. Avec toute la maintenance qui va avec, et bizarrement, après avoir fait les deux/trois modifications qui s&rsquo;imposaient (entre autres désactivation de l&rsquo;installation de Traefik pour faire la mienne, et la personnalisation du réseau, personnalisation de l&rsquo;inventaire comme le préconise la doc), ça a fini par tomber en marche. Mais comptez deux après-midi de perte de temps quand même, si c&rsquo;est pas un boulot de champion ça&#8230;</p>
<p style="text-align: justify;">Comme je prévois d&rsquo;utiliser quelques softs sans forcément pousser la configuration de ouf, j&rsquo;ai cherché à installer Helm, que je viens d&rsquo;évoquer, en tentant quelques tâches Ansible. Après plusieurs échecs minables parce que je ne suis parfois pas doué (ou pas concentré), j&rsquo;ai finalement retrouvé la mémoire, à savoir qu&rsquo;il existe une base de données plutôt fournie de rôles communautaires qui s&rsquo;appelle Ansible Galaxy. J&rsquo;ai donc fouillé dedans et il n&rsquo;a pas fallu une minute pour que <a href="https://galaxy.ansible.com/andrewrothstein/kubernetes-helm" target="_blank" rel="noopener">Helm soit installé</a>. On ne regarde pas assez souvent ce que les gens ont contribué sur Galaxy, c&rsquo;est une vraie mine d&rsquo;or.</p>
<h3 style="text-align: justify;">Convertir mes services, en mode feignant ?</h3>
<p style="text-align: justify;">À l&rsquo;image de Gogs, qui était passé de « bare metal » <a href="https://blog.seboss666.info/2017/12/comment-transformer-un-de-ses-services-avec-docker-gogs/" target="_blank" rel="noopener">à Docker Swarm</a>, j&rsquo;ai ensuite dû me pencher sur la conversion du fichier docker stack/compose en manifestes Kubernetes. On va le voir, de la même façon qu&rsquo;on déclare un réseau, des services, et des volumes, il faut aussi déclarer plusieurs types d&rsquo;objets pour faire le boulot, l&rsquo;architecture globale n&rsquo;ayant cette-fois-ci pas trop besoin de changer puisqu&rsquo;on est déjà dans un contexte container.</p>
<p style="text-align: justify;">Par contre, même les plus aguerris vous le dirons, la syntaxe des manifestes k8s, écrit le plus souvent en yaml, est pour le moins verbeuse. À tel point que si on définit une stack Swarm dans un fichier unique généralement, les bonnes pratiques consistent à créer un fichier par objet ou type d&rsquo;objet pour Kubernetes. Oui, on en est là.</p>
<p style="text-align: justify;">De cette complexité est né l&rsquo;outil <a href="https://kompose.io/getting-started/" target="_blank" rel="noopener">Kompose</a>, un véritable must have selon moi qui permet de créer des manifestes K8s à partir de fichiers docker-compose. Ils sont rarement exploitables en l&rsquo;état mais permettent de mâcher le boulot pour avoir la structure qui va bien, un peu à l&rsquo;image d&rsquo;ansible-galaxy qui peut vous générer la structure d&rsquo;un module Ansible pour vous, dans l&rsquo;optique d&rsquo;une publication.</p>
<h3 style="text-align: justify;">La question sensible des volumes persistants&#8230;</h3>
<p style="text-align: justify;">Toujours cette satanée persistance dont personne ne veut prendre en charge les problèmatiques. C&rsquo;est faux en partie, Kubernetes embarque nativement pas mal de plugins pour des technos de stockage diverses et variées, notamment celles des fournisseurs de cloud qui proposent des services Kubernetes hébergés et gérés prêts à l&#8217;emploi, ces plugins permettant alors, depuis Kubernetes, de « commander » automatiquement des volumes de différents types.</p>
<p style="text-align: justify;">K3s étant simplifié, par défaut tous ces plugins sautent et seul le hostpath et l&#8217;emptydir persistent. C&rsquo;est embêtant parce que j&rsquo;utilise déjà du NFS et il est possible de déclarer les PV NFS sans problème, mais pas les PVC (et on parle de plusieurs heures à essayer). Comme je l&rsquo;indiquais <a href="https://blog.seboss666.info/2019/12/une-bonne-gestion-des-volumes-nfs-dans-un-cluster-docker-swarm/" target="_blank" rel="noopener">dans le billet dédié à ce sujet</a> maintenant les volumes NFS sont déclaré explicitement dans mes stacks, et non plus via un montage global sur chaque nœud. J&rsquo;ai de toute façon prévu de m&rsquo;en débarrasser, rappelez-vous, quand tout redémarre le temps de démarrage du NAS faisait que mes services tentaient de démarrer sans leur volume, avec un résultat parfois intéressant, mais il faut bien que je transfère les données. Une des solutions de contournement, serait d&rsquo;utiliser le <a href="https://github.com/helm/charts/tree/master/stable/nfs-client-provisioner" target="_blank" rel="noopener">nfs-client-provisioner</a>, pluggé sur mon partage global, qui crée des dossiers dynamiquement, dans lesquels je synchroniserai éventuellement les data le temps de faire cette migration. Mais au final, si le nfs-client-provisioner est là, il n&rsquo;est que très peu utilisé.</p>
<p style="text-align: justify;">Pour disposer de volumes persistants au sein même du cluster, j&rsquo;ai décidé d&rsquo;utiliser un autre projet de Rancher, <a href="https://longhorn.io/" target="_blank" rel="noopener">Longhorn</a>. J&rsquo;ai eu par contre la désagréable surprise de voir sa lourdeur pour mon cluster, donc tant pis, on verra à l&rsquo;usage. Un autre élément à prendre en compte, c&rsquo;est que les volumes Longhorn ne supporte que le mode d&rsquo;écriture RWO, pour Read-Write-Once, ce qui veut dire pas de replicas d&rsquo;un même pod, et surtout pas de rolling update. Aussi, même en déclarant un volume aussi petit que 32Mi via PVC, il a créé un PV d&rsquo;1Go, et le PVC mentionne aussi 1Go. Fort heureusement ce sont des volumes « dynamiques », à savoir qu&rsquo;ils consomment réellement uniquement ce qu&rsquo;on y met, mais si on vide manuellement un volume, le fichier correspondant sous-jacent sur l&rsquo;OS n&rsquo;est pas redimensionné, à l&rsquo;image d&rsquo;une image disque de machine virtuelle (ce qu&rsquo;on avait pu voir à l&rsquo;époque <a href="https://blog.seboss666.info/2014/08/convertir-une-image-disque-de-machine-virtuelle-au-format-qcow2/" target="_blank" rel="noopener">sur le format qcow2</a>).</p>
<p style="text-align: justify;">Pour contourner la limitation du RWO, il existe un provisioner « <a href="https://longhorn.io/docs/1.0.2/advanced-resources/rwx-workloads/" target="_blank" rel="noopener">longhorn-nfs</a> » disponible dans la dernière version qui va créer un volume unique d&rsquo;une certaine taille (20Go par défaut), et l&rsquo;exposer en NFS via une StorageClass, ce qui permet du coup de bénéficier des rolling updates. J&rsquo;arrive toujours pas à me décider si je vais tout utiliser de cette manière, on verra à l&rsquo;usage.</p>
<h3 style="text-align: justify;">&#8230; et le réapprentissage de l&rsquo;Ingress controller</h3>
<p style="text-align: justify;">Comme je l&rsquo;ai évoqué un peu plus tôt, même si k3s est fourni avec Traefik, la version embarquée me plait moyennement car la 2.2 apporte beaucoup de fonctions sympatiques. Pour l&rsquo;installation de cette version, là encore rien de transcendant, je me suis basé sur le <a href="https://github.com/djerfy/kubernetes-ingress-traefik" target="_blank" rel="noopener">travail de configuration « simple » mis à disposition par Djerfy</a>, en l&rsquo;adaptant légèrement pour mes besoins. J&rsquo;avais commencé par Helm, mais j&rsquo;avais un petit risque de passer à côté de la souplesse de personnaliser complètement l&rsquo;outil. Je peux maintenant exposer les ports via la box, et faire tout le boulot qu&rsquo;on demande d&rsquo;un reverse-proxy. Et voilà, j&rsquo;ai la base pour redéployer mes services désormais.</p>
<p style="text-align: justify;">Traefik a l&rsquo;air très intéressant, mais son implémentation dans Kubernetes amène pas mal de concepts que je dois réapprendre, par rapport à un Ingress Controller plus classique (Nginx étant le plus répandu, et j&rsquo;ai pratiqué haproxy lors d&rsquo;un projet client). Et sinon, là où ça restera compliqué pour la conversion, c&rsquo;est que je crois que Kompose ne crée pas les fichiers d&rsquo;Ingress, je n&rsquo;ai donc aucune base de travail. Pas étonnant, aucun label particulier pour l&rsquo;aider, son travail à partir du docker-compose se limite donc à l&rsquo;exposition du service.  L&rsquo;avantage c&rsquo;est que tout est documenté, mais ça n&#8217;empêche pas que je doives apprendre toute la syntaxe de configuration, adapter les « tricks » que j&rsquo;avais pu faire sur mon reverse-proxy Nginx, et surtout, trouver un moyen de coupler les IngressRoute propres à Kubernetes à des bouts de configuration plus statiques pour les quelques services qui ne seront pas dans le cluster, l&rsquo;interface du NAS en premier lieu.</p>
<p><a href="https://blog.seboss666.info/wp-content/uploads/2019/09/traefik_dashboard_svc.png" rel="lightbox[5962]"><img class="aligncenter size-medium wp-image-6391" src="https://blog.seboss666.info/wp-content/uploads/2019/09/traefik_dashboard_svc-300x156.png" alt="" width="300" height="156" srcset="https://blog.seboss666.info/wp-content/uploads/2019/09/traefik_dashboard_svc-300x156.png 300w, https://blog.seboss666.info/wp-content/uploads/2019/09/traefik_dashboard_svc-768x399.png 768w, https://blog.seboss666.info/wp-content/uploads/2019/09/traefik_dashboard_svc-1024x532.png 1024w, https://blog.seboss666.info/wp-content/uploads/2019/09/traefik_dashboard_svc.png 1468w" sizes="(max-width: 300px) 100vw, 300px" /></a></p>
<p style="text-align: justify;">En tout cas pas mécontent d&rsquo;avoir dans mes contacts proches un Djerfy qui est Traefik Ambassador pour m&rsquo;épauler (bien qu&rsquo;il soit parfois lui-même en train de déterrer des trucs), ça aide bien pendant cette mini-traversée du désert <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<h3 style="text-align: justify;">La mise en pratique de la migration de service</h3>
<p style="text-align: justify;">Pour l&rsquo;article je vais prendre l&rsquo;exemple simple de <a href="https://oss.oetiker.ch/smokeping/" target="_blank" rel="noopener">Smokeping</a>. Un container, deux volumes, un port, on peut difficilement faire plus accessible. Voici d&rsquo;ailleurs la stack actuelle :</p>
<p></p><pre class="crayon-plain-tag">version: "3.2"

volumes:
  smokedata:
    driver_opts:
      type: nfs
      o: "addr=1.2.3.4,rw,nfsvers=3,nolock,soft,exec"
      device: ":/Docker/smokeping/data"
  smokeconfig:
    driver_opts:
      type: nfs
      o: "addr=1.2.3.4,rw,nfsvers=3,nolock,soft,exec"
      device: ":/Docker/smokeping/config"

networks:
  smokeping:
    driver: overlay

services:
  smokeping:
    image: linuxserver/smokeping:191068eb-ls64
    networks:
      - "smokeping"
    ports:
      - "20080:80"
    environment:
      - "PUID=1001"
      - "GUID=1001"
      - "TZ=Europe/Paris"
    volumes:
      - type: volume
        source: smokedata
        target: /data
        volume:
          nocopy: true
      - type: volume
        source: smokeconfig
        target: /config
        volume:
          nocopy: true
    deploy:
      replicas: 1
      restart_policy:
        condition: any</pre><p></p>
<p style="text-align: justify;">Passons maintenant à Kompose, pas besoin de détailler son installation, il suffit de suivre <a href="https://kompose.io/installation/" target="_blank" rel="noopener">la doc</a> (rtfm quoi). Pour son utilisation, il suffit de le lancer en lui indiquant le fichier compose et paf, ça fait des chocapic, ou presque. On constate qu&rsquo;il a créé plusieurs fichiers yaml, dont on va détailler les éléments :</p>
<p></p><pre class="crayon-plain-tag">-rw-r--r-- 1 seboss666 seboss666  271 18.08.2020 19:55 smokeconfig-persistentvolumeclaim.yaml
-rw-r--r-- 1 seboss666 seboss666  268 18.08.2020 19:55 smokedata-persistentvolumeclaim.yaml
-rw-r--r-- 1 seboss666 seboss666 1,4K 10.08.2020 19:40 smokeping-deployment.yaml
-rw-r--r-- 1 seboss666 seboss666  294 10.08.2020 19:40 smokeping-networkpolicy.yaml
-rw-r--r-- 1 seboss666 seboss666  381 10.08.2020 19:40 smokeping-service.yaml</pre><p></p>
<p style="text-align: justify;">On a donc deux persistent volume claims, un deployment, un networkpolicy et un service. Il manque encore l&rsquo;IngressRoute et un ou deux éléments annexes dont on va parler juste après.</p>
<p style="text-align: justify;">Voyons un peu à quoi ressemblent ces fichiers, celui du deployment étant assez intéressant :</p>
<p></p><pre class="crayon-plain-tag">apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: smokeping
  annotations:
    kompose.cmd: kompose convert -f ./smokeping_stack.yml
    kompose.version: 1.21.0 (992df58d8)
  creationTimestamp: null
  labels:
    io.kompose.service: smokeping
  name: smokeping
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: smokeping
  strategy:
    type: Recreate
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f ./smokeping_stack.yml
        kompose.version: 1.21.0 (992df58d8)
      creationTimestamp: null
      labels:
        io.kompose.network/smokeping: "true"
        io.kompose.service: smokeping
    spec:
      containers:
      - env:
        - name: GUID
          value: "1001"
        - name: PUID
          value: "1001"
        - name: TZ
          value: Europe/Paris
        image: linuxserver/smokeping:191068eb-ls64
        imagePullPolicy: ""
        name: smokeping
        ports:
        - containerPort: 80
        resources: {}
        volumeMounts:
        - mountPath: /data
          name: smokedata
        - mountPath: /config
          name: smokeconfig
      restartPolicy: Always
      serviceAccountName: ""
      volumes:
      - name: smokedata
        persistentVolumeClaim:
          claimName: smokedata
      - name: smokeconfig
        persistentVolumeClaim:
          claimName: smokeconfig
status: {}</pre><p></p>
<p style="text-align: justify;">Je l&rsquo;avais dit que c&rsquo;était particulièrement verbeux ? C&rsquo;est un des reproches que je fais à la techno. Pareil pour les volumes, dans Swarm, vous déclarez un volume, vous l&rsquo;utilisez, point barre. Ici il faut déclarer un volume (PersistentVolume), déclarer qu&rsquo;on va l&rsquo;utiliser (PersistentVolumeClaim), et ensuite l&rsquo;attacher dans le Deployment en le déclarant. Et tout ça avec 10 fois plus de lignes. Et encore, grâce à Longhorn, on « simplifie » parce qu&rsquo;il n&rsquo;y a besoin que du VolumeClaim, le PV étant provisionné de manière dynamique derrière. Vient ensuite le service, sans lequel le port de l&rsquo;application n&rsquo;est pas réellement exposé, et même là, ça reste de la communication « interne », à moins de faire un service de type nodePort, qui réplique finalement le comportement de docker Swarm.</p>
<p style="text-align: justify;">Car oui, en temps normal dans un cluster K8s, c&rsquo;est l&rsquo;Ingress Controller qui est chargé de faire le lien entre l&rsquo;extérieur et les services. Et donc Kompose ne s&rsquo;occupe absolument pas de cet aspect, il faut que je bosse le sujet. Pour Smokeping, je suis le seul à y accéder, on a donc une IngressRoute classique avec juste un auth basic http. Un modèle qui sera réutilisé pour la plupart des services je pense, comme c&rsquo;était le cas sur mon Nginx. Ce setup a une particularité : il a besoin d&rsquo;un secret, pour stocker le couple utilisateur:motdepassehashé, d&rsquo;un Middleware qui est une ressource Custom créée par le déploiement de Traefik pour déclarer cette authentification, et dans l&rsquo;IngressRoute lui-même, l&rsquo;appel à ce Middleware. Certes je pourrais regrouper ces éléments dans le même fichier, mais pour l&rsquo;exercice, ça fait donc trois fichiers de plus :</p>
<p></p><pre class="crayon-plain-tag">-rw-r--r-- 1 seboss666 seboss666  271 18.08.2020 19:55 smokeconfig-persistentvolumeclaim.yaml
-rw-r--r-- 1 seboss666 seboss666  268 18.08.2020 19:55 smokedata-persistentvolumeclaim.yaml
-rw-r--r-- 1 seboss666 seboss666 1,4K 10.08.2020 19:40 smokeping-deployment.yaml
-rw-r--r-- 1 seboss666 seboss666  351 18.08.2020 20:33 smokeping-ingressroute.yaml
-rw-r--r-- 1 seboss666 seboss666  211 18.08.2020 20:17 smokeping-middleware.yaml
-rw-r--r-- 1 seboss666 seboss666  294 10.08.2020 19:40 smokeping-networkpolicy.yaml
-rw-r--r-- 1 seboss666 seboss666  237 18.08.2020 20:16 smokeping-secret.yaml
-rw-r--r-- 1 seboss666 seboss666  381 10.08.2020 19:40 smokeping-service.yaml</pre><p></p>
<p style="text-align: justify;">Dans l&rsquo;immédiat je n&rsquo;ai pas appliqué la NetworkPolicy, parce que je dois l&rsquo;adapter à mon installation d&rsquo;abord, mais ça fait partie des bonnes pratiques que je recommande vivement d&rsquo;appliquer en production pour isoler vos applications entre elles. J&rsquo;ai d&rsquo;autres priorités dans l&rsquo;immédiat, et je radote je sais, mais c&rsquo;est le stockage.</p>
<p style="text-align: justify;">Revenons vite fait à l&rsquo;Ingress pour mentioner un dernier morceau : pour la génération du mot de passe dans le secret, je recommande d&rsquo;utiliser openssl qui a l&rsquo;avantage, sous Linux, d&rsquo;être déjà fourni par la plupart des distributions :</p>
<p></p><pre class="crayon-plain-tag">$ echo -e "user:$(openssl passwd -apr1 superpassword)\n"</pre><p></p>
<p style="text-align: justify;">Au passage vous pouvez aussi utiliser htpasswd du paquet httpd-tools/apache2-tools.</p>
<p style="text-align: justify;">La migration du stockage des applications a été une autre aventure. J&rsquo;évoquais la possible utilisation du nfs-client-provisioner, mais faire un premier déploiement avec un tel volume, procéder au rsync depuis le NAS sur le dossier créé, puis depuis le pod refaire un rsync sur le volume final, c&rsquo;était beaucoup trop lourd. J&rsquo;ai finalement trouvé quelque chose de pas super souple, mais beaucoup plus simple. On commence par créer le namespace et les pvc, et on crée un micro-déploiement qui monte ces deux volumes. Je me suis basé sur nginx parce que c&rsquo;est léger, rapide, avec un compte root pour éviter les problèmes de permissions pendant les manipulations. Ensuite sur le master, j&rsquo;ai également monté le partage Docker du NAS en NFS de manière dynamique, parce que ça n&rsquo;a pas vocation à persister, et j&rsquo;ai donc copié les données des volumes via « kubectl cp », sachant que derrière, il peut y avoir encore quelques manipulations à l&rsquo;intérieur du pod nginx parce que les chemins sont souvent mal interprétés (ou alors je suis mauvais, je me suis fait une raison avec le temps). Une fois terminé, je supprime le déploiement temporaire pour lancer le vrai déploiement. Pour l&rsquo;instant, je n&rsquo;ai pas rencontré de difficulté. Ça restera la partie la plus pénible des autres migrations.</p>
<h3 style="text-align: justify;">L&rsquo;accès au cluster de l&rsquo;extérieur, pas trivial</h3>
<p style="text-align: justify;">En effet, pour accéder à l&rsquo;admin du cluster via kubectl, ça se fait via https sur le port 6443 du master. Je n&rsquo;ai pas l&rsquo;intention de l&rsquo;exposer à l&rsquo;extérieur dans l&rsquo;immédiat, mais pour déployer des services dessus à distance ou procéder aux interventions de manière générale, il va falloir une solution. Exposer le control plane n&rsquo;est <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8552" target="_blank" rel="noopener">jamais une bonne idée</a>, après quelques tergiversations je vais faire ça avec une connexion SSH qui redirige le port 6443 du master vers le port 6443 local, et en plus je fais ça via le fichier <span style="font-family: courier new, courier, monospace;">~/.ssh/config</span> plutôt que via la ligne de commande, ce qui me permet de gagner du temps :</p>
<p></p><pre class="crayon-plain-tag">Host k3s-master
        LocalForward 6443 127.0.0.1:6443</pre><p></p>
<p style="text-align: justify;">Me reste à utiliser une copie du fichier kubeconfig en remplaçant l&rsquo;ip du master par 127.0.0.1. On retrouve donc la même méthode que pour le déploiement via terraform vu plus haut, avec un poil de « sucre » en plus en vue d&rsquo;une utilisation plus régulière.</p>
<p style="text-align: justify;">Enfin pour la partie Ingress Controller, j&rsquo;ai déjà indiqué comment je comptais procéder, j&rsquo;expose les ports 80 et 443 du master via le NAT de la box. Le tout malheureusement en full IPv4 car toujours pas de vrai pare-feu ipv6 sur la Freebox (et ça sera bientôt aussi le cas sur Livebox, la fibre étant au programme pour septembre, Free n&rsquo;étant pas encore à jour dans l&rsquo;Oise malgré une promesse de disponibilité fin 2019).</p>
<h3 style="text-align: justify;">Les différences avec le cluster swarm, la suite</h3>
<p style="text-align: justify;">La principale différence vient du fait que je n&rsquo;ai qu&rsquo;une seule machine qui joue le rôle de master/control plane, quand toutes les VMs du swarm étaient manager. Vu que tout est sur la même machine physique, j&rsquo;ai envie de dire que ce n&rsquo;est pas trop grave. Exit également portainer pour l&rsquo;instant, même s&rsquo;il supporte k8s désormais, et qui avait déjà sauté à l&rsquo;occasion d&rsquo;une petite corruption de configuration suite à une mauvaise manipulation lors d&rsquo;une mise à jour. Je n&rsquo;ai pas encore pour l&rsquo;instant envisagé de réinstaller une forme de dashboard « global », en dehors de celui de Traefik et de Longhorn, je verrai dans le futur si j&rsquo;en ressens le besoin.</p>
<p style="text-align: justify;">Même si à l&rsquo;époque j&rsquo;aurais pu exposer le port d&rsquo;admin de Docker Swarm pour me connecter de l&rsquo;extérieur, la configuration est beaucoup plus rudimentaire, et sur ce point Kubernetes est bien plus facilitant. Attention, ce n&rsquo;est pas nécessairement recommandé, d&rsquo;ailleurs la conf par défaut de k3s crée un simple token et j&rsquo;avoue que je tenterai bien d&rsquo;ajouter une authentification via certificat client, ce qui est bien plus sécurisant.</p>
<p style="text-align: justify;">J&rsquo;ai pu constater la réactivité de k8s par rapport à des actions de mises à jour ou de relancement d&rsquo;application, de mon point de vue c&rsquo;est plus rapide sur kube quand on tue un pod pour qu&rsquo;il réapparaisse, et surtout, j&rsquo;ai désormais la possibilité de faire du rolling update (via longhorn-nfs), limitant très fortement les indisponibilités en cas de mise à jour. Un élément plutôt impactant à prendre en compte tiens d&rsquo;ailleurs, qui a couru dès le début de l&rsquo;installation du cluster : sans la fibre, pas mal de manipulations prennent du temps, le téléchargement de chaque binaire par exemple (via Ansible, k3s était téléchargé sur trois serveurs en même temps, idem pour Helm), ou chaque image docker de plusieurs centaines de Mo est pénalisant.</p>
<h3 style="text-align: justify;">Les chantiers pour la suite</h3>
<p style="text-align: justify;">Tellement, déjà, en l&rsquo;état j&rsquo;ai redéployé un peu comme un gougnafier, et il manque des éléments qui seront importants surtout vu la capacité du cluster actuellement, à savoir les requests et limits pour éviter tout débordement d&rsquo;une application. Voici l&rsquo;état de la consommation avec Traefik, Longhorn, le nfs-client-provisioner, smokeping et gitea :</p>
<p></p><pre class="crayon-plain-tag">$ kubectl top nodes
NAME            CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
k3s-master      408m         20%    1156Mi          57%
k3s-worker-01   364m         18%    640Mi           32%
k3s-worker-02   399m         19%    797Mi           39%</pre><p></p>
<p style="text-align: justify;">L&rsquo;idée va être de laisser tourner un peu sans ces limites, voir le comportement (via ctop ou kube-capacity par exemple), et appliquer les limites raisonnables en conséquence. Dans le même état d&rsquo;esprit, des liveness/readiness ne seront pas de trop pour redémarrer automatiquement les services, pour l&rsquo;instant c&rsquo;est le désert.</p>
<p style="text-align: justify;">J&rsquo;ai déjà évoqué l’utilisation de Longhorn, reléguant le NFS aux seules sauvegardes. Justement je n&rsquo;ai absolument pas parlé de sauvegardes, ça sera peut-être l&rsquo;occasion de bosser sur Velero, histoire de sauvegarder le contenu des volumes car sauvegarder les VMs ne suffira peut-être pas à assurer le boulot. Il ne sera d&rsquo;ailleurs pas nécessairement utile de sauvegarder toutes les machines, au moins le master, les nodes pouvant être réinstallés/ajoutés à l&rsquo;envi via terraform/ansible.</p>
<p style="text-align: justify;">À l&rsquo;image du backup, il manque le déploiement d&rsquo;une forme de monitoring. C&rsquo;est d&rsquo;autant plus nécessaire qu&rsquo;on est justement dans un mode contraint de ressources, et comme je compte bien réinstaller Prometheus, pas dans le cluster lui-même mais sur un Raspberry Pi qui fera le travail dédié (avec celui de bastion certainement pour laisser toutes les ressources du serveur au cluster). Possible encore que je me base sur le travail de <a href="https://blog.stephane-robert.info/post/monitoring-kubernetes-k3s-prometheus-grafana/" target="_blank" rel="noopener">Stéphane Robert</a> qui a eu l&rsquo;amabilité de tout partager.</p>
<p style="text-align: justify;">Enfin, il sera l&rsquo;occasion de commencer à bosser sur de l&rsquo;intégration continue, dans la continuation de ma migration vers gitea, ce sera donc drone qui sera potentiellement amené dans le futur à déployer les mises à jour de mes services kube sur le cluster.</p>
<p style="text-align: justify;">En dehors du stockage, on parle donc d&rsquo;automatiser les choses un maximum, en bon feignant qui se respecte, mais le feignant va quand même devoir pas mal se retrousser les manches pour arriver au résultat voulu <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p style="text-align: justify;">Par contre, cela va devoir se faire dans une enveloppe de ressources plutôt compliquée à gérer, car en l&rsquo;état, voilà l&rsquo;état du cluster :</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2019/09/pimousse_resources.png" rel="lightbox[5962]"><img class="aligncenter size-medium wp-image-6381" src="https://blog.seboss666.info/wp-content/uploads/2019/09/pimousse_resources-300x99.png" alt="" width="300" height="99" srcset="https://blog.seboss666.info/wp-content/uploads/2019/09/pimousse_resources-300x99.png 300w, https://blog.seboss666.info/wp-content/uploads/2019/09/pimousse_resources-480x160.png 480w, https://blog.seboss666.info/wp-content/uploads/2019/09/pimousse_resources.png 762w" sizes="(max-width: 300px) 100vw, 300px" /></a>On le voit, c&rsquo;est serré, même sur le NAS qui participe au calcul du stockage. Il est temps que je rentre chez moi pour m&rsquo;occuper de tout ça <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<hr />
<p style="text-align: justify;"><strong>PS</strong> : On a pu le voir ici, je n&rsquo;ai pas eu à réinventer la roue, j&rsquo;ai pu grandement bénéficier du travail déjà effectué et surtout partagé par d&rsquo;autres, et je tiens encore à tous les remercier. Je n&rsquo;ai pas eu l&rsquo;occasion de beaucoup améliorer ou compléter leur travail, à part mes mésaventures avec Terraform sur le déploiement des VMs après la création du template que j&rsquo;ai remonté, et des échanges en direct avec Djerfy par rapport aux bricoles autour de Traefik. Cet article est donc aussi un témoignage de mon amour pour leur travail. Un jour peut-être je pourrais moi-même en faire plus.</p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/08/de-docker-swarm-a-kubernetes-avec-k3s/feed/</wfw:commentRss>
            <slash:comments>2</slash:comments>
        </item>
        <item>
            <title>Firefox pour Android : le renouveau, imparfait une fois de plus</title>
            <link>https://blog.seboss666.info/2020/08/firefox-pour-android-le-renouveau-imparfait-une-fois-de-plus/</link>
            <comments>https://blog.seboss666.info/2020/08/firefox-pour-android-le-renouveau-imparfait-une-fois-de-plus/#comments</comments>
            <pubDate>Fri, 21 Aug 2020 10:00:58 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Firefox]]></category>
            <category><![CDATA[android]]></category>
            <category><![CDATA[extensions]]></category>
            <category><![CDATA[limitations]]></category>
            <category><![CDATA[moteur]]></category>
            <category><![CDATA[quantum]]></category>
            <category><![CDATA[recherche]]></category>
            <category><![CDATA[refonte]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6354</guid>
            <description><![CDATA[Oui, un nouvel article sur le blog depuis plus d&#8217;un mois ! Et pour parler de Firefox, notre navigateur mobile préféré, mais pas pour le [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Oui, un nouvel article sur le blog depuis plus d&rsquo;un mois ! Et pour parler de Firefox, notre navigateur mobile préféré, mais pas pour le bureau, pour Android ! Cela fait plus d&rsquo;un an que Mozilla travaille à une refonte totale du butineur mobile, et pour l&rsquo;utiliser moi-même depuis plusieurs mois, il est temps de vous en parler, car il commence sa carrière « stable ».</p>
<p style="text-align: justify;"><span id="more-6354"></span></p>
<h3 style="text-align: justify;">Un vieux code poussif, consommateur de RAM</h3>
<p style="text-align: justify;">C&rsquo;est un fait, le Firefox pour Android actuel a toujours quelques avantages, avec notamment un support étendu des extensions, mais il n&rsquo;est pas réputé pour ses performances, sa réactivité, ou sa légèreté. C&rsquo;est un vrai gouffre à batterie qui en plus n&rsquo;offre plus aucun confort dans un monde mobile sous perfusion Chromesque, monde poussant les développeurs JavaScript à toujours plus de paresse dans l&rsquo;optimisation du poids de leurs horreurs.</p>
<p style="text-align: justify;">De plus, le code du navigateur lui-même n&rsquo;avait plus aucune marge de manœuvre pour corriger le tir, avec pour conséquence, une grosse stagnation dans le support des standards du web, même si on a pu le voir récemment <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1164187" target="_blank" rel="noopener">avec WebRTC</a>, il arrive parfois que Firefox traîne un peu (faire un VPN hébergé aux USA, c&rsquo;est tellement plus urgent&#8230;), sans parler que la consommation de mémoire déclenchait facilement la mise en veille du navigateur, ce qui fait toujours tâche quand ça se passe à un simple switch d&rsquo;application (genre on est sur son navigateur, on répond à un SMS, en revenant sur le navigateur il avait été déchargé car prenant trop de place&#8230;). Ce qui a poussé Mozilla à prendre la décision de repartir de zéro, gardant cette version stable en mode maintenance, ne corrigeant que le strict nécessaire en matière de sécurité et de stabilité. Stabilité étant probablement le maître mot, parce que j&rsquo;ai utilisé la version preview, puis beta, et c&rsquo;est pas toujours d&rsquo;une fiabilité remarquable, leur statut n&rsquo;est de toute façon pas prévu pour ça</p>
<p style="text-align: justify;">Comme je l&rsquo;ai dit, le support d&rsquo;extensions de toute sorte fait la force de Firefox mobile, mais malheureusement, certaines étant d&rsquo;abord conçues pour un ordinateur plus classique, l&rsquo;ergonomie et parfois la stabilité ne sont pas trop au rendez-vous. Pour ma part j&rsquo;ai le plus souvent limité mes usages mobiles à l&rsquo;ajout d&rsquo;un bloqueur de publicités, et là-dessus uBlock Origin ne déçoit pas. Ce support d&rsquo;extensions était donc un passage obligé du petit nouveau, avec quelques surprises à la clé.</p>
<h3 style="text-align: justify;">Here comes a new challenger, nouvelle architecure, chrome-like</h3>
<p style="text-align: justify;">Alors, il faut comprendre un peu comment fonctionne Android, et surtout certains de ses composants. Tout le monde connaît Chrome, le navigateur maison, avec Blink, son moteur de rendu. Mais il y a un « petit frère », car Android met à disposition des applications qui ont besoin d&rsquo;afficher du contenu web une version allégée du moteur, sous le nom de WebView (logique), qui suit les numérotations de Chrome dans la pratique. Certains développeurs peu inspirés reposent d&rsquo;ailleurs entièrement sur cette WebView pour faire leur « application », avec souvent un résultat peu amène pour l&rsquo;intégration native d&rsquo;Android. Je n&rsquo;exclus pas qu&rsquo;au final Chrome se base sur la WebView pour faire son taf de navigateur web, vous avez tout à fait le droit de me corriger si ce n&rsquo;est pas le cas.</p>
<p style="text-align: justify;">Et justement, le nouveau Firefox a choisi cette approche, en développant d&rsquo;un côté le moteur, appelé <a href="https://mozilla.github.io/geckoview/" target="_blank" rel="noopener">GeckoView</a>, qui se base en partie sur les technos développées pour Quantum, et destiné, à l&rsquo;instar de WebView, à pouvoir être exploité dans des applications tierces. Et de l&rsquo;autre, l&rsquo;interface qui exploite GeckoView. Ces choix ont permis de prioriser certains développements, performance en tête, pendant que d&rsquo;un autre côté, le développement de l&rsquo;interface pouvait se faire à un rythme différent.</p>
<h3 style="text-align: justify;">Des performances de ouf, des nouveautés bienvenues</h3>
<p style="text-align: justify;">C&rsquo;est le constat le plus flagrant selon moi : malgré un Android un peu trop agressif sur la gestion d&rsquo;applications et de la mémoire, le rechargement du navigateur et du ou des onglets courants est impressionnant, presque plus rapide que sur mon ordinateur portable à base de Core i5. C&rsquo;est bien simple, je ne vois plus aucun problème à revenir dessus, le seul souci serait d&rsquo;avoir un formulaire en cours de remplissage qui du coup serait dégommé, ce qui arrive très rarement (vu que j&rsquo;utilise l&rsquo;<a href="https://blog.seboss666.info/2015/02/lapplication-wordpress-pour-android-un-bon-moyen-de-demarrer-rapidement-un-article/" target="_blank" rel="noopener">application mobile wordpress</a> pour gérer les brouillons&#8230;).</p>
<p style="text-align: justify;">J&rsquo;ai pu également voir du mieux sur l&rsquo;affichage de certains sites qui ne sont pourtant pas mobile-friendly, sans avoir besoin de recourir au mode lecture. Globalement le support des standards récents, et notamment ceux liés au mobile, fait un sacré bon en avant et c&rsquo;est tant mieux.</p>
<p style="text-align: justify;">Les temps de chargement des pages même les plus lourdes sont incomparables, je n&rsquo;ai pas de chiffres à fournir en comparaison de Chrome Mobile, car comme sur « bureau » je le fuis comme la peste, mais comparé au vieux Firefox c&rsquo;est vraiment le jour et la nuit. C&rsquo;est bien simple, je n&rsquo;ai pas lancé l&rsquo;ancien Firefox depuis plusieurs mois, bien qu&rsquo;il soit toujours installé. Et pour cause, quand il faut pratiquement 10 secondes à froid pour qu&rsquo;il charge mon FreshRSS, ça devient éliminatoire.</p>
<p style="text-align: justify;">Du côté des autres nouveautés pour l&rsquo;instant, il parait qu&rsquo;on a droit au Picture-in-picture, que je n&rsquo;ai pas eu l&rsquo;occasion de tester, et le support des PWA. D&rsquo;un côté, j&rsquo;aime l&rsquo;idée de ne plus dépendre des stores fermés des dealers de plateforme mobiles que sont Android et iOS, d&rsquo;un autre, le fait de tout faire en JavaScript me donne toujours des envies de vomir vu la lourdeur toujours plus grande des frameworks et des applications en question. Pour rappel, PWA veut dire Progressive Web App, en clair, un application web, qui passe par le navigateur en temps normal, mais qu&rsquo;on « installe » comme une application mobile plus classique. Tous les inconvénients d&rsquo;un fonctionnement JavaScript dans un navigateur, sans les avantages d&rsquo;une application plus native avec ses performances et son optimisation à la plateforme cible. Je reproche déjà aux navigateurs web de bureau d&rsquo;être devenus des usines à gaz, et on reproduit exactement les mêmes erreurs sur mobile, à l&rsquo;heure ou l&rsquo;autonomie stagne effroyablement. Ce fonctionnement est justment rendu possible grâce à la GeckoView.</p>
<div id="attachment_6376" style="width: 152px" class="wp-caption aligncenter"><a href="https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_collections.jpg" rel="lightbox[6354]"><img class="size-medium wp-image-6376" src="https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_collections-142x300.jpg" alt="" width="142" height="300" srcset="https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_collections-142x300.jpg 142w, https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_collections-768x1621.jpg 768w, https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_collections-485x1024.jpg 485w, https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_collections.jpg 1080w" sizes="(max-width: 142px) 100vw, 142px" /></a><p class="wp-caption-text">Des groupes d&rsquo;onglets quoi</p></div>
<p style="text-align: justify;">Le reste est toujours d&rsquo;actualité, protections contre le pistage, synchronisation Firefox Sync, navigation privée. Comme le déploiement n&rsquo;est pas encore généralisé sur la version stable, je reste en beta, qui est un peu plus stable que la preview, mais je recommande quand même d&rsquo;attendre qu&rsquo;il soit plus naturellement poussé sur le canal stable pour l&rsquo;utiliser au quotidien, sauf si évidemment l&rsquo;aventure ne vous fait pas peur.</p>
<h3 style="text-align: justify;">Des problèmes de jeunesse, extensions en tête</h3>
<p style="text-align: justify;">Et ce n&rsquo;est pas pour rien : si le « phoenix » impressionne par ses performances, ce n&rsquo;est pas le cas de son interface : c&rsquo;est simple, c&rsquo;est beaucoup trop limité par rapport au Firefox « original », beaucoup moins de menus à disposition, et même la disparition regrettable du about:config, avec le faux prétexte qu&rsquo;un seul mauvais réglage peut faire définitivement planter le navigateur, alors que c&rsquo;était dispo depuis des années et que les critiques n&rsquo;étaient pas vraiment tournées vers ce genre de problème.</p>
<p style="text-align: justify;">J&rsquo;évoque les extensions, c&rsquo;est un autre gros gros manque potentiel, chaque release du navigateur vient avec une liste certes grandissante, mais très limitée d&rsquo;extensions validées pour fonctionner avec le nouveau moteur. On atteint même pas la dizaine actuellement, voici la liste :</p>
<ul style="text-align: justify;">
<li>uBlock Origin</li>
<li>Decentraleyes</li>
<li>Dark Reader</li>
<li>Privacy Badger</li>
<li>HTTPS Everywhere</li>
<li>Noscript Security Suite</li>
<li>Search by Image</li>
<li>Youtube HD</li>
<li>Privacy Possum</li>
</ul>
<p style="text-align: justify;">Certaines sont reconnues, indispensables, d&rsquo;autres sont plus ciblées voire élitistes dans le cadre de Noscript, mais avouez que ça fait sacrément chiche. Alors que j&rsquo;envisage de remplacer mon KeepassKC local par Bitwarden (via Bitwarden_rs, sur mon cluster k3s, teasing), il n&rsquo;y a pas d&rsquo;extension disponible pour le navigateur afin de remplir les champs automatiquement. C&rsquo;est plutôt frustrant, et je pense qu&rsquo;il y avait plus urgent que « Search by Image » par exemple pour rendre de suite le navigateur attractif. Et non, Mozilla a déjà mon historique et mes trop nombreux marque-pages stocké chez lui via Firefox Sync (parce qu&rsquo;on ne peut toujours pas installer de serveur Firefox Accounts en nodejs avec leur ersatz de documentation), pas question de stocker les identifiants chez eux. Et concernant le support futur des autres extensions, ben bon courage pour avoir des infos, manifestement personne ne sait, même pas les développeurs desdites extensions.</p>
<p style="text-align: justify;">En dehors de ça, j&rsquo;ai plusieurs réserves sur l&rsquo;interface principale, avec une dominante « violet sur noir » qui ne m&rsquo;inspire pas particulièrement. Ce n&rsquo;est pas foncièrement moche, ou très mal organisé, mais voilà, y&rsquo;a pas d&rsquo;effet wouahouh, j&rsquo;ai même du mal avec les options de nouvel onglet, avec un système de collections dont j&rsquo;ai vraiment beaucoup de mal à saisir l&rsquo;intérêt, quand ce qui m&rsquo;intéresse au « rechargement » c&rsquo;est d&rsquo;avoir à minima la liste des onglets ouverts pour rapidement basculer dessus. Et là encore, sans extensions pour corriger ça&#8230;</p>
<div id="attachment_6375" style="width: 152px" class="wp-caption aligncenter"><a href="https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_violet.jpg" rel="lightbox[6354]"><img class="size-medium wp-image-6375" src="https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_violet-142x300.jpg" alt="" width="142" height="300" srcset="https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_violet-142x300.jpg 142w, https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_violet-768x1621.jpg 768w, https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_violet-485x1024.jpg 485w, https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_violet.jpg 1080w" sizes="(max-width: 142px) 100vw, 142px" /></a><p class="wp-caption-text">Du violet partout&#8230;</p></div>
<p style="text-align: justify;">La gestion des moteurs de recherche a aussi vu un gros retour en arrière en termes d&rsquo;ergonomie. Bon certes j&rsquo;utilise encore Qwant qui est facilement disponible, mais pour ceux qui ne sont pas « inclus », il faut manuellement ajouter l&rsquo;url du champ de recherche. Alors que par le passé, sur un site présentant un champ de recherche, on pouvait rester appuyé sur le champ pour l&rsquo;ajouter directement à la liste des moteurs de recherche disponibles. Certes, 95% des lambdas continueront d&rsquo;utiliser Google, ce qui est désolant, mais avouez que ça ne semble pas compliqué de conserver un tel fonctionnement sur la nouvelle interface ?</p>
<div id="attachment_6377" style="width: 152px" class="wp-caption aligncenter"><a href="https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_search_hell.jpg" rel="lightbox[6354]"><img class="size-medium wp-image-6377" src="https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_search_hell-142x300.jpg" alt="" width="142" height="300" srcset="https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_search_hell-142x300.jpg 142w, https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_search_hell-768x1621.jpg 768w, https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_search_hell-485x1024.jpg 485w, https://blog.seboss666.info/wp-content/uploads/2020/08/firefox_android_search_hell.jpg 1080w" sizes="(max-width: 142px) 100vw, 142px" /></a><p class="wp-caption-text">Sérieux ? En 2020 ?</p></div>
<p style="text-align: justify;">Et parmi les bugs que je rencontre encore, si le téléchargement de fichiers est fonctionnel (oui ça n&rsquo;a pas toujours été le cas), l&rsquo;ouverture automatique dans l&rsquo;application idoine, ou l&rsquo;affichage des applications candidates à l&rsquo;ouverture d&rsquo;un fichier, pose toujours problème. J&rsquo;en viens à télécharger le fichier, et passer par l&rsquo;explorateur de fichiers, soit celui fourni par Huawei, soit via l&rsquo;interne de VLC quand il s&rsquo;agit de podcasts, encore faut-il connaître le chemin. La peinture est encore vraiment fraîche.</p>
<h3 style="text-align: justify;">C&rsquo;est de la bombe pour les usages légers</h3>
<p style="text-align: justify;">On le voit donc, ce « Firefox nouveau » n&rsquo;a probablement pas un goût de banane, mais ses performances font sourire et dans le bon sens du terme. Cela s&rsquo;est cependant traduit par une finition très inégale, une couverture fonctionnelle très imparfaite, et il reste beaucoup de chemin à parcourir. C&rsquo;est plutôt étrange de voir Mozilla rusher la sortie, quand bien même la stabilité est au rendez-vous pour le canal stable (c&rsquo;est peu l&rsquo;objectif de son nom), avec des conséquences plus importantes peut-être que pour la transition Quantum pour les versions de bureau, qui ont pu se faire de manière beaucoup plus graduelles.</p>
<p style="text-align: justify;">Maintenant on peut comprendre Mozilla : l&rsquo;ancienne version est un boulet qu&rsquo;ils se traînent depuis un peu trop longtemps, et avec les récentes annonces sur <a href="https://www.nextinpact.com/article/43368/mozilla-licencie-250-personnes-quete-rentabilite-au-premier-plan" target="_blank" rel="noopener">les restrictions de personnel</a> qui se profilent, il est essentiel de se débarrasser des versions obsolètes pour n&rsquo;avoir que l&rsquo;essentiel, un navigateur mobile paré pour le futur, un futur qu&rsquo;il doit rattraper rapidement.</p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/08/firefox-pour-android-le-renouveau-imparfait-une-fois-de-plus/feed/</wfw:commentRss>
            <slash:comments>10</slash:comments>
        </item>
        <item>
            <title>DroidCam : c&#8217;est cool, mais ça pourrait être bien mieux</title>
            <link>https://blog.seboss666.info/2020/06/droidcam-cest-cool-mais-ca-pourrait-etre-bien-mieux/</link>
            <comments>https://blog.seboss666.info/2020/06/droidcam-cest-cool-mais-ca-pourrait-etre-bien-mieux/#respond</comments>
            <pubDate>Sat, 13 Jun 2020 09:01:05 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Astuces]]></category>
            <category><![CDATA[android]]></category>
            <category><![CDATA[laptop]]></category>
            <category><![CDATA[linux]]></category>
            <category><![CDATA[qualité]]></category>
            <category><![CDATA[smartphone]]></category>
            <category><![CDATA[webcam]]></category>
            <category><![CDATA[windows]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6324</guid>
            <description><![CDATA[Avec le confinement, il se trouve que je n&#8217;ai pas pu voir ma sœur depuis le nouvel an. Idem pour ma mère, qui de son [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Avec le confinement, il se trouve que je n&rsquo;ai pas pu voir ma sœur depuis le nouvel an. Idem pour ma mère, qui de son côté s&rsquo;est flingué le dos. Pour organiser une visioconférence de « consolation », j&rsquo;ai redécouvert à quel point les webcam integrées dans les laptop sont affreuses. Et si on tentait le smartphone en guise de remplaçant ?</p>
<p style="text-align: justify;"><span id="more-6324"></span></p>
<p style="text-align: justify;">Il n&rsquo;y a qu&rsquo;à voir les rageux fans d&rsquo;Apple gueuler sur la qualité médiocre (c&rsquo;est même pire que ça : <a href="https://www.macg.co/mac/2020/05/webcam-mediocre-sur-les-macbook-quelles-solutions-la-place-113867" target="_blank" rel="noopener">c&rsquo;est moins bon qu&rsquo;avant</a>) de la cam intégrée aux derniers macbook pro qui coutent deux smic pour comprendre le problème : même chez Apple qui fait rarement dans le compromis, un composant pourtant peu onéreux par rapport au reste de la machine se retrouve être juste honteux. Apple, qui vante les qualités de son application Facetime, qui utilise une source vidéo affreuse, ça fait tâche dans le tableau.</p>
<p style="text-align: justify;">Mais il ne faut pas croire que le problème est spécifique à la marque à la pomme, sans vouloir aller jusqu&rsquo;à des webcam 4k60fps intégrées (on a pas souvent les réseaux pour envoyer une telle image, sans parler de la décoder à l&rsquo;autre bout de la « ligne »), la différence flagrante de la qualité des webcams comparées aux évolutions constantes année après année des capteurs de smartphone me rend perplexe, à croire qu&rsquo;on ne peut pas capitaliser sur ces évolutions. Je suis de près l&rsquo;apparition des modèles de laptop qui sortent avec une plateforme Ryzen 4000 (partie CPU de Ryzen 3000 et GPU Vega en 7nm), et le constat est le même à chaque fois : quelque soit la cible de l&rsquo;appareil, la webcam est au maximum en 720p 30fps, ce qui est désormais limite en 2020. Je demande pas la lune, mais avoir au moins du fullHD avec en bonus, sur les hauts de gamme, du 60FPS, me parait loin d&rsquo;être impossible ni trop cher en 2020, non ?</p>
<p style="text-align: justify;">Arrive quand même l&rsquo;horreur : la webcam du PC de ma mère. Un modèle 17&Prime; Asus à base de Core i3 4000m d&rsquo;il y a donc six ans, fourni avec Windows 8.1, dont la webcam est sobrement intitulée « USB Camera ». Le mieux que j&rsquo;ai pu apprendre est qu&rsquo;elle est fabriquée par Realtek, mais je n&rsquo;ai rien trouvé d&rsquo;autre comme référence ni pilote, car c&rsquo;est celui de Microsoft qui est utilisé, et qui date de&#8230; 2006. Vous la sentez la merde ?</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2020/06/droidcam_integrated_pc_webcam.jpg" rel="lightbox[6324]"><img class="aligncenter size-medium wp-image-6333" src="https://blog.seboss666.info/wp-content/uploads/2020/06/droidcam_integrated_pc_webcam-300x145.jpg" alt="" width="300" height="145" srcset="https://blog.seboss666.info/wp-content/uploads/2020/06/droidcam_integrated_pc_webcam-300x145.jpg 300w, https://blog.seboss666.info/wp-content/uploads/2020/06/droidcam_integrated_pc_webcam.jpg 687w" sizes="(max-width: 300px) 100vw, 300px" /></a></p>
<p style="text-align: justify;">Voilà, et encore, c&rsquo;est une image fixe, en 640&#215;480 donc, la résolution que j&rsquo;utilisais pour mon écran en 2002. Et je vous épargne la photo le soir avec 4 fois moins de lumière. Dans la pratique en vidéo si on arrive à obtenir 10 images par seconde c&rsquo;est tout le bout du monde. Alors imaginez quand un Skype vous étire ça sur l&rsquo;intégralité de votre écran 16 pouces (celui de ma sœur), ça donne quelque chose de tellement immonde que je renonce à vous l&rsquo;afficher, pour préserver votre santé mentale et visuelle.</p>
<h3 style="text-align: justify;">Le smartphone en remplacement ?</h3>
<p style="text-align: justify;">J&rsquo;avais déjà eu cette idée dans le passé, sans avoir été au bout de la démarche en cherchant et en testant, mais avec l&rsquo;idée de la comparaison naturelle entre la qualité d&rsquo;image des smartphones même d&rsquo;entrée de gamme (en gros, pour le prix d&rsquo;une Logitech StreamCam, on a un smartphone 4G complet avec un écran de 6&Prime;&#8230;),  cette expérimentation a naturellement refait surface. Entre le débit d&rsquo;image, la résolution, la gestion de la lumière bien plus optimale, les possibilités éventuelles sur le zoom et j&rsquo;en passe, bref, c&rsquo;est une aventure qui se tente.</p>
<p style="text-align: justify;">J&rsquo;ai donc eu l&rsquo;occasion de faire le test sur deux ordiphones différents : mon Huawei P20 Lite dont il est prévu que je vous donne des nouvelles pour ses deux ans, et le Huawei Y5 version 2019. Mais tout smartphone Android un peu récent fera l&rsquo;affaire, pour peu qu&rsquo;il ait un peu de patate quand même, parce qu&rsquo;on a vu la différence entre les deux déjà, on va le voir.</p>
<h3 style="text-align: justify;">DroidCam, l&rsquo;application de référence</h3>
<p style="text-align: justify;">Malgré son nom, DroidCam est techniquement disponible sur Android et iOS, et les applications PC Windows ET Linux sont également de la partie. Oui oui, aussi pour Linux, mais j&rsquo;ai eu l&rsquo;occasion de faire le test d&rsquo;abord sur Windows, comme ça pas de jaloux.</p>
<p style="text-align: justify;">Pour rappel, l&rsquo;application fonctionne en deux parties : la partie installée sur mobile capture l&rsquo;image du téléphone et crée un « serveur vidéo », qu&rsquo;on peut ensuite soit consulter directement dans un navigateur (on a que l&rsquo;image), soit contacter via l&rsquo;appli client sur PC qui va créer une webcam virtuelle pour y transmettre le flux récupéré sur le téléphone. On peut aussi capturer le son du smartphone, mais pour avoir tenté de faire un comparatif, la qualité du micro ambiant du smartphone n&rsquo;est pas forcément plus agréable que le micro intégré du laptop, et on est toujours à des années lumière des micro-casques donc&#8230; Deux modes de fonctionnement sont possibles, le premier simple via le wifi/réseau local, le deuxième via USB qui demande un peu plus de manipulations que je n&rsquo;ai pas testé.</p>
<p style="text-align: justify;">Premier constat : les devs sont bons, les applications aussi bien mobiles que PC sont simples et très fonctionnelles. Par contre, leur site web <a href="http://www.dev47apps.com/" target="_blank" rel="noopener">c&rsquo;est de la merde en barre</a> : aucun menu de navigation, ni de moteur de recherche, on doit sauter de page en page pour tenter de trouver nos informations (j&rsquo;en ai surtout eu besoin pour la partie Linux, j&rsquo;y reviendrai). On se croirait revenu sur un de mes premiers essais de site web en 1998 en cours d&rsquo;informatique en seconde.</p>
<p style="text-align: justify;">Deuxième constat : l&rsquo;application mobile existe en deux versions, une « gratuite » et une payante. Je mets gratuite entre guillemets parce qu&rsquo;on sait que désormais, l&rsquo;affichage de publicité n&rsquo;a rien d&rsquo;innocent et désintéressé dans l&rsquo;univers Google et du Web en général. Pire, et là c&rsquo;est vraiment gonflé de leur part, <a href="https://www.dev47apps.com/droidcam/hd-mode/" target="_blank" rel="noopener">la résolution du flux vidéo du smartphone est limitée</a>, dans la version gratuite, à 640&#215;480. On garde les autres avantages comme la gestion de la lumière et la fluidité relative à la puissance du smartphone, mais merde, on est plus en 2002. La version payante propose en plus une tétrachiée d&rsquo;options supplémentaires qui permettent de contrôler plusieurs éléments du smartphone directement depuis l&rsquo;appli, comme le zoom, l&rsquo;autofocus, la balance des blancs, l&rsquo;allumage du flash, etc, mais ils auraient au moins pu amener le 720p par défaut quoi !</p>
<h3 style="text-align: justify;">Usage sous Windows, avec le laptop de ma mère</h3>
<p style="text-align: justify;">Comme je l&rsquo;ai évoqué, l&rsquo;application est simple, efficace, s&rsquo;installe sans pourrir votre PC. On aimerait voir des freeware comme ça plus respectueux de nos machines en 2020 ! L&rsquo;interface est simple, on lance, on saisit l&rsquo;adresse IP du téléphone (et le port si on s&rsquo;est amusé à le changer), et une seconde après on a l&rsquo;image qui doit s&rsquo;afficher, sauf si on a laissé le téléphone sur la table évidemment <img src="https://s.w.org/images/core/emoji/11/72x72/1f600.png" alt="😀" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Mais il suffit dès lors de cadrer l&rsquo;image qu&rsquo;on souhaite partager. En fonction des téléphones et de l&rsquo;usage final, on peut poser le « capteur » contre l&rsquo;écran , ça masquera une petite partie de celui-ci mais si on n&rsquo;a rien à manipuler en paralèlle, ça peut le faire.</p>
<p style="text-align: justify;">Ensuite sous Skype, on sélectionne la webcam « DroidCam » et on constate le résultat :</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2020/06/droidcam_smartphone_webcam.jpg" rel="lightbox[6324]"><img class="aligncenter size-medium wp-image-6334" src="https://blog.seboss666.info/wp-content/uploads/2020/06/droidcam_smartphone_webcam-300x145.jpg" alt="" width="300" height="145" srcset="https://blog.seboss666.info/wp-content/uploads/2020/06/droidcam_smartphone_webcam-300x145.jpg 300w, https://blog.seboss666.info/wp-content/uploads/2020/06/droidcam_smartphone_webcam.jpg 666w" sizes="(max-width: 300px) 100vw, 300px" /></a>On a la même résolution, mais on est à des années lumière en termes de qualité et de fluidité. Ma sœur me l&rsquo;a fait remarquer quand on s&rsquo;est amusé à faire un comparatif entre les deux <img src="https://s.w.org/images/core/emoji/11/72x72/1f600.png" alt="😀" class="wp-smiley" style="height: 1em; max-height: 1em;" /> En clair, solution validée, même pour ma maman quand elle se retrouvera autonome pour ça.</p>
<h3 style="text-align: justify;">Usage sous Linux, laptop pro et perso (c&rsquo;est pareil)</h3>
<p style="text-align: justify;">Pareil parce que les deux sont sous Manjaro, la seule différence c&rsquo;est que sur le PC du boulot je suis resté en noyau 4.19, alors que sur mon perso c&rsquo;est du noyau 5.4. Oui, que du LTS. Je vous expliquerai probablement pourquoi sur le laptop du boulot j&rsquo;ai du revenir au 4.19 en 2020, c&rsquo;est marrant aussi. Enfin dans les deux cas, j&rsquo;ai pu faire fonctionner le système sans trop de problèmes, mais évidemment, ça n&rsquo;a pas été aussi fluide que sous Windows. L&rsquo;installation aucun souci, <a href="https://aur.archlinux.org/packages/droidcam" target="_blank" rel="noopener">via AUR</a> c&rsquo;est d&rsquo;une simplicité absolue. Mais la suite&#8230;</p>
<p style="text-align: justify;">D&rsquo;abord, le module noyau v4l2loopback-dc qui permet de créer la webcam virtuelle n&rsquo;est pas chargé par défaut, il faut manuellement « modprober » ce qui se fait en mode administrateur. On a vu plus souple, le point positif c&rsquo;est que le module est fourni via <a href="https://fr.wikipedia.org/wiki/Dynamic_Kernel_Module_Support" target="_blank" rel="noopener">DKMS</a> il est donc mis à jour proprement en cas d&rsquo;update noyau. Et c&rsquo;est là en fait que j&rsquo;ai découvert la limitation de la résolution, le module crée par défaut une webcam en 640&#215;480, même si le flux est en résolution supérieure. Il faut aller modifier, toujours en mode administrateur, le fichier de configuration du module pour changer les paramètres (pensez à créer le fichier chez vous s&rsquo;il n&rsquo;existe pas déjà) :</p>
<p></p><pre class="crayon-plain-tag">#cat /etc/modprobe.d/v4l2loopback-dc.conf
options v4l2loopback_dc width=960 height=720</pre><p></p>
<p style="text-align: justify;">Ensuite décharger le module (modprobe -r), et le recharger, parce qu&rsquo;évidemment les paramètres ne sont pas pris à chaud. Et attention, si on met une sortie qui n&rsquo;est pas dans le même format que la source, l&rsquo;image est déformée. Dans mon cas j&rsquo;ai quand même poussé jusqu&rsquo;à 720p, ça étire un peu le flux d&rsquo;origine mais comme je garde le ratio, c&rsquo;est moins dégueulasse. On constate quand même une légère augmentation du bruit visible en faible luminosité.</p>
<p style="text-align: justify;">Ensuite, la gestion du son est encore à part et vu les manipulations de la documentation j&rsquo;ai abandonné direct. On parle de module Alsa, qui reste semble-t-il toujours aux commandes alors qu&rsquo;on manipule pulseaudio au quotidien, donc j&rsquo;ai du mal à comprendre comment ça fonctionne. 2020, et la gestion du son sous Linux a encore 20 ans de retard sur Windows, et on se demande pourquoi Linux ne s&rsquo;impose toujours pas&#8230;</p>
<p style="text-align: justify;">Enfin, une fois la partie « bas niveau » en place, on peut lancer l&rsquo;application qui a exactement la même tête que sous Windows, donc adresse IP à saisir, et ensuite, on sélectionne la caméra dans Skype/Teams. La bonne surprise cependant, c&rsquo;est que là où dans l&rsquo;application Windows on me dit que les contrôles sont réservés à la version DroidCamX (donc payante), sous Linux je peux contrôler le zoom, l&rsquo;autofocus et le flash  <img src="https://s.w.org/images/core/emoji/11/72x72/1f600.png" alt="😀" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Sur le laptop boulot on a donc une webcam avec la même résolution, mais l&rsquo;ouverture est plus large, l&rsquo;image plus fine et lumineuse et la fluidité un peu meilleure. Sur le laptop perso, la webcam fait déjà du 720p avec une gestion relativement propre de la lumière, la fluidité n&rsquo;est pas parfaite mais ça peut suffire pour des petites visio-conférences. Y&rsquo;a quand même du bruit donc faut pas être exigeant sur la qualité de l&rsquo;image.</p>
<h3 style="text-align: justify;">L&rsquo;alternative qui n&rsquo;a pas fonctionné pour moi</h3>
<p style="text-align: justify;">J&rsquo;ai cherché à voir si une option permettant une meilleure qualité sans devoir balancer sa carte bancaire à Google existait. Il semblerait, elle s&rsquo;appelle Iriun Webcam, dont le fonctionnement est siimilaire à savoir appli mobile+appli desktop. Il permet d&rsquo;exploiter la 4K si le téléphone le permet, mais de mon côté, j&rsquo;ai rencontré beaucoup de problèmes. Déjà, l&rsquo;installation avec <a href="https://aur.archlinux.org/packages/iriunwebcam-bin" target="_blank" rel="noopener">le paquet AUR</a> déconne parce que le md5 de l&rsquo;archive téléchargée par le script d&rsquo;installation n&rsquo;est pas le même. Les développeurs n&rsquo;ont pas spécialement envie de penser qu&rsquo;on est sur PC et qu&rsquo;on a besoin de contrôles de versions, donc j&rsquo;ai tenté l&rsquo;installation à la main (on clone le dépot AUR, on modifie le PKGBUILD, et makepkg -si dans la foulée). Mais une fois v4l2loobpack manuellement chargé au niveau du noyau (module officiel pour faire une webcam virtuelle) et le logiciel lancé, ben écran noir sur la capture, pourtant le smartphone indique bien que la connexion est établie. Aussi, le flux semble coupé très très régulièrement, du coup, au bout d&rsquo;un quart d&rsquo;heure de manipulations sans résultat, j&rsquo;ai lâché l&rsquo;affaire.</p>
<p style="text-align: justify;">Je ne l&rsquo;ai pas testé non plus sous Windows, si vous avez expérimenté avec hésitez pas à partager, à ce moment de l&rsquo;histoire j&rsquo;ai décidé que j&rsquo;avais autre chose à faire que de débugger des applis qui ne me donnent déjà pas beaucoup d&rsquo;infos sur leur fonctionnement.</p>
<h3 style="text-align: justify;">Ça manque cruellement d&rsquo;open-source</h3>
<p style="text-align: justify;">Car oui, tous les éléments testés ici ne sont pas open-source. Et c&rsquo;est un vrai problème des deux côtés, aussi bien au niveau du smartphone où l&rsquo;on dépend du store fermé de Google ou d&rsquo;Apple, que du côté du PC où l&rsquo;on ne peut pas forcément s&rsquo;assurer que l&rsquo;application n&rsquo;en fait pas un peu trop, pour un logiciel qui a accès à la webcam. Sur Linux, comme ça dépend d&rsquo;un module noyau (modifié dans le cas de DroidCam), c&rsquo;est un peu tendu pour s&rsquo;assurer du suivi du bon support lors des montées de version (même si globalement l&rsquo;infrastructure v4l2 est assez stable).</p>
<p style="text-align: justify;">Il y a bien eu une application appelée <a href="https://sourceforge.net/projects/smartcam/files/" target="_blank" rel="noopener">SmartCam</a>, dont les fichiers sont toujours disponibles, mais elle n&rsquo;a pas été mise à jour depuis 2013 voire plus vieux encore pour certains, et autant dire que ça commence à faire vraiment trop dans le monde de l&rsquo;informatique.</p>
<p style="text-align: justify;">En attendant, et vu la qualité du résultat même avec une résolution décevante avec la version gratuite, vous avez une solution de rechange pour les webcam intégrées aux laptop, ou pour votre PC de bureau. Y&rsquo;a juste un truc que j&rsquo;ai pas vraiment abordé : le fait qu&rsquo;il faut poser le téléphone dans une position pas trop désavantageuse pour votre visage <img src="https://s.w.org/images/core/emoji/11/72x72/1f600.png" alt="😀" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p style="text-align: justify;"><strong>PS</strong> : c&rsquo;est évident pour certains, mais je rappelle que si vous êtes moche comme moi à la base, une bonne webcam ou un bon smartphone n&rsquo;y changera rien. On verra juste mieux à quel point vous êtes moche <img src="https://s.w.org/images/core/emoji/11/72x72/1f600.png" alt="😀" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/06/droidcam-cest-cool-mais-ca-pourrait-etre-bien-mieux/feed/</wfw:commentRss>
            <slash:comments>0</slash:comments>
        </item>
        <item>
            <title>Un peu d&#8217;amour pour le blog (et la VM en général)</title>
            <link>https://blog.seboss666.info/2020/06/un-peu-damour-pour-le-blog-et-la-vm-en-general/</link>
            <pubDate>Tue, 02 Jun 2020 16:30:09 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Editos]]></category>
            <category><![CDATA[conflit]]></category>
            <category><![CDATA[debian]]></category>
            <category><![CDATA[dette]]></category>
            <category><![CDATA[ménage]]></category>
            <category><![CDATA[php]]></category>
            <category><![CDATA[rationalisation]]></category>
            <category><![CDATA[sources]]></category>
            <category><![CDATA[versions]]></category>
            <category><![CDATA[wordpress]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6303</guid>
            <description><![CDATA[Vous connaissez l&#8217;adage qui dit que les cordonniers sont les plus mal chaussés ? Dans mon cas c&#8217;était incroyablement vrai, ma procrastination sur la maintenance [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Vous connaissez l&rsquo;adage qui dit que les cordonniers sont les plus mal chaussés ? Dans mon cas c&rsquo;était incroyablement vrai, ma procrastination sur la maintenance de tout ça étant incroyablement puissante. J&rsquo;ai quand même fini par me mettre à la tâche, et j&rsquo;ai décidé de détailler pour que l&rsquo;on comprenne bien le problème afin d&rsquo;éviter de le reproduire.</p>
<p style="text-align: justify;"><span id="more-6303"></span></p>
<h3 style="text-align: justify;">Le champ de bataille</h3>
<p style="text-align: justify;">Nous sommes donc sur une VM bloquée en Debian 8, avec les installations notables suivantes :</p>
<ul style="text-align: justify;">
<li>PHP 5.6 des dépots Jessie pour les scripts legacy</li>
<li>PHP 7.0 des dépots <a href="https://www.dotdeb.org/instructions/" target="_blank" rel="noopener">Dotdeb</a> (la référence de l&rsquo;époque quand je l&rsquo;ai installé)</li>
<li>PHP 7.3 des dépots <a href="https://deb.sury.org/" target="_blank" rel="noopener">Sury</a>, d&rsquo;abord pour Matomo dont les dernières versions commandaient un PHP supporté.</li>
<li>Redis de dépot Dotdeb</li>
<li>nginx-http2 du dépot dédié Dotdeb</li>
</ul>
<p style="text-align: justify;">Et surtout, d&rsquo;anciennes traces d&rsquo;installation d&rsquo;<a href="https://www.ispconfig.org/" target="_blank" rel="noopener">ISPConfig</a>, qu&rsquo;on se traîne encore comme un boulet parfois sans savoir pourquoi on a des soucis. On le voit, je ne suis pas vraiment mon propre conseil d&rsquo;essayer de limiter les sources externes de paquets, mais avec le temps et l&rsquo;âge d&rsquo;une Debian, proposer des technos récentes (PHP7+ et HTTP2 entre autres), c&rsquo;est compliqué. Pareil pour les montées de versions qui sont compliquées par les opérations passées et l&rsquo;activité des scripts.</p>
<div id="attachment_6308" style="width: 310px" class="wp-caption aligncenter"><a href="https://blog.seboss666.info/wp-content/uploads/2020/06/sac_de_noeuds.jpg" rel="lightbox[6303]"><img class="size-medium wp-image-6308" src="https://blog.seboss666.info/wp-content/uploads/2020/06/sac_de_noeuds-300x225.jpg" alt="" width="300" height="225" srcset="https://blog.seboss666.info/wp-content/uploads/2020/06/sac_de_noeuds-300x225.jpg 300w, https://blog.seboss666.info/wp-content/uploads/2020/06/sac_de_noeuds.jpg 500w" sizes="(max-width: 300px) 100vw, 300px" /></a><p class="wp-caption-text">Installation de la VM, allégorie</p></div>
<p style="text-align: justify;">De cette installation, j&rsquo;en ai tiré notamment un conflit à l&rsquo;installation du module Redis sur PHP 7.3 à cause du nom du package qui bute avec les fichiers de celui de php 7.0 de Dotdeb. J&rsquo;avais pas fait attention quand j&rsquo;avais installé PHP 7.3 en ce mois de Janvier, et j&rsquo;avais du coup perdu deux mois de visites sur Matomo (c&rsquo;est lui qui demandait PHP 7.3 pour ses mises à jour), parce que le plugin Queued Tracking qui stocke les visites dans Redis avant enregistrement définitif renvoyait une erreur 500 parce que les commandes Redis n&rsquo;existent pas. Et comme l&rsquo;interface fonctionnait au moment où j&rsquo;ai basculé, j&rsquo;ai pas percuté. Oui, je suis un boulet.</p>
<h3 style="text-align: justify;">Travail préparatoire</h3>
<p style="text-align: justify;">L&rsquo;intervention a donc d&rsquo;abord été l&rsquo;occasion d&rsquo;un gros gros inventaire et surtout d&rsquo;un nettoyage de scripts inutiles, de vhosts inexistants et non fonctionnels, de pools php qui vont avec ou orphelins (vhosts nettoyés mais php toujours là), bref, les confs PHP et Nginx sont beaucoup plus claires sur ce qui est réellement en activité sur le serveur.</p>
<p style="text-align: justify;">J&rsquo;en ai également profité pour procéder à un déménagement de certains vhosts annexes sur PHP 7.3, comme mon FreshRSS qui me remercie grandement. Au passage, au fur et à mesure je rend agnostique le chemin du socket, ça permet de changer facilement de version sans avoir à bidouiller plusieurs fichiers. Là, je déplace le fichier de conf du pool d&rsquo;une version de PHP à l&rsquo;autre, je redémarre celui qui ne sert plus, je redémarre celui qui servira, je teste. Le retour arrière est à peu près aussi rapide.</p>
<p style="text-align: justify;">Ça a aussi permis de virer quelques packages, et j&rsquo;ai été surpris, parce qu&rsquo;en fait, PHP 5.6 n&rsquo;était plus utilisé ni démarré, il a donc fini à la poubelle. Autre découverte, apache2 est également toujours installé !? Il a rejoint PHP 5.6. J&rsquo;ai potentiellement viré un ou deux autres trucs découverts par hasard, mais pas forcément en lien direct avec le bordel du jour.</p>
<h3 style="text-align: justify;">On attaque la butte</h3>
<p style="text-align: justify;">Ce coup-ci, on rendre dans le dur. Je commence par réactiver les dépôts Sury pour tenter de mettre à jour les paquets PHP 7.0 de Dotdeb vers PHP 7.0 Sury. L&rsquo;opération a pris du temps, mais s&rsquo;est bien terminée, modulo quelques paquets restants. En effet, ils n&rsquo;ont pas le même nom chez Sury. Je les supprime donc (paquets liés au module redis) et je réinstalle la version Sury. Et ça s&rsquo;est super bien passé !</p>
<p style="text-align: justify;">Il restait quelques éléments à supprimer pour être définitivement tranquille. Le méta-paquet « php » va installer la dernière révision de PHP en date, soit PHP 7.4. Et désormais, je n&rsquo;ai plus de conflit à l&rsquo;installation de paquets PHP 7.x. Au passage, il y a des différences entre PHP 7.0 et php 7.3, mais dans certains cas ils sont juste inutiles donc pas la peine de les installer. D&rsquo;autres n&rsquo;existent plus comme mcrypt, on va voir juste après la conséquence.</p>
<h3 style="text-align: justify;">Ce que le nettoyage a permis</h3>
<p style="text-align: justify;">J&rsquo;ai pu réinstaller le QueuedTracking de Matomo, qui permet un gain de temps substantiel dans le chargement de la page puisque la visite est enregistrée dans Redis avant d&rsquo;être traitée et enregistrée dans la base de données en arrière-plan par Matomo. Moins d&rsquo;attente dans le chargement d&rsquo;une page de votre côté, et comme de toute façon je suis pas à la seconde pour la traçabilité, ça peut prendre le temps que ça veut pour enregistrer (ou pas, en fonction des détails envoyés comme le DNT).</p>
<p style="text-align: justify;">J&rsquo;ai aussi profité pour virer le dépot Dotdeb pour m&rsquo;assurer que je ne risquais pas d&rsquo;installer quelque chose qui provient de chez eux. Il ne reste que celui dédié à Nginx qui n&rsquo;a de toute façon pas été mis à jour depuis un moment (oui je sais&#8230;), mais comme il ne contient pas de paquets PHP c&rsquo;est pas grave. J&rsquo;ai d&rsquo;ailleurs fait le ménage sur deux/trois autres dépôts qui ne servent plus et qui pour certains étaient déjà désactivés. Moins de dépôts activés, veut dire mises à jour et installations qui prennent moins de temps.</p>
<p style="text-align: justify;">Une seule source de PHP, plus de conflit (je crois que je l&rsquo;ai déjà dit), veut dire aussi passage à de futures versions facilité, ou presque. En effet, en fonction de l&rsquo;âge des scripts/applications installées, ça peut se vautrer dans les grandes largeurs avec une version qui supprime une ou plusieurs fonctions qui servent à ceux-ci. et dans mon cas, mon WordPress va encore avoir besoin d&rsquo;un peu d&rsquo;amour pour tenter une grosse montée de version avant de pouvoir bénéficier d&rsquo;une montée de version de PHP (et quand je vois le gain sur FreshRSS, ça fait plus qu&rsquo;envie). J&rsquo;ai quand même tenté l&rsquo;upgrade vers PHP 7.2, pour l&rsquo;instant je ne constate pas d&rsquo;erreur, malgré l&rsquo;âge de certains éléments (plugins pas maintenus entre autres). Il faudra quand même que je termine cette satanée migration vers WordPress 5 pour m&rsquo;assurer de ne plus avoir de problème et pouvoir continuer les migrations.</p>
<div id="attachment_6309" style="width: 310px" class="wp-caption aligncenter"><a href="https://blog.seboss666.info/wp-content/uploads/2020/06/monsieur-propre.jpg" rel="lightbox[6303]"><img class="size-medium wp-image-6309" src="https://blog.seboss666.info/wp-content/uploads/2020/06/monsieur-propre-300x166.jpg" alt="" width="300" height="166" srcset="https://blog.seboss666.info/wp-content/uploads/2020/06/monsieur-propre-300x166.jpg 300w, https://blog.seboss666.info/wp-content/uploads/2020/06/monsieur-propre.jpg 500w" sizes="(max-width: 300px) 100vw, 300px" /></a><p class="wp-caption-text">moi à la fin de l&rsquo;après-midi</p></div>
<p style="text-align: justify;">J&rsquo;étais chaud du coup j&rsquo;ai procédé un peu pareil sur le VPS qui porte l&rsquo;installation de LibreNMS. ce VPS avait déjà subi une sale montée de version de Debian à l&rsquo;arrache, OVH avait eu la très mauvaise idée de juste laisser « stable » dans la configuration des dépots, mais comme je ne fais pas de dist-upgrade en auto, ça s&rsquo;était fini en simili Debian 9 avec des dépendances et le noyau de Debian 8. Là encore, j&rsquo;avais le PHP 5.6 de Debian 8 encore installé sur Debian 9, alors qu&rsquo;il ne servait plus à rien.</p>
<h3 style="text-align: justify;">Le nécessaire déménagement</h3>
<p style="text-align: justify;">Je me suis concentré aujourd&rsquo;hui sur les problèmes liés à PHP et au blog (tiens au passage, le récent problème lié à <a href="https://wordpress.org/support/topic/update-1-11-13-broke-the-site/" target="_blank" rel="noopener">Broken Link Checker</a> a été compliqué à régler, mais c&rsquo;est fait). Mais on l&rsquo;a vu, il reste des horreurs comme le nginx custom, et la VM, avec son âge, a plusieurs autres tares, dont ces fameux relents d&rsquo;ISPConfig. Faire la montée de version en place ne m&rsquo;intéresse pas et causerait certainement plus de problème qu&rsquo;elle n&rsquo;en résoudrait, il est temps de mettre l&rsquo;installation à la retraite pour repartir sur du neuf, un peu comme un gros ménage de printemps ne remplace pas un déménagement dans l&rsquo;efficacité à virer les choses accumulées depuis des années.</p>
<p style="text-align: justify;">Et ça fait partie des choses que je préparais pour le futur proche, mais c&rsquo;était dans l&rsquo;optique d&rsquo;un certain budget allouable qui ne sera pas possible cette année (merci SARS-Cov-2). J&rsquo;ai donc des plans à revoir pour quand même avancer sur le sujet sans me faire trop mal au porte-monnaie, en attendant, je suis content du résultat des travaux.</p>
<p style="text-align: justify;"><strong>PS</strong> : j&rsquo;avais prévenu sur Twitter que « <a href="https://twitter.com/Seboss666/status/1267389606330339329" target="_blank" rel="noopener">ça va couper chérie</a> » le temps que je bosse dessus. On m&rsquo;a demandé pourquoi j&rsquo;ai pas bossé sur une seconde VM à côté et basculé une fois terminé. Déjà parce qu&rsquo;il y a pas mal de choses sur cette VM, et pas seulement le blog : autres sites, serveurs de discussion vocales, etc. Ensuite, la configuration réseau n&rsquo;a jamais été pensée pour permettre ce genre de bascule simple, la machine est directement exposée avec son IP publique, sans pare-feu ni reverse-proxy devant, pas de Docker, pas de pare-feu autre que celui du noyal. Donc j&rsquo;ai bossé « en live », ce qui n&rsquo;était pas plus mal pour permettre de découvrir l&rsquo;étendue des dégâts potentiels. Mais certains aspects pourraient changer dans la future infra.</p>
]]></content:encoded>
        </item>
        <item>
            <title>Analyse poussée d&#8217;un code malveillant PHP, deuxième round</title>
            <link>https://blog.seboss666.info/2020/05/analyse-poussee-dun-code-malveillant-php-deuxieme-round/</link>
            <comments>https://blog.seboss666.info/2020/05/analyse-poussee-dun-code-malveillant-php-deuxieme-round/#comments</comments>
            <pubDate>Fri, 08 May 2020 16:40:33 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Divers]]></category>
            <category><![CDATA[Sysadmin]]></category>
            <category><![CDATA[analyse]]></category>
            <category><![CDATA[cryptolocker]]></category>
            <category><![CDATA[infection]]></category>
            <category><![CDATA[javascript]]></category>
            <category><![CDATA[navigateur]]></category>
            <category><![CDATA[php]]></category>
            <category><![CDATA[redirection]]></category>
            <category><![CDATA[sécurité]]></category>
            <category><![CDATA[SEO]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6263</guid>
            <description><![CDATA[Pour ceux que la sécurité informatique intéresse un peu, j&#8217;avais déjà fait une sorte de pas à pas d&#8217;analyse d&#8217;un code PHP masqué pour tenter [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Pour ceux que la sécurité informatique intéresse un peu, j&rsquo;avais déjà fait une sorte de pas à pas <a href="https://blog.seboss666.info/2018/05/decoder-un-script-php-malveillant-comment-sen-proteger/" target="_blank" rel="noopener">d&rsquo;analyse d&rsquo;un code PHP masqué</a> pour tenter d&rsquo;en comprendre le fonctionnement. J&rsquo;ai pu mettre la main récemment sur un nouveau morceau de choix, car mon analyse m&rsquo;a poussé beaucoup plus loin. Let&rsquo;s go ?</p>
<p style="text-align: justify;"><span id="more-6263"></span></p>
<p style="text-align: justify;">Le code qu&rsquo;on avait analysé en substance n&rsquo;était là que pour permettre de déposer d&rsquo;autres fichiers. Basique, mais toujours pratique à garder sous la main. Ici, je suis tombé sur un morceau beaucoup plus intéressant, qui m&rsquo;a pris deux bonnes heures pour noter tout ce que je vous partage aujourd&rsquo;hui. Je vais volontairement masquer certains éléments comme l&rsquo;URL finale, histoire de pas trop diriger les gens vers des éléments qui peuvent potentiellement endommager leur appareil ou en tout cas ses données.</p>
<p style="text-align: justify;">Petit contexte rapide aussi, le ministère de la Culture remonte un problème avec un lien vers un site (celui de mon client) qui redirigeait vers des sites louches. Alors que normalement je ne touche plus que très rarement à ce genre de situation dans mon quotidien, le client avec qui je bosse en parallèle sur une refonte de sa plateforme m&rsquo;a contacté directement. Comme je suis quelqu&rsquo;un de faible qui aime ce genre de situation, j&rsquo;interviens évidemment <img src="https://s.w.org/images/core/emoji/11/72x72/1f600.png" alt="😀" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<h3 style="text-align: justify;">L&rsquo;enquête de surface</h3>
<p style="text-align: justify;">J&rsquo;attaque par une fouille rapide de l&rsquo;arborescence, en suivant la logique du code : un bout de JavaScript injecté en bas de page via le fichier index.php, qui remonte à plus de deux mois, et j&rsquo;identifie un code PHP injecté dans une dépendance qui remonte à plus de deux ans (un oubli de nettoyage d&rsquo;une précédente intervention, erf).</p>
<p style="text-align: justify;">J&rsquo;ai pris le réflexe de faire une copie de toutes mes trouvailles pour analyse à froid avant de faire le ménage rapidement, et rassurer le ministère de la Culture que c&rsquo;était bon, qu&rsquo;ils pouvaient remettre le lien en ligne. C&rsquo;est plusieurs jours plus tard que j&rsquo;ai attaqué la véritable enquête.</p>
<p style="text-align: justify;">Le JavaScript en substance procédait à du <a href="http://www.blackhat-seo.fr/" target="_blank" rel="noopener">Black Hat SEO</a>, il était embarqué dans une div parlant de Louis Vuitton en anglais (sur un site français), div qui était accompagnée par le code JavaScript obfusqué :</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_indexjs.png" rel="lightbox[6263]"><img class="aligncenter size-medium wp-image-6276" src="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_indexjs-300x118.png" alt="" width="300" height="118" srcset="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_indexjs-300x118.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_indexjs-768x303.png 768w, https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_indexjs-1024x404.png 1024w, https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_indexjs.png 1296w" sizes="(max-width: 300px) 100vw, 300px" /></a>On remplace le deuxième <code>eval()</code> par un <code>document.write()</code> et le tour est joué :</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_indexjs_showed.png" rel="lightbox[6263]"><img class="aligncenter size-medium wp-image-6273" src="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_indexjs_showed-300x22.png" alt="" width="300" height="22" srcset="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_indexjs_showed-300x22.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_indexjs_showed.png 526w" sizes="(max-width: 300px) 100vw, 300px" /></a>La div était donc masquée, mais sa présence dans le code source suffit à faire son effet sur les robots d&rsquo;indexation. Et c&rsquo;est donc le PHP qui m&rsquo;a donné du fil à retordre, on va voir pourquoi.</p>
<h3 style="text-align: justify;">« -Scalpel ? -Scalpel. »</h3>
<p style="text-align: justify;">Voyons donc le petit saligaud :</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_raw.png" rel="lightbox[6263]"><img class="aligncenter size-medium wp-image-6277" src="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_raw-300x122.png" alt="" width="300" height="122" srcset="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_raw-300x122.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_raw-768x311.png 768w, https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_raw-1024x415.png 1024w, https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_raw.png 1292w" sizes="(max-width: 300px) 100vw, 300px" /></a></p>
<p style="text-align: justify;">C&rsquo;est pas beau hein ? Bon le fait est que la première étape va être beaucoup plus facile à analyser parce qu&rsquo;il n&rsquo;y aura pas cinquante étapes de traduction des fonctions, ici j&rsquo;épure et je remplace l&rsquo;eval par un echo. Voici le résultat :</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_deciphered.png" rel="lightbox[6263]"><img class="aligncenter size-medium wp-image-6278" src="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_deciphered-300x141.png" alt="" width="300" height="141" srcset="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_deciphered-300x141.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_deciphered-768x361.png 768w, https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_deciphered-1024x481.png 1024w, https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_deciphered.png 1359w" sizes="(max-width: 300px) 100vw, 300px" /></a>Pas très beau à lire, mais les barbouillis ne concernent que les noms des variables, ça va être cool. On a donc plusieurs éléments ici qu&rsquo;on va détailler bloc par bloc.</p>
<p style="text-align: justify;">La première ligne est une arme nucléaire ou presque : elle traite le contenu d&rsquo;une requête POST, si elle trouve une clé &lsquo;pf&rsquo; dont le contenu mouliné avec md5 correspond à ce qui est demandé, ça exécute le code PHP encodé en base64 qui doit se trouver dans une autre clé &lsquo;cookies_p&rsquo;. Vous avez là un petit moteur d&rsquo;exécution de code distant, ce qu&rsquo;on appelle dans le métier une RCE. En pratique ça fait partie des pires failles de sécurité qu&rsquo;on remonte dans les programmes, ici, l&rsquo;attaquant s&rsquo;est donc laissé une porte grande ouverte. Dans la pratique il est pour l&rsquo;instant limité à l&rsquo;utilisateur PHP, mais rien ne l&#8217;empêche de tenter des escalades de privilèges, c&rsquo;est même possible de procéder à des extractions de données sans même plus de difficultés. Vous l&rsquo;aurez compris, il est désormais compliqué de pouvoir continuer de faire confiance au serveur. Mais c&rsquo;est pas tout.</p>
<p style="text-align: justify;">À partir de la ligne 9, on a un code que je n&rsquo;avais encore jamais eu l&rsquo;occasion de voir et qui m&rsquo;intrigue beaucoup. Il s&rsquo;avère que le code tente d&rsquo;identifier si la requête a été faite par un humain, un robot d&rsquo;indexation de moteur de recherche, ou un humain mais en local (ce qui peut être le site lui-même). En gros, si c&rsquo;est un humain, on va parser tout le contenu de la variable $_SERVER pour en faire un flux qu&rsquo;on va envoyer via une requête POST sur une URL distante. Je vous laisse avec <a href="https://www.php.net/manual/en/reserved.variables.server.php" target="_blank" rel="noopener">la documentation de PHP</a> pour voir tout ce que peut contenir cette variable $_SERVER, c&rsquo;est plutôt détaillé et complet.</p>
<p style="text-align: justify;">Cette URL est toujours en ligne, le whois du domaine ne dit rien mais l&rsquo;adresse IP est hébergée en Ukraine. Le script appelé sans paramètre répond vide mais un code 200, il semble donc toujours d&rsquo;actualité. J&rsquo;ai donc décidé de tenter de rejouer le code pour voir son comportement.</p>
<p style="text-align: justify;">J&rsquo;ai pris quelques minutes pour tenter de crafter moi-même ce contenu de $_SERVER. Pour ce faire, j&rsquo;ai écrit un micro code PHP :</p>
<p></p><pre class="crayon-plain-tag">&lt;?php

var_dump($_SERVER);</pre><p></p>
<p style="text-align: justify;">J&rsquo;ai ensuite démarré un micro serveur Apache avec module PHP embarqué via une image docker random trouvée sur le hub, flemmardise totale mais ça suffit pour l&rsquo;exercice :</p>
<p></p><pre class="crayon-plain-tag">docker run --rm -p 8000:80 --name "apache-php" -v "${PWD}/index.php":/var/www/html/index.php newdeveloper/apache-php</pre><p></p>
<p style="text-align: justify;">Et j&rsquo;ouvre ce fichier index.php via mon navigateur sur l&rsquo;adresse 127.0.0.1 et sur le port 8000. Voilà le résultat :</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2020/04/php_mal_server_craft.png" rel="lightbox[6263]"><img class="aligncenter wp-image-6266 size-large" src="https://blog.seboss666.info/wp-content/uploads/2020/04/php_mal_server_craft-1024x76.png" alt="" width="860" height="64" srcset="https://blog.seboss666.info/wp-content/uploads/2020/04/php_mal_server_craft-1024x76.png 1024w, https://blog.seboss666.info/wp-content/uploads/2020/04/php_mal_server_craft-300x22.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/04/php_mal_server_craft-768x57.png 768w" sizes="(max-width: 860px) 100vw, 860px" /></a>N&rsquo;étant pas un expert en regex de porc et feignant comme pas deux pour faire un parsing, j&rsquo;ai fait le gros sale à base de copier/coller dans un fichier pour ensuite modifier ce contenu pour en faire une vraie affectation de tableau en PHP pour la variable $_SERVER. J&rsquo;ai ensuite fait une copie du code en question, pour voir ce que le file_get_contents() récupérait, mais une fois encore on fait un echo à la place du eval.</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_url_response.png" rel="lightbox[6263]"><img class="aligncenter wp-image-6279 size-large" src="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_url_response-1024x25.png" alt="" width="860" height="21" srcset="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_url_response-1024x25.png 1024w, https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_url_response-300x7.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_url_response-768x19.png 768w" sizes="(max-width: 860px) 100vw, 860px" /></a>Oh ben tiens dis donc, le code PHP récupéré et exécuté injecte un header Location avec une URL bizarre, ce qui a pour effet de rediriger le visiteur vers cette URL. Je m&rsquo;attarde pas sur le base64, il fait la même chose mais via du code HTML si pour une raison ou pour une autre le code PHP a déjà envoyé ses headers avant l&rsquo;exécution de cette portion (ce qui se traduit par une erreur fatale en PHP&#8230;).</p>
<p style="text-align: justify;">A ce moment-là, je vous conseille de vous préparer avant de faire les cons. Soit vous tentez l&rsquo;URL via curl, mais il ne vous retournera que le html brut. Soit vous tentez dans un navigateur, et là vous avez intérêt à être blindé, à jour, voir à désactiver dans un premier temps l&rsquo;exécution de Javascript et l&rsquo;analyser/le charger manuellement si vous le sentez.</p>
<p style="text-align: justify;">Pourquoi ? Oh, trois fois rien. Après deux/trois redirections, le navigateur s&rsquo;est bloqué sur une page qui affiche un bête « Loading&#8230; », et n&rsquo;a rien fait de plus chez moi. Mais en analysant la réponse, c&rsquo;est assez impressionnant :</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_js_raw.png" rel="lightbox[6263]"><img class="aligncenter size-medium wp-image-6280" src="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_js_raw-300x167.png" alt="" width="300" height="167" srcset="https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_js_raw-300x167.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_js_raw-768x427.png 768w, https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_js_raw-1024x570.png 1024w, https://blog.seboss666.info/wp-content/uploads/2020/05/php_mal_js_raw.png 1461w" sizes="(max-width: 300px) 100vw, 300px" /></a>Oui, ce n&rsquo;est que du code JavaScript. Je suis pas expert, et c&rsquo;est à mon avis fait exprès qu&rsquo;il soit aussi tordu, mais malgré tout, en le parcourant en diagonale, on finit par comprendre qu&rsquo;on vient de charger un outil soit de minage de cryptomonnaie, soit plus plausible un <a href="https://fr.wikipedia.org/wiki/CryptoLocker" target="_blank" rel="noopener">CryptoLocker</a>, ce qui est déjà beaucoup plus pénible si ça passe les protections du navigateur. Et ce que vous voyez à droite est la taille du code, vu de « très haut ». C&rsquo;est donc très long, et très dense. J&rsquo;ai pas insisté sur la lecture, j&rsquo;ai envie de garder un semblant de santé mentale.</p>
<h3 style="text-align: justify;">Verdict : on évite le code zombie</h3>
<p style="text-align: justify;">Le reste de l&rsquo;analyse n&rsquo;a pas permis d&rsquo;identifier de truc caché, y compris des fichiers « images » qui sont en fait des scripts PHP. En posant la question j&rsquo;apprends que le code concerné a été réalisé il y a plus de dix ans par des stagiaires, et qu&rsquo;il n&rsquo;a été ni corrigé, ni mis à jour depuis cette date. J&rsquo;avais déjà eu un indice avec le fait que le code était « full français » : nom des variables et des fonctions, commentaires, noms des fichiers et des dossiers, tout y était. L&rsquo;autre indice était l&rsquo;organisation même du code qui ressemblait bizarrement à mes tous premiers projets persos, ceux avant le peu glorieux Collect pour ceux qui voudraient rigoler de mon niveau en développement PHP.</p>
<p style="text-align: justify;">Il tourne de plus sur une machine dont la gestion des mises à jour et des montées de version d&rsquo;environnements d&rsquo;exécutions est inexistante : OS en fin de vie, PHP non supporté, la totale. N&rsquo;importe qui vous le dira : la sécurité informatique, c&rsquo;est une chaîne, aussi forte que le maillon le plus faible. Mettez vos serveurs et vos logiciels à jour, mais laissez un code zombie comme celui-là mal conçu et c&rsquo;est grand ouvert pour se faire infecter et faire joujou avec toutes sortes de saloperies, et tous les autres efforts fournis n&rsquo;auront servi à rien. Je sais, c&rsquo;est plus facile à dire qu&rsquo;à faire, et j&rsquo;en suis le premier exemple, actuellement il ne faut pas trop regarder sous le capot du blog, l&rsquo;installation tient plus du bidonville que du Palace. le chantier est au programme, mais sans date précise pour le moment.</p>
<p style="text-align: justify;">Il y a tout de même quelques techniques pour limiter les dégâts, la plupart déjà partagées dans <a href="https://blog.seboss666.info/category/series/securisation-serveur/" target="_blank" rel="noopener">ma série sur la sécurisation d&rsquo;un serveur</a>, mais au détour d&rsquo;une question Twitter on m&rsquo;a rappelé qu&rsquo;ils dataient un peu, il n&rsquo;est pas impossible dans un futur proche que je rafraîchisse un peu le contenu. Je ne sais pas encore quelle forme ça va prendre, on va déjà commencer par se relire hein, on sait comment fonctionne ma mémoire <img src="https://s.w.org/images/core/emoji/11/72x72/1f600.png" alt="😀" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/05/analyse-poussee-dun-code-malveillant-php-deuxieme-round/feed/</wfw:commentRss>
            <slash:comments>4</slash:comments>
        </item>
        <item>
            <title>Programmation défensive en bash</title>
            <link>https://blog.seboss666.info/2020/04/programmation-defensive-en-bash/</link>
            <comments>https://blog.seboss666.info/2020/04/programmation-defensive-en-bash/#comments</comments>
            <pubDate>Mon, 27 Apr 2020 16:30:26 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Astuces]]></category>
            <category><![CDATA[bash]]></category>
            <category><![CDATA[clarté]]></category>
            <category><![CDATA[défensive]]></category>
            <category><![CDATA[pratique]]></category>
            <category><![CDATA[programmation]]></category>
            <category><![CDATA[qualité]]></category>
            <category><![CDATA[sécurité]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=2935</guid>
            <description><![CDATA[Nouvelle traduction aujourd&#8217;hui, d&#8217;un article qui risque sans prévenir de disparaître. La programmation défensive consiste à structurer son code pour limiter au strict minimum les [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Nouvelle traduction aujourd&rsquo;hui, d&rsquo;un article qui risque sans prévenir de disparaître. La <a href="http://kfirlavi.herokuapp.com/blog/2012/11/14/defensive-bash-programming/" target="_blank" rel="noopener">programmation défensive</a> consiste à structurer son code pour limiter au strict minimum les surfaces d&rsquo;attaques. Le JDN a un article <a href="http://www.journaldunet.com/developpeur/tutoriel/theo/070831-programmation-defensive.shtml" target="_blank" rel="noopener">qui résume bien</a> des concepts, mais ici, on va s&rsquo;attarder sur les scripts Bash. En effet, comme avec PHP on peut vite faire de la merde, et il est préférable de suivre certaines pratiques pour que leur qualité ne soit pas trop catastrophique quand il seront réutilisés ailleurs. Je ne les suis pas toutes, mais j&rsquo;ai trouvé utile de les partager avec vous.</p>
<p style="text-align: justify;"><span id="more-2935"></span></p>
<h3 style="text-align: justify;">Variables globales immutables</h3>
<ul style="text-align: justify;">
<li>Essayez de limiter le nombre de variables globales</li>
<li>Nommage en majuscules</li>
<li>déclarations en lecture seule</li>
<li>Utilisez des variables globales pour remplacer les cryptiques $1, $0, etc</li>
<li>Les globales que j’utilise pratiquement systématiquement dans mes scripts :</li>
</ul>
<p></p><pre class="crayon-plain-tag">readonly PROGNAME=$(basename $0)
readonly PROGDIR=$(readlink -m $(dirname $0))
readonly ARGS="$@"</pre><p></p>
<h3 style="text-align: justify;">Tout est local</h3>
<p style="text-align: justify;">Toutes les variables devraient être locales.</p>
<p></p><pre class="crayon-plain-tag">change_owner_of_file() {
  local filename=$1
  local user=$2
  local group=$3

  chown $user:$group $filename
}


change_owner_of_files() {
  local user=$1; shift
  local group=$1; shift
  local files=$@
  local i

  for i in $files
  do
    chown $user:$group $i
  done
}</pre><p></p>
<ul style="text-align: justify;">
<li>des paramètres « auto-documentés »</li>
<li>Habituellement pour les boucles ont utilise « i », il est vital de la déclarer comme locale</li>
<li>les variables locales ne fonctionnent pas dans un contexte global :</li>
</ul>
<p></p><pre class="crayon-plain-tag">kfir@goofy ~ $ local a
bash: local: can only be used in a function</pre><p></p>
<h3 style="text-align: justify;">main()</h3>
<ul style="text-align: justify;">
<li>Permet de conserver toutes les variables comme locales</li>
<li>Intuitif pour la programmation fonctionnelle</li>
<li>La seule commande globale dans le code est : main</li>
</ul>
<p></p><pre class="crayon-plain-tag">main() {
  local files="/tmp/a /tmp/b"
  local i

  for i in $files
    do
      change_owner_of_file kfir users $i
    done
}
main</pre><p></p>
<h3 style="text-align: justify;">Tout est une fonction</h3>
<ul style="text-align: justify;">
<li>Le seul code qui tourne globalement est
<ul>
<li>Les déclarations globales qui sont immutables</li>
<li>main</li>
</ul>
</li>
<li>Permet de garder un code propre</li>
<li>Les procédures sont plus descriptives</li>
</ul>
<p></p><pre class="crayon-plain-tag">main() {
local files=$(ls /tmp | grep pid | grep -v daemon)
}</pre><p></p><pre class="crayon-plain-tag">temporary_files() {
  local dir=$1

  ls $dir \
    | grep pid \
    | grep -v daemon
}

main() {
  local files=$(temporary_files /tmp)
}</pre><p></p>
<ul style="text-align: justify;">
<li><em>Le deuxième exemple est bien meilleur</em>. Rechercher des fichiers est le problème de temporary_files() et pas celui de main(). Le code est également mieux « testable », via un test unitaire sur temporary_files().</li>
<li>Si vous testez la première version, vous mélangez la logique de recherche du reste de main.</li>
</ul>
<p></p><pre class="crayon-plain-tag">test_temporary_files() {
  local dir=/tmp

  touch $dir/a-pid1232.tmp
  touch $dir/a-pid1232-daemon.tmp

  returns "$dir/a-pid1232.tmp" temporary_files $dir

  touch $dir/b-pid1534.tmp

  returns "$dir/a-pid1232.tmp $dir/b-pid1534.tmp" temporary_files $dir
}</pre><p></p>
<p style="text-align: justify;">Comme vous le voyez, ce test ne concerne pas main().</p>
<h3 style="text-align: justify;">Des fonctions de debug</h3>
<ul style="text-align: justify;">
<li>Lancez le programme avec le drapeau -x :</li>
</ul>
<p></p><pre class="crayon-plain-tag">bash -x my_prog.sh</pre><p></p>
<ul style="text-align: justify;">
<li>Débuggez une portion du code en utilisant set -x et set +x, ce qui va afficher les messages de débug pour le code entouré des commandes.</li>
</ul>
<p></p><pre class="crayon-plain-tag">temporary_files() {
  local dir=$1

  set -x
  ls $dir \
    | grep pid \
    | grep -v daemon
  set +x
}</pre><p></p>
<ul style="text-align: justify;">
<li>Affichez le nom de la fonction et ses arguments :</li>
</ul>
<p></p><pre class="crayon-plain-tag">temporary_files() {
  echo $FUNCNAME $@
  local dir=$1

  ls $dir \
    | grep pid \
    | grep -v daemon
}</pre><p></p>
<p style="text-align: justify;">Donc, en appelant la fonction :</p>
<p></p><pre class="crayon-plain-tag">temporary_files /tmp</pre><p></p>
<p style="text-align: justify;">affichera sur la sortie standard :</p>
<p></p><pre class="crayon-plain-tag">temporary_files /tmp</pre><p></p>
<h3 style="text-align: justify;">Clarté du code</h3>
<p style="text-align: justify;">Qu&rsquo;est-ce que fait ce code ?</p>
<p></p><pre class="crayon-plain-tag">main() {
  local dir=/tmp

  [[ -z $dir ]] \
    &amp;&amp; do_something...

  [[ -n $dir ]] \
    &amp;&amp; do_something...

  [[ -f $dir ]] \
    &amp;&amp; do_something...

  [[ -d $dir ]] \
    &amp;&amp; do_something...
}
main</pre><p></p>
<p style="text-align: justify;">Laissez votre code parler :</p>
<p></p><pre class="crayon-plain-tag">is_empty() {
  local var=$1

  [[ -z $var ]]
}

is_not_empty() {
  local var=$1

  [[ -n $var ]]
}

is_file() {
  local file=$1

  [[ -f $file ]]
}

is_dir() {
  local dir=$1

  [[ -d $dir ]]
}

main() {
  local dir=/tmp

  is_empty $dir \
    &amp;&amp; do_something...

  is_not_empty $dir \
    &amp;&amp; do_something...

  is_file $dir \
    &amp;&amp; do_something...

  is_dir $dir \
    &amp;&amp; do_something...
}
main</pre><p></p>
<h3 style="text-align: justify;">Chaque ligne fait une seule chose</h3>
<ul style="text-align: justify;">
<li>Sectionnez vos commandes avec des antislash <code></code>. Par exemple :</li>
</ul>
<p></p><pre class="crayon-plain-tag">temporary_files() {
  local dir=$1

  ls $dir | grep pid | grep -v daemon
}</pre><p></p>
<p style="text-align: justify;">Peut être écrit plus clairement :</p>
<p></p><pre class="crayon-plain-tag">temporary_files() {
  local dir=$1

  ls $dir \
    | grep pid \
    | grep -v daemon
}</pre><p></p>
<ul style="text-align: justify;">
<li>Les symboles doivent être en début de ligne. Mauvais exemple de symboles à la fin :</li>
</ul>
<p></p><pre class="crayon-plain-tag">temporary_files() {
  local dir=$1

  ls $dir | \
    grep pid | \
    grep -v daemon
}</pre><p></p>
<p style="text-align: justify;">Bon exemple où l&rsquo;on voit clairement la connexion entre les les lignes et les symboles :</p>
<p></p><pre class="crayon-plain-tag">print_dir_if_not_empty() {
  local dir=$1

  is_empty $dir \
    &amp;&amp; echo "dir is empty" \
    || echo "dir=$dir"
}</pre><p></p>
<h3 style="text-align: justify;">Afficher l&rsquo;usage</h3>
<p style="text-align: justify;">Ne faites pas ça :</p>
<p></p><pre class="crayon-plain-tag">echo "this prog does:..."
echo "flags:"
echo "-h print help"</pre><p></p>
<p style="text-align: justify;">Ça devrait être une fonction :</p>
<p></p><pre class="crayon-plain-tag">usage() {
  echo "this prog does:..."
  echo "flags:"
  echo "-h print help"
}</pre><p></p>
<p style="text-align: justify;">echo est répété à chaque ligne. A la place on a &lsquo;Here Document&rsquo; :</p>
<p></p><pre class="crayon-plain-tag">usage() {
	cat &lt;&lt;- EOF
	usage: $PROGNAME options

	Program deletes files from filesystems to release space.
	It gets config file that define fileystem paths to work on, and whitelist rules to
	keep certain files.

	OPTIONS:
		-c --config configuration file containing the rules. use --help-config to see the syntax.
		-n --pretend do not really delete, just how what you are going to do.
		-t --test run unit test to check the program
		-v --verbose Verbose. You can specify more then one -v to have more verbose
		-x --debug debug
		-h --help show this help
		   --help-config configuration help

	Examples:
		Run all tests:
		$PROGNAME --test all

		Run specific test:
		$PROGNAME --test test_string.sh

		Run:
		$PROGNAME --config /path/to/config/$PROGNAME.conf

		Just show what you are going to do:
		$PROGNAME -vn -c /path/to/config/$PROGNAME.conf
	EOF
}</pre><p></p>
<p style="text-align: justify;">Attention à bien utiliser des tabulations &lsquo;\t&rsquo; pour le début de chaque ligne. Dans vim vous pouvez utiliser cette astuce si votre tabulation consiste en 4 espaces :</p>
<p></p><pre class="crayon-plain-tag">:s/^    /\t/</pre><p></p>
<h3 style="text-align: justify;">Arguments de ligne de commande</h3>
<p style="text-align: justify;">Voici un exemple de complément à la fonction usage d&rsquo;au-dessus. Ce code est tiré de l&rsquo;article <a href="http://kirk.webfinish.com/2009/10/bash-shell-script-to-use-getopts-with-gnu-style-long-positional-parameters/" target="_blank" rel="noopener">bash shell script to use getopts with gnu style long positional parameters</a> sur le blog de Kirk :</p>
<p></p><pre class="crayon-plain-tag">cmdline() {
  # got this idea from here:
  # http://kirk.webfinish.com/2009/10/bash-shell-script-to-use-getopts-with-gnu-style-long-positional-parameters/
  local arg=
  for arg
  do
    local delim=""
    case "$arg" in
      #translate --gnu-long-options to -g (short options)
      --config) args="${args}-c ";;
      --pretend) args="${args}-n ";;
      --test) args="${args}-t ";;
      --help-config) usage_config &amp;&amp; exit 0;;
      --help) args="${args}-h ";;
      --verbose) args="${args}-v ";;
      --debug) args="${args}-x ";;
      #pass through anything else
      *) [[ "${arg:0:1}" == "-" ]] || delim="\""
         args="${args}${delim}${arg}${delim} ";;
    esac
  done

  #Reset the positional parameters to the short options
  eval set -- $args

  while getopts "nvhxt:c:" OPTION
  do
    case $OPTION in
      v)
          readonly VERBOSE=1
          ;;
      h)
          usage
          exit 0
          ;;
      x)
          readonly DEBUG='-x'
          set -x
          ;;
      t)
          RUN_TESTS=$OPTARG
          verbose VINFO "Running tests"
          ;;
      c)
          readonly CONFIG_FILE=$OPTARG
          ;;
      n)
          readonly PRETEND=1
          ;;
    esac
  done

  if [[ $recursive_testing || -z $RUN_TESTS ]]; then
    [[ ! -f $CONFIG_FILE ]] \
      &amp;&amp; eexit "You must provide --config file"
  fi
  return 0
}</pre><p></p>
<p style="text-align: justify;">On l&rsquo;utilise ensuite de cette façon en utilisant la variable immutable ARGS qu&rsquo;on a défini au début du script :</p>
<p></p><pre class="crayon-plain-tag">main() {
cmdline $ARGS
}
main</pre><p></p>
<h3 style="text-align: justify;">Tests unitaires</h3>
<ul style="text-align: justify;">
<li>Très important dans les langages de haut niveau</li>
<li>Utilisez shunit2 pour vos tests unitaires</li>
</ul>
<p></p><pre class="crayon-plain-tag">test_config_line_paths() {
  local s='partition cpm-all, 80-90,'

  returns "/a" "config_line_paths '$s /a, '"
  returns "/a /b/c" "config_line_paths '$s /a:/b/c, '"
  returns "/a /b /c" "config_line_paths '$s /a : /b : /c, '"
}

config_line_paths() {
  local partition_line="$@"

  echo $partition_line \
    | csv_column 3 \
    | delete_spaces \
    | column 1 \
    | colons_to_spaces
}

source /usr/bin/shunit2</pre><p></p>
<p style="text-align: justify;">Voici un autre exemple sur la commande df :</p>
<p></p><pre class="crayon-plain-tag">DF=df

mock_df_with_eols() {
    cat &lt;&lt;- EOF
    Filesystem           1K-blocks      Used Available Use% Mounted on
    /very/long/device/path
                         124628916  23063572 100299192  19% /
    EOF
}

test_disk_size() {
  returns 1000 "disk_size /dev/sda1"

  DF=mock_df_with_eols
  returns 124628916 "disk_size /very/long/device/path"
}

df_column() {
  local disk_device=$1
  local column=$2

  $DF $disk_device \
    | grep -v 'Use%' \
    | tr '\n' ' ' \
    | awk "{print \$$column}"
}

disk_size() {
  local disk_device=$1

  df_column $disk_device 2
}</pre><p></p>
<p style="text-align: justify;">Ici il y a une exception, pour les tests je déclare DF au niveau global et pas en lecture seule. C&rsquo;est parce que shunit2 n&rsquo;autorise pas les changements de fonctions au niveau global.</p>
<hr />
<p style="text-align: justify;">Les plus aguerris au développement logiciel trouveront peut-être évidents ces constructions de scripts, pour ma part j&rsquo;avais déjà lu certains de ces conseils, notamment pour Python. C&rsquo;est sympa de voir qu&rsquo;on peut réutiliser les mêmes concepts pour Bash, par défaut c&rsquo;est un langage particulièrement permissif, à l&rsquo;image de PHP. Il n&rsquo;en faut pas plus pour que les deux se trainent une réputation désastreuse.</p>
<p style="text-align: justify;">
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/04/programmation-defensive-en-bash/feed/</wfw:commentRss>
            <slash:comments>10</slash:comments>
        </item>
        <item>
            <title>Déployer un service Consul, mais surtout le sécuriser !</title>
            <link>https://blog.seboss666.info/2020/04/deployer-un-service-consul-mais-surtout-le-securiser/</link>
            <comments>https://blog.seboss666.info/2020/04/deployer-un-service-consul-mais-surtout-le-securiser/#comments</comments>
            <pubDate>Mon, 20 Apr 2020 16:30:28 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Sysadmin]]></category>
            <category><![CDATA[acl]]></category>
            <category><![CDATA[consul]]></category>
            <category><![CDATA[docker]]></category>
            <category><![CDATA[protection]]></category>
            <category><![CDATA[stockage]]></category>
            <category><![CDATA[terraform]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6241</guid>
            <description><![CDATA[Maintenant que j&#8217;ai récupéré la main complète sur le destin de l&#8217;infrastructure publique dont fait partie le serveur qui héberge le blog, je prépare le [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Maintenant que j&rsquo;ai récupéré la main complète sur le destin de l&rsquo;infrastructure publique dont fait partie le serveur qui héberge le blog, je prépare le futur, et ce futur passe par de l&rsquo;infrastructure as code, notamment avec Terraform et Ansible. Pour le premier, un élément important du résultat est le fichier d&rsquo;état de l&rsquo;infrastructure, le fameux « tfstate ». Et pour le garder au chaud, j&rsquo;ai voulu utiliser, plutôt qu&rsquo;un fichier texte sur le pc, un service Consul. Mais il ne faut pas faire n&rsquo;importe quoi avec.</p>
<p style="text-align: justify;"><span id="more-6241"></span></p>
<h3 style="text-align: justify;">Le parfait compagnon de Terraform</h3>
<p style="text-align: justify;">Consul fait partie d&rsquo;une famille qu&rsquo;on appelle service de stockage dit clé-valeur, comme Redis, même si ce dernier a une forte orientation « temporaire » car il sert souvent de mémoire cache. Il est développé par Hashicorp, la même boite qui s&rsquo;occupe aussi de Terraform. Il est donc nativement inclus comme backend de stockage pour y conserver son précieux fichier tfstate.</p>
<p style="text-align: justify;">Vous pourrez également y stocker quantité de données qui pourront être réutilisées par la suite. Un de nos clients chez Linkbynet l&rsquo;utilise par exemple pour y enregistrer ses besoins en termes de projets et d&rsquo;infrastructures liées (nom du projet, nombre de machines, dimensionnements, nommages des ressources), et on n&rsquo;a plus qu&rsquo;à lancer un pipeline qui va lire les valeurs et déployer l&rsquo;infrastructure en fonction de ces données. Les usages sont donc multiples.</p>
<p style="text-align: justify;">Évidemment, disposer d&rsquo;un « serveur » consul n&rsquo;a de sens que si on doit accéder à plusieurs machines à ces données, l&rsquo;avoir en local est pratique pour faire des tests, mais superflu par rapport à un fichier plat local, notamment dans le cadre de Terraform.</p>
<h3 style="text-align: justify;">Un déploiement sur Docker Swarm très rapide</h3>
<p style="text-align: justify;">Le service n&rsquo;a pas besoin d&rsquo;être répliqué vu l&rsquo;usage basique, les volumes persistants ont été créés sur le NAS, et la stack est presque basique, je la partage quand même :</p>
<p></p><pre class="crayon-plain-tag">version: "3.2"
networks:
  consul:
    driver: overlay

volumes:
  consul_data:
    driver_opts:
      type: nfs
      o: "addr=192.168.1.200,rw,nfsvers=3,nolock,soft,exec"
      device: ":/volume1/Docker/consul/data"
  consul_config:
    driver_opts:
      type: nfs
      o: "addr=192.168.1.200,rw,nfsvers=3,nolock,soft,exec"
      device: ":/volume1/Docker/consul/config"
services:
  consul:
    image: consul:1.7.2
    environment:
      - "CONSUL_BIND_INTERFACE=eth0"
      - "CONSUL_HTTP_ADDR=0.0.0.0"
    entrypoint:
      - consul
      - agent
      - -server
      - -bootstrap-expect=1
      - -config-format
      - json
      - -config-file
      - /consul/config/consul-acl.json
      - -data-dir=/consul/data
      - -bind={{ GetInterfaceIP "eth0" }}
      - -client=0.0.0.0
      - -ui

    networks:
      - consul
    ports:
      - "8500:8500"
      - "8600:8600/udp"
    volumes:
      - type: volume
        source: consul_data
        target: /consul/data
      - type: volume
        source: consul_config
        target: /consul/config
    deploy:
      replicas: 1
      restart_policy:
        condition: any</pre><p></p>
<p style="text-align: justify;">La partie importante pour un déploiement « docker prod ready », c&rsquo;est l&rsquo;entrypoint qui contient les commandes permettant de bien faire prendre en compte l&rsquo;initialisation des ACL et l&rsquo;activation du mode « bootstrap » qui sinon laisse le serveur en mode « dev », avec moults messages de debug pratique, mais surtout un mode « in-memory » qui va un peu à l&rsquo;envers de ce qu&rsquo;on cherche à faire à savoir disposer d&rsquo;un stockage persistant.</p>
<h3 style="text-align: justify;">Données précieuses, sécurité adaptée</h3>
<p style="text-align: justify;">En effet, par défaut, c&rsquo;est grand ouvert. Quelque soit le mode de déploiement, vous lancez, deux secondes après vous pouvez enregistrer votre première clé. On va pas se mentir, c&rsquo;est pas dingue. Si quelqu&rsquo;un vient foutre le bordel, notamment sur votre fichier d&rsquo;état, vous serez bon pour tout reprendre à la main. Pour un ou deux serveurs, c&rsquo;est pas grave, quand vous déployez plusieurs dizaines de ressources différentes d&rsquo;un coup, ça fait bien mal au cul. Il est donc nécessaire de mettre en place un certain niveau de protection.</p>
<h4 style="text-align: justify;">Le transport</h4>
<p style="text-align: justify;">Tout d&rsquo;abord, il faut garder à l&rsquo;esprit que les communications se font en HTTP. C&rsquo;est donc un minimum que de chiffrer le transport. Plusieurs options sont possibles en fonction du contexte.</p>
<p style="text-align: justify;">Pour un serveur qui restera dans un réseau un peu privé et un accès semi-manuel (exécution d&rsquo;outils sur son poste), on pourra utiliser un tunnel SSH avec transfert de port. On utilisera la forme suivante :</p>
<p></p><pre class="crayon-plain-tag">$ ssh -L 8500:&lt;consul_ip&gt;:8500 &lt;consul_ip|consul_host&gt;</pre><p></p>
<p style="text-align: justify;">Ensuite, si vous interrogez le port local 8500, la connexion sera renvoyée à travers la connexion SSH pour interroger le port 8500 en face.</p>
<p style="text-align: justify;">Dans mon cas, comme j&rsquo;ai déployé le consul dans mon cluster Docker swarm, j&rsquo;ai voulu passer par le reverse-proxy plutôt que le SSH. J&rsquo;ai donc déployé du HTTPS avec un sous-domaine dédié et du Let&rsquo;s Encrypt. C&rsquo;est plus pratique dans ce dernier cas car consul peut être accédé par des outils tiers, comme un runner gitlab, et aussi, je peux utiliser n&rsquo;importe quel PC sans forcément avoir mes clés SSH sur moi. Notez que dans un cas comme dans l&rsquo;autre (SSH ou TLS), on est généralement sur des hauts niveaux de protection donc ça va.</p>
<h4 style="text-align: justify;">L&rsquo;authentification</h4>
<p style="text-align: justify;">Bien, le transport est chiffré, mais dans le cas d&rsquo;HTTPS par exemple, ça ne résout pas un problème fondamental : si on connaît l&rsquo;adresse, on fait ce qu&rsquo;on veut du serveur. Fort heureusement, il est possible de mettre plusieurs choses en place.</p>
<p style="text-align: justify;">La première qui est presque systématique sur les services que j&rsquo;expose sur mon cluster Swarm, je met en place une authentification HTTP basique, qui repose sur un couple user/password que je génère quand je déploie le vhost sur le reverse-proxy. Sans ce couple, vous prenez une erreur 401 de la part d&rsquo;Nginx. Les règles classiques se posent alors, entre longueur de mots de passe et complexité. Dans le cas présent où c&rsquo;est conçu d&rsquo;abord pour être exploité via des outils, la saisie manuelle n&rsquo;étant pas nécessaire tout le temps je conseille de ne pas lésiner sur la longueur, pas de problème à disposer de couples de 32 caractères chacun, le tout bien aléatoire avec une palette étendue (alphanumérique, majuscule/minuscules, ponctuation). On évite quand même les emoji dans les login ou mots de passe qu&rsquo;on commence à voir apparaître, déjà c&rsquo;est pénible à taper sans clavier adapté, et croyez-le ou non ça a tendance à bien faire bugger les programmes, malgré les promesses d&rsquo;UTF-8.</p>
<p style="text-align: justify;">Consul de son côté dispose d&rsquo;un système d&rsquo;ACL qui semble bien fourni, mais que j&rsquo;ai pour l&rsquo;instant bien du mal à mettre en place. La faute à <a href="https://www.consul.io/api/acl/acl.html" target="_blank" rel="noopener">une documentation</a> bien moins fournie et claire que peut l&rsquo;être celle de Terraform, ou mieux celle d&rsquo;Ansible qui regorge d&rsquo;exemple pour tous les modules supportés permettant de mieux comprendre leur fonctionnement. Là si l&rsquo;activation du moteur ACL est assez facile, la mise en place des règles de contrôle d&rsquo;accès, et la création du token, semblent plus compliqués, sans parler de tester manuellement derrière, avec curl entre autres. Mais ceci dit, les ACL vous permettront notamment de limiter les actions d&rsquo;une clé à certaines portions du serveur consul, ce qui permet d&rsquo;éviter d&rsquo;aller polluer les voisins.</p>
<p style="text-align: justify;">À retenir, vous pouvez tout à fait activer les deux méthodes en même temps, Terraform permet de renseigner les informations pour les deux types de protection, il suffit d&rsquo;initialiser le backend avec les options suivantes :</p>
<p></p><pre class="crayon-plain-tag">$ terraform init -backend=true \
    -backend-config="address=${CONSUL_ADDRESS}" \
    -backend-config="scheme=${CONSUL_SCHEME}" \
    -backend-config="http_auth=${CONSUL_USERNAME}:${CONSUL_PASSWORD}" \
    -backend-config="access_token=${CONSUL_TOKEN}" \
    -backend-config="path=${CONSUL_PATH}" \
    -backend-config="lock=${CONSUL_LOCK}"</pre><p></p>
<h3 style="text-align: justify;">Un outil versatile</h3>
<p style="text-align: justify;">Ici vous n&rsquo;avez entrevu qu&rsquo;un usage de Consul, mais il a plusieurs autres qualités que je vous laisse découvrir avec <a href="https://www.consul.io/" target="_blank" rel="noopener">le site officiel</a>. Je lâche pas l&rsquo;affaire sur les ACL, j&rsquo;ai beau reconnaître l&rsquo;avantage de ce système de gestion de permissions, j&rsquo;ai toujours du mal avec les différentes implémentations, j&rsquo;ai pleuré avec celles de Mumble par exemple, pareil pour Teamspeak 3, donc autant dire que ça va mettre un peu de temps. Mais je désespère pas <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/04/deployer-un-service-consul-mais-surtout-le-securiser/feed/</wfw:commentRss>
            <slash:comments>2</slash:comments>
        </item>
        <item>
            <title>Haproxy : OpenVPN ou SSH ?</title>
            <link>https://blog.seboss666.info/2020/04/haproxy-openvpn-ou-ssh/</link>
            <comments>https://blog.seboss666.info/2020/04/haproxy-openvpn-ou-ssh/#comments</comments>
            <pubDate>Fri, 17 Apr 2020 16:30:27 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Astuces]]></category>
            <category><![CDATA[Sysadmin]]></category>
            <category><![CDATA[bastion]]></category>
            <category><![CDATA[filtrage]]></category>
            <category><![CDATA[haproxy]]></category>
            <category><![CDATA[https]]></category>
            <category><![CDATA[openvpn]]></category>
            <category><![CDATA[protocole]]></category>
            <category><![CDATA[routage]]></category>
            <category><![CDATA[ssh]]></category>
            <category><![CDATA[tls]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6153</guid>
            <description><![CDATA[Je n&#8217;utilise pas du tout Haproxy à titre personnel, mes contacts n&#8217;ont été que professionnels, et principalement pour du load-balancing HTTP/HTTPS. Mais il est tout [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Je n&rsquo;utilise pas du tout Haproxy à titre personnel, mes contacts n&rsquo;ont été que professionnels, et principalement pour du load-balancing HTTP/HTTPS. Mais il est tout à fait possible de s&rsquo;en servir pour d&rsquo;autres usages, en mode TCP, c&rsquo;est à dire en mode « brut ». Et là, ça permet de faire des choses de tarés, et l&rsquo;astuce d&rsquo;aujourd&rsquo;hui en est une, partager le port 443 pour faire soit du SSH, soit de l&rsquo;OpenVPN. Z&rsquo;êtes prêts ?</p>
<p style="text-align: justify;"><span id="more-6153"></span></p>
<h3 style="text-align: justify;">Le concept</h3>
<p style="text-align: justify;">Oui parce que l&rsquo;idée ne sort pas de nulle part non plus. Sur le papier déjà, il faut savoir que n&rsquo;importe quel port peut être utilisé pour n&rsquo;importe quel protocole. Ça n&#8217;empêche pas les RFC de définir des ports par défaut, qui sont la plupart du temps respectés, et qu&rsquo;on doit laisser passer pour faire un peu de Web et d&rsquo;Internet, sinon ça n&rsquo;aurait pas grand intérêt : 53 pour le DNS, 80 et 443 pour HTTP et HTTPS, 22 pour SSH, vous en connaissez surement plusieurs dans ce cas.</p>
<p style="text-align: justify;">Mais dans la pratique, et dans beaucoup de réseaux publics notamment, mais aussi des réseaux d&rsquo;entreprise, avoir droit à autre chose que du 80 et du 443, c&rsquo;est pas toujours évident (oui parfois même le DNS public est bloqué, et on doit passer par le point d&rsquo;accès pour ça &#8211;quelle horreur&#8230;). Et il n&rsquo;y a rien de plus frustrant de se retrouver coincé sur un réseau qui n&rsquo;autorise pas à faire de l&rsquo;Internet, seulement du Web. Et pour ceux qui ont du mal, prenez quelques instants pour me <a href="https://blog.seboss666.info/2014/04/le-web-cest-comme-la-biere/" target="_blank" rel="noopener">relire ce billet</a>, et reviendez après.</p>
<p style="text-align: justify;">Donc, pour faire de l&rsquo;internet sur les réseaux qui ne veulent pas, il est intéressant de faire croire qu&rsquo;on va faire du Web, soit port 443 en mode TCP, mais d&rsquo;y héberger notre service qui n&rsquo;est pas du Web. Le problème qui survient très vite dans ce cas, c&rsquo;est qu&rsquo;en théorie, on ne peut exposer qu&rsquo;un seul service à la fois sur un port donné. C&rsquo;est là qu&rsquo;Haproxy va nous aider.</p>
<h3 style="text-align: justify;">La trousse à outils du load-balancing, et bien plus</h3>
<p style="text-align: justify;">J&rsquo;ai déjà eu l&rsquo;occasion de parler d&rsquo;Haproxy <a href="https://blog.seboss666.info/?s=haproxy" target="_blank" rel="noopener">par le passé</a>, mais c&rsquo;était à chaque fois pour évoquer des usages Web. Et il le fait très bien, c&rsquo;est ce qu&rsquo;on utilise en général sur les pare-feux « netfilter » qu&rsquo;on déploie sur des plateformes VMware entre autres, mais c&rsquo;est aussi le moteur qui est exploité au sein d&rsquo;NSX Edge, la passerelle virtuelle de VMware pour ses solutions de clustering. À part que dans ce cas, on vous colle devant une interface aussi merdique que possible, où appliquer une configuration relève du miracle tellement tout est contre-intuitif. À tel point que l&rsquo;astuce que je vous présente aujourd&rsquo;hui n&rsquo;est peut-être pas applicable sur NSX, alors que la technologie sous-jacente le permet, c&rsquo;est dire.</p>
<p style="text-align: justify;">Tout ça pour dire que l&rsquo;application de load-balancing sait en faire beaucoup plus, notamment grâce au mode TCP, qui permet de traiter les paquets de manière un peu moins spécifique. Encore que là, on va le voir, il est possible d&rsquo;appliquer des règles en fonction de l&rsquo;analyse du contenus des paquets. C&rsquo;est pas du <a href="https://fr.wikipedia.org/wiki/Deep_packet_inspection" target="_blank" rel="noopener">DPI</a> encore à ce niveau, on cherche pas à déchiffrer le contenu, juste les entêtes pour agir en conséquence.</p>
<h3 style="text-align: justify;">Architecture</h3>
<p style="text-align: justify;">L&rsquo;exemple d&rsquo;aujourd&rsquo;hui se base sur une configuration qui peut être simple, à savoir que tout tient sur le même serveur, mais ce n&rsquo;est pas obligatoire. On a donc trois services, paramétrés de cette manière :</p>
<ul style="text-align: justify;">
<li>HAProxy, sur le port 443</li>
<li>OpenVPN, sur le port 1914 (parce que j&rsquo;ai envie, mais vous pouvez garder 1194)</li>
<li>SSH, sur le port 22</li>
</ul>
<p style="text-align: justify;">Sur la machine, seul le port 443 est ouvert au monde évidemment, ce qui permet de brouiller les pistes. Celui qui va vouloir scanner les ports pensera tomber sur un serveur web, et aura quelques difficultés. Et le comportement sera un peu bizarre s&rsquo;il tente une connexion HTTPS classique, au mieux la session TLS va quand même démarrer (sauf si la connexion VPN repose sur un certificat client), au pire il aura une réponse étrange voire une simple déconnexion (RST).</p>
<p style="text-align: justify;">Comme j&rsquo;ai dit, c&rsquo;est pour l&rsquo;exemple, les services en question peuvent tout à fait se trouver sur d&rsquo;autres machines sur un réseau privé par exemple. Et je ne vais pas plus que ça détailler la configuration de ces services, c&rsquo;est très facile de trouver des ressources même en français.</p>
<p style="text-align: justify;">Alors oui, je préviens, je déconseille du coup d&rsquo;utiliser cette configuration pour ajouter aussi le support d&rsquo;un serveur web. Déjà parce que la connexion TLS est déjà filtrée pour la partie OpenVPN, donc il faudrait encore creuser pour qualifier la différence entre les deux, mais surtout parce qu&rsquo;en mode TCP, haproxy va certes renvoyer les paquets vers le serveur web, mais du coup ce dernier verra l&rsquo;adresse IP d&rsquo;haproxy en tant que source, et plus l&rsquo;ip du client. Et comme haproxy ne fait pas la terminaison, il n&rsquo;y a pas d&rsquo;ajout d&rsquo;entête HTTP X-Forwarded-For puisque le protocole est toujours chiffré à ce moment-là. Il y a potentiellement moyen de s&rsquo;en sortir avec le <a href="https://www.loadbalancer.org/blog/configure-haproxy-with-tproxy-kernel-for-full-transparent-proxy/" target="_blank" rel="noopener">TPROXY</a>, mais ça sort du cadre de l&rsquo;expérimentation. Vous êtes prévenu, attaquons les choses sérieuses.</p>
<h3 style="text-align: justify;">La configuration</h3>
<p style="text-align: justify;">Pour la mise en place, ça va « simplement » reposer sur un frontend, celui qui écoutera sur le port 443, et deux backends, un pour ssh, un pour openvpn. Là encore, pas la peine de s&rsquo;attarder sur la configuration des backends, car toute la beauté du fonctionnement réside dans le frontend, et de plusieurs concepts, dont les acl et l&rsquo;analyse de contenus des paquets. On va y aller étape par étape avec une explication à chaque fois.</p>
<p style="text-align: justify;">On commence par une détection d&rsquo;une connexion TLS :</p>
<p></p><pre class="crayon-plain-tag">frontend 443
  tcp-request inspect-delay 15s
  tcp-request content accept if { req.ssl_hello_type 1 }</pre><p></p>
<p style="text-align: justify;">tcp-request permet de spécifier dans quel mode on bosse, et surtout comment on analyse les paquets (TCP et pas HTTPS directement), ici on laisse passer les paquets TLS de type « client hello » (type 1, si vous voulez laisser passer un paquet entrant de type « server hello » &#8212; c&rsquo;est bizarre mais passons &#8211;, c&rsquo;est type 2), et de ce que j&rsquo;ai compris le délai permet d&rsquo;éviter de confondre OpenVPN et HTTPS. Cette première étape est nécessaire pour pouvoir ensuite filter les paquets OpenVPN spécifiquement :</p>
<p></p><pre class="crayon-plain-tag">acl acl_proto_openvpn payload(0,2) -m bin 003c
  tcp-request content accept if acl_proto_openvpn</pre><p></p>
<p style="text-align: justify;">On retrouve ici la déclaration d&rsquo;une ACL, comme on l&rsquo;a fait par le passé, mais cette fois, le critère est assez velu. On analyse le contenu brut d&rsquo;un paquet pour faire correspondre une séquence binaire au début du paquet. En effet, la charge d&rsquo;un paquet TCP commence par un code qui correspond au type de protocole, 003c correspondant donc ici à OpenVPN.</p>
<p style="text-align: justify;">Je vous l&rsquo;ai dit, c&rsquo;est velu. Fort heureusement, la détection d&rsquo;OpenSSH est plus simple. Si vous avez déjà fait un coup de telnet sur un serveur OpenSSH, vous avez déjà vu que l&rsquo;annonce du serveur est en clair, et il y a un élément facilement identifiable, qui est la version du protocole SSH. On peut dès lors non pas taper sur de la reconnaissance binaire, mais du plus humain avec une chaine de caractères :</p>
<p></p><pre class="crayon-plain-tag">acl acl_proto_ssh payload(0,7) -m str SSH-2.0
  tcp-request content accept if acl_proto_ssh</pre><p></p>
<p style="text-align: justify;">Et c&rsquo;est tout. Pour chaque protocole on a défini un filtre avec l&rsquo;ACL sur le contenu du paquet, et on force Haproxy à n&rsquo;accepter que ce type de paquet avec <code>tcp-request content accept</code>. Ne reste plus qu&rsquo;à « router » vers le service concerné :</p>
<p></p><pre class="crayon-plain-tag">use_backend host_ssh if acl_proto_ssh
  use_backend openvpn if acl_proto_openvpn</pre><p></p>
<p style="text-align: justify;">Et voilà, vous avez votre routeur maison de protocole pour contourner les limitations un peu pénibles de certains réseaux.</p>
<p style="text-align: justify;">Je vous remet la configuration complète ici, pour que ce soit plus digeste si vous voulez copier/coller :</p>
<p></p><pre class="crayon-plain-tag">frontend 443
  #ssl client hello
  tcp-request inspect-delay 15s
  tcp-request content accept if { req.ssl_hello_type 1 }
  #OpenVPN
  acl acl_proto_openvpn payload(0,2) -m bin 003c
  tcp-request content accept if acl_proto_openvpn
  #OpenSSH
  acl acl_proto_ssh payload(0,7) -m str SSH-2.0
  tcp-request content accept if acl_proto_ssh</pre><p></p>
<h3 style="text-align: justify;">L&rsquo;alternative SSLH</h3>
<p style="text-align: justify;">J&rsquo;ai présenté haproxy parce que je le connais bien, et que j&rsquo;ai kiffé quand un collègue m&rsquo;a expliqué qu&rsquo;il faisait ça sur son serveur. Alors évidemment avec mon organisation, j&rsquo;ai mis plus de trois mois pour vous rédiger tout ça, mais voilà, c&rsquo;est fait. Mais Haproxy n&rsquo;est pas seul à permettre ce multiplexage de protocole.</p>
<p style="text-align: justify;">Pour faire du SSH et du HTTPS, il y a <a href="https://github.com/yrutschle/sslh" target="_blank" rel="noopener">SSLH</a>, contraction d&rsquo;SSL (nom original d&rsquo;un protocole qui s&rsquo;appelle désormais TLS, à la base du chiffrement d&rsquo;HTTPS et d&rsquo;OpenVPN) et d&rsquo;SSH, pour l&rsquo;ouverture sécurisée d&rsquo;un shell. Et cerise sur le gâteau, chose que je ne savais pas avant d&rsquo;avoir pratiquement fini d&rsquo;écrire cet article, il semble qu&rsquo;il supporte désormais aussi OpenVPN et même plusieurs autres protocoles. J&rsquo;ai pas creusé, du coup, je vous laisse découvrir, mais pour des accès à une infra derrière une livebox, ça pourrait être plus intéressant que de multiplier les ouvertures de ports et les solutions type rebond/bastion. Reste qu&rsquo;avec le HTTPS il y a toujours ces questions d&rsquo;adresses IP source dans les logs, et de ce que j&rsquo;ai lu, SSLH traite le problème de la même façon qu&rsquo;Haproxy, à savoir TPROXY.</p>
<p style="text-align: justify;">Vous l&rsquo;avez peut-être déjà utilisé, ou alors, si vous le mettez en place, n&rsquo;hésitez pas à partager vos retours, que ce soit ici en commentaire ou votre propre espace d&rsquo;expression, c&rsquo;est toujours sympa à voir en français <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/04/haproxy-openvpn-ou-ssh/feed/</wfw:commentRss>
            <slash:comments>4</slash:comments>
        </item>
        <item>
            <title>Gérer plusieurs versions de certains outils en ligne de commande</title>
            <link>https://blog.seboss666.info/2020/04/gerer-plusieurs-versions-de-certains-outils-en-ligne-de-commande/</link>
            <comments>https://blog.seboss666.info/2020/04/gerer-plusieurs-versions-de-certains-outils-en-ligne-de-commande/#comments</comments>
            <pubDate>Wed, 15 Apr 2020 16:30:42 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Astuces]]></category>
            <category><![CDATA[Sysadmin]]></category>
            <category><![CDATA[Ansible]]></category>
            <category><![CDATA[asdf-vm]]></category>
            <category><![CDATA[cli]]></category>
            <category><![CDATA[gestion]]></category>
            <category><![CDATA[helm]]></category>
            <category><![CDATA[kubernetes]]></category>
            <category><![CDATA[switch]]></category>
            <category><![CDATA[terraform]]></category>
            <category><![CDATA[tfenv]]></category>
            <category><![CDATA[utilitaires]]></category>
            <category><![CDATA[version]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6214</guid>
            <description><![CDATA[C&#8217;est un problème qu&#8217;on rencontre pas forcément quand on gère que du perso, mais quand on bosse sur une quantité importante de projets clients, il [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">C&rsquo;est un problème qu&rsquo;on rencontre pas forcément quand on gère que du perso, mais quand on bosse sur une quantité importante de projets clients, il arrive qu&rsquo;on doive jongler, pour différentes raisons, avec plusieurs versions différentes d&rsquo;outils divers et variés. Et souvent les « procédures d&rsquo;installation » (télécharger, copier dans /usr/local/bin, j&rsquo;appelle pas ça une procédure), ne prennent pas ce cas d&rsquo;usage en compte. je vais donc faire un inventaire de ce que j&rsquo;ai pu faire et que je fais encore aujourd&rsquo;hui pour gérer ça.</p>
<p style="text-align: justify;"><span id="more-6214"></span></p>
<p style="text-align: justify;">Les utilitaires que je manipule ces derniers mois ne sont pas obscurs : terraform, ansible, git, kubernetes, helm, pour ne citer qu&rsquo;eux, évoluent constamment, et apportent toujours plus de nouvelles possibilités. Sauf que ces outils ne servent qu&rsquo;à exécuter du code qui a été écrit à un instant T, donc avec la version disponible alors. Ou pas, j&rsquo;ai eu à bosser sur un projet terraform dont certains modules étaient encore figés à la syntaxe 0.11, donc pas le choix, sauf qu&rsquo;en parallèle, un projet interne utilisait la syntaxe 0.12. Il a donc fallu trouver une solution simple.</p>
<p style="text-align: justify;">Vous avez donc maintenant une meilleure idée, et quand le problème s&rsquo;est reproduit pour d&rsquo;autres outils, j&rsquo;ai cherché et trouvé d&rsquo;autres solutions.</p>
<h3 style="text-align: justify;">Terraform : tfenv</h3>
<p style="text-align: justify;">C&rsquo;est en effet probablement le premier pour lequel j&rsquo;ai eu à chercher une solution qui n&rsquo;était pas utilisable nativement, comme on le verra avec Ansible plus tard. Quand vous regardez la doc, c&rsquo;est « téléchargez, copiez dans un dossier du PATH, enjoy ». Et démerdez vous avec ça. Remarquez qu&rsquo;on trouve beaucoup trop cette solution basique avec les outils développés en Go, qui effectivement ne s&#8217;embarrassent pas trop de bibliothèques partagées car ils sont majoritairement compilés en statique, donc avec tout ce dont ils ont besoin. Ça vous fait un fichier binaire de plus de 100Mo, mais on va dire que c&rsquo;est un détail (regardez pas de trop près les providers terraform, vous allez vite vous pendre).</p>
<p style="text-align: justify;">Donc, pour pouvoir facilement switcher entre les versions de Terraform, et même gérer facilement les versions installées sur mon poste, j&rsquo;ai découvert un petit utilitaire très pratique : <a href="https://github.com/tfutils/tfenv" target="_blank" rel="noopener">tfenv</a>. Il est utilisable sous Linux et Mac (et apparemment sous Windows, dans git-bash), et permet d&rsquo;installer et de switcher facilement entre les versions de terraform. Le genre d&rsquo;outil qu&rsquo;on aurait aimé avoir en natif plutôt que du bête download de binaire, mais bon, on peut pas tout avoir.</p>
<p style="text-align: justify;">Pour l&rsquo;installation j&rsquo;ai fait le feignant et je suis passé par yay sur Manjaro, mais les instructions disponibles sur le README sont faciles à suivre.</p>
<h3 style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2020/04/tfenv.png" rel="lightbox[6214]"><img class="aligncenter size-medium wp-image-6228" src="https://blog.seboss666.info/wp-content/uploads/2020/04/tfenv-300x59.png" alt="" width="300" height="59" srcset="https://blog.seboss666.info/wp-content/uploads/2020/04/tfenv-300x59.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/04/tfenv-768x151.png 768w, https://blog.seboss666.info/wp-content/uploads/2020/04/tfenv-1024x201.png 1024w" sizes="(max-width: 300px) 100vw, 300px" /></a>Ansible : les virtualenv à la rescousse !</h3>
<p style="text-align: justify;">Eh oui, Ansible est un outil écrit en Python, et j&rsquo;avais parlé de comment utiliser les virtualenv très récemment pour utiliser <a href="https://blog.seboss666.info/2020/03/youtube-dl-sur-un-nas-synology-cest-possible/" target="_blank" rel="noopener">youtube-dl sur le NAS</a> de ma môman. Dans le cas d&rsquo;Ansible, j&rsquo;ai eu à jouer avec plus que la version, car là c&rsquo;était en fonction de la version de Python directement que j&rsquo;avais à switcher entre les virtualenv, certains modules utilisés n&rsquo;étant compatibles qu&rsquo;avec Python 2 (le mainteneur sait qu&rsquo;il doit repasser dessus pour les passer en python 3, mais ça demande du temps qu&rsquo;on facture pas au client, donc personne le fait &#8211; une sacrée connerie contre laquelle on se bat de plus en plus souvent&#8230;).</p>
<p style="text-align: justify;">Sur une machine où vous avez les deux versions de Python d&rsquo;installés, il faut donc vérifier si vous avez python2-virtualenv (souvent seulement appelé python-virtualenv) et python3-virtualenv, ou alors pour Python 3, reprendre la méthode avec le module intégré <code>python3 -m venv</code>.</p>
<p></p><pre class="crayon-plain-tag">~  .venv  ansible 
$ python --version
Python 3.8.2
 ~  .venv  ansible 
$ ansible --version
ansible 2.8.10
  config file = None
  configured module search path = ['/home/seboss666/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/seboss666/.venv/ansible/lib/python3.8/site-packages/ansible
  executable location = /home/seboss666/.venv/ansible/bin/ansible
  python version = 3.8.2 (default, Feb 26 2020, 22:21:03) [GCC 9.2.1 20200130]
 ~  .venv  ansible 
$ deactivate
 ~  .venv 
$ python -m venv ansible29
 ~  .venv 
$ source ansible29/bin/activate
 ~  .venv  ansible29 
$ pip install --upgrade pip
Collecting pip
  Using cached https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl
Installing collected packages: pip
  Found existing installation: pip 19.2.3
    Uninstalling pip-19.2.3:
      Successfully uninstalled pip-19.2.3
Successfully installed pip-20.0.2
 ~  .venv  ansible29 
$ pip install ansible
Collecting ansible
  Downloading ansible-2.9.6.tar.gz (14.2 MB)
     |████████████████████████████████| 14.2 MB 9.1 MB/s
Collecting jinja2
  Using cached Jinja2-2.11.1-py2.py3-none-any.whl (126 kB)
Collecting PyYAML
  Using cached PyYAML-5.3.1.tar.gz (269 kB)
Collecting cryptography
  Downloading cryptography-2.9-cp35-abi3-manylinux2010_x86_64.whl (2.7 MB)
     |████████████████████████████████| 2.7 MB 9.3 MB/s
Collecting MarkupSafe&gt;=0.23
  Using cached MarkupSafe-1.1.1-cp38-cp38-manylinux1_x86_64.whl (32 kB)
Collecting six&gt;=1.4.1
  Using cached six-1.14.0-py2.py3-none-any.whl (10 kB)
Collecting cffi!=1.11.3,&gt;=1.8
  Using cached cffi-1.14.0-cp38-cp38-manylinux1_x86_64.whl (409 kB)
Collecting pycparser
  Using cached pycparser-2.20-py2.py3-none-any.whl (112 kB)
Installing collected packages: MarkupSafe, jinja2, PyYAML, six, pycparser, cffi, cryptography, ansible
    Running setup.py install for PyYAML ... done
    Running setup.py install for ansible ... done
Successfully installed MarkupSafe-1.1.1 PyYAML-5.3.1 ansible-2.9.6 cffi-1.14.0 cryptography-2.9 jinja2-2.11.1 pycparser-2.20 six-1.14.0
 ~  .venv  ansible29 
$ ansible --version
ansible 2.9.6
  config file = None
  configured module search path = ['/home/seboss666/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/seboss666/.venv/ansible29/lib/python3.8/site-packages/ansible
  executable location = /home/seboss666/.venv/ansible29/bin/ansible
  python version = 3.8.2 (default, Feb 26 2020, 22:21:03) [GCC 9.2.1 20200130]</pre><p></p>
<p style="text-align: justify;">Pour certains projets, comme le code repose aussi sur des sdk de cloud provider, je crée un venv dédié qui embarque à la fois ansible et le sdk/cli concerné, aws et azure majoritairement pour l&rsquo;instant (j&rsquo;ai commencé à découvrir Google Cloud Platform très récemment, rien de transcendant). L&rsquo;aspect paradoxal de tout ça c&rsquo;est que je peux avoir plusieurs fois la même version d&rsquo;Ansible d&rsquo;installée, pour différentes versions de Python et des dépendances associées. Ça consomme plus de disque, mais bon, j&rsquo;ai plus de Windows pour m&#8217;emmerder avec ça et le SSD est loin d&rsquo;être saturé, le coût est donc plus que supportable.</p>
<h3 style="text-align: justify;">Kubernetes/helm, j&rsquo;ai sorti l&rsquo;artillerie lourde</h3>
<p style="text-align: justify;">Pour Kubernetes et Helm, je n&rsquo;ai pas trouvé de méthode maison ou un outil léger adapaté comme pour Terraform. Par contre, je suis tombé sur la rolls, de celles qui pourraient au final remplacer aussi tfenv pour terraform, car elle repose sur un système de plugins.</p>
<p style="text-align: justify;">asdf Version Manager est cette rolls. Je vous laisse regarder <a href="https://asdf-vm.com/#/plugins-all" target="_blank" rel="noopener">la liste des plugins</a> pour comprendre la palette de possibilités de gestion d&rsquo;outils, j&rsquo;ai donc pour ma part pour l&rsquo;instant utilisé ceux de kubectl et d&rsquo;helm. kubectl parce que l&rsquo;utilitaire pour manipuler ses cluster Kubernetes a une palette certes large de compatibilité entre versions serveur et client, mais y&rsquo;a des limites, et si vous avez un kubectl en 1.16.x, et que vous avez le malheur de devoir manipuler un cluster qui est encore installé en 1.12.x, vous vous engagez sur une pente plus que glissante, car la version 1.16 a mis à la retraite bon nombre d&rsquo;API qui étaient en service sur l&rsquo;ancien. Helm parce qu&rsquo;entre la version 2 et la version 3 c&rsquo;est le jour et la nuit sur le fonctionnement, et que des packages installés avec la version 2 ne peuvent pas être gérés simplement de manière transparente du jour au lendemain avec la version 3. D&rsquo;autant plus quand vous utilisez le provider pour terraform.</p>
<p></p><pre class="crayon-plain-tag">~ 
$ asdf plugin-add kubectl
initializing plugin repository...
Clonage dans '/home/seboss666/.asdf/repository'...
remote: Enumerating objects: 96, done.
remote: Counting objects: 100% (96/96), done.
remote: Compressing objects: 100% (84/84), done.
remote: Total 1743 (delta 41), reused 38 (delta 12), pack-reused 1647
Réception d'objets: 100% (1743/1743), 393.01 Kio | 1.36 Mio/s, fait.
Résolution des deltas: 100% (760/760), fait.
 ~ 
$ asdf list-all
No plugin given
 ~  ✘ 1 
$ asdf list-all kubectl
1.14.10
1.15.7
1.15.8
1.15.9
1.15.10
1.15.11
1.16.3
1.16.4
1.16.5
1.16.6
1.16.7
1.16.8
1.17.0-rc.1
1.17.0-beta.2
1.17.0-rc.2
1.17.0
1.17.1
1.17.2
1.17.3
1.17.4
1.18.0-alpha.1
1.18.0-beta.1
1.18.0-rc.1
1.18.0-alpha.2
1.18.0-beta.2
1.18.0-alpha.3
1.18.0-alpha.5
1.18.0
1.18.1
1.19.0-alpha.1
 ~ 
$ asdf install kubectl 1.16.8
Downloading kubectl from https://storage.googleapis.com/kubernetes-release/release/v1.16.8/bin/linux/amd64/kubectl
 ~ 
$ asdf global kubectl 1.16.8
 ~ 
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"16", GitVersion:"v1.16.8", GitCommit:"ec6eb119b81be488b030e849b9e64fda4caaf33c", GitTreeState:"clean", BuildDate:"2020-03-12T21:00:06Z", GoVersion:"go1.13.8", Compiler:"gc", Platform:"linux/amd64"}
The connection to the server localhost:8080 was refused - did you specify the right host or port?</pre><p></p>
<p style="text-align: justify;">Et ça ce ne sont que les utilitaires, mais dans les plugins vous pouvez aussi bosser carrément avec des versions différentes de langages de programmation, comme nodejs, ruby, et j&rsquo;en passe, c&rsquo;est donc très pratique dans un environnement de développement, et pour se passer de docker qui a ses propres contraintes. Attention toutefois, asdf est vraiment pensé pour un usage sur poste local, ce n&rsquo;est pas un outil de déploiement en production, je recommande vivement soit de passer par Docker, soit d&rsquo;adapter l&rsquo;environnement pour votre application en installant plus proprement (idéalement via package manager pour gérer les mises à jour auto). Je pense par exemple aux software collections sur Redhat/CentOS qui permettent de multiplier les versions de certains langages (coucou PHP).</p>
<p style="text-align: justify;">Bref, s&rsquo;il ne devait en rester qu&rsquo;un, ça serait probablement celui-là. Surtout que si le plugin dont vous auriez besoin n&rsquo;existe pas encore, vous avez tout à fait la possibilité de l&rsquo;écrire vous-même <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<h3 style="text-align: justify;">Et vous, vous faites comment ?</h3>
<p style="text-align: justify;">Mon manager repose désormais exclusivement sur Docker pour ce genre de besoins. Il garde soigneusement quantité de containers et d&rsquo;images qu&rsquo;il redémarre à la volée quand il en a besoin, mais je trouve la solution plus lourde et moins naturelle par rapport au reste de l&rsquo;usage du système.</p>
<p style="text-align: justify;">Mais vous avez probablement vos propres routines pour ce genre de situation, je suis curieux de les découvrir, alors, comment ça jongle ?</p>
<p style="text-align: justify;"><strong>PS</strong> : le très partageur Cascador, qui a fait un petit namedrop sur systemd-nspawn, sans préciser qu&rsquo;il a carrément fait <a href="https://www.blog-libre.org/2020/04/17/une-presentation-de-systemd-nspawn/" target="_blank" rel="noopener">un article dessus</a> <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/04/gerer-plusieurs-versions-de-certains-outils-en-ligne-de-commande/feed/</wfw:commentRss>
            <slash:comments>4</slash:comments>
        </item>
        <item>
            <title>Quelques astuces diverses, dix-huitième</title>
            <link>https://blog.seboss666.info/2020/04/quelques-astuces-diverses-dix-huitieme/</link>
            <pubDate>Sun, 12 Apr 2020 08:30:06 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Astuces diverses]]></category>
            <category><![CDATA[alias]]></category>
            <category><![CDATA[bash]]></category>
            <category><![CDATA[décodage]]></category>
            <category><![CDATA[git]]></category>
            <category><![CDATA[kubernetes]]></category>
            <category><![CDATA[Manjaro]]></category>
            <category><![CDATA[nmap]]></category>
            <category><![CDATA[ssh]]></category>
            <category><![CDATA[steam]]></category>
            <category><![CDATA[sublime text]]></category>
            <category><![CDATA[vlc]]></category>
            <category><![CDATA[worms]]></category>
            <category><![CDATA[WSL]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6107</guid>
            <description><![CDATA[Cela fait beaucoup trop longtemps que je n&#8217;ai pas sorti de nouvel épisode de ces astuces en tout genre (Novembre 2019 !). Mais elles existent [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Cela fait beaucoup trop longtemps que je n&rsquo;ai pas sorti de nouvel épisode de ces astuces en tout genre (Novembre 2019 !). Mais elles existent toujours, et voilà enfin un nouvel épisode.</p>
<p style="text-align: justify;"><span id="more-6107"></span></p>
<h3 style="text-align: justify;">Un nmap fonctionnel sur WSL</h3>
<p style="text-align: justify;">J&rsquo;en ai parlé, j&rsquo;ai pas mal expérimenté avec <a href="https://blog.seboss666.info/?s=wsl" target="_blank" rel="noopener">le WSL 1</a> sur mon installation de Windows à destination du PC de jeu, pour limiter mon recours à une machine virtuelle Linux. Parmi les problèmes/limitations que j&rsquo;ai pu rencontrer, il y a l&rsquo;utilisation d&rsquo;nmap. En effet, le binaire Linux m&rsquo;a gratifié d&rsquo;une palanquée de messages d&rsquo;erreur bien salaces. Pas étonnant, il cherche à demander des infos bas niveau au noyau Linux, qui n&rsquo;existe pas&#8230;</p>
<p style="text-align: justify;">J&rsquo;ai du coup découvert qu&rsquo;on pouvait lancer des binaires Windows depuis le WSL, et donc, la solution recommandée dans ce cas est d&rsquo;installer la version Windows d&rsquo;nmap <a href="https://nmap.org/download.html" target="_blank" rel="noopener">depuis le site officiel</a> et seulement lui, qui elle va utiliser les sous-systèmes du noyal Windows pour faire son job, sans erreur donc. Pour l&rsquo;appeler ensuite de manière transparente, un alias suffit dans votre environnement :</p>
<p></p><pre class="crayon-plain-tag">alias nmap='"/mnt/c/Program Files (x86)/Nmap/nmap.exe"'</pre><p></p>
<p style="text-align: justify;">Je vous laisse adapter le chemin si vous avez modifié les points de montages pour une <a href="https://blog.seboss666.info/2019/11/windows-wsl-et-docker-mode-demploi/" target="_blank" rel="noopener">utilisation de Docker</a>.</p>
<h3 style="text-align: justify;">Fermer la fenêtre principale de Steam sous Manjaro Linux</h3>
<p style="text-align: justify;">Si vous êtes aussi sous Manjaro et que vous utilisez Steam, vous aurez certainement remarqué un comportement par défaut plutôt pénible par rapport à Windows : malgré la présence de l&rsquo;icône de notifications, fermer la fenêtre principale ne fait que la réduire.</p>
<p style="text-align: justify;">C&rsquo;est une mesure prise à cause de certains bureaux où l&rsquo;icône déconne et laisse traîner un process zombie à la fin, ce qui empêche de relancer correctement le client derrière. Mais on peut modifier ce comportement avec une variable d&rsquo;environnement, et je vous recommande de la mettre justement dans <span style="font-family: couriernew,courier,monospace;">/etc/environment</span> :</p>
<p></p><pre class="crayon-plain-tag">STEAM_FRAME_FORCE_CLOSE=1</pre><p></p>
<p style="text-align: justify;">Normalement ce comportement est spécifique à Manjaro, mais si d&rsquo;aventure vous le rencontrez ailleurs, vous savez par où commencer.</p>
<h3 style="text-align: justify;">Correctement utiliser l&rsquo;accélération du décodage vidéo Intel avec VLC</h3>
<p style="text-align: justify;">J&rsquo;ai passé un peu de temps à pester contre ça, d&rsquo;autant que c&rsquo;est beaucoup mieux géré sous Windows. En effet, je pensais avoir suivi les recommandations du <a href="https://wiki.archlinux.org/index.php/Hardware_video_acceleration#Intel" target="_blank" rel="noopener">Wiki Archlinux</a>, j&rsquo;avais, droit à ça :</p>
<ul style="text-align: justify;">
<li>intel-media-driver =&gt; ok</li>
<li>libva =&gt; ok</li>
<li>vainfo =&gt; ko :</li>
</ul>
<p></p><pre class="crayon-plain-tag">$ vainfo
vaInitialize failed with error code -1 (unknown libva error),exit</pre><p></p>
<p style="text-align: justify;">Et quand on lance VLC, dans les messages on peut voir ça :</p>
<p></p><pre class="crayon-plain-tag">[00007f6c9c001f70] glconv_vaapi_x11 gl error: vaInitialize: unknown libva error
[00007f6c9c001f70] glconv_vaapi_drm gl error: vaInitialize: unknown libva error
libva error: va_getDriverName() failed with operation failed,driver_name=i965</pre><p></p>
<p style="text-align: justify;">Moralité la conso CPU est bien vénère avec un VLC qui mange facile les trois quarts du CPU au global pour la lecture d&rsquo;une vidéo full HD.</p>
<p style="text-align: justify;">La solution : la variable d&rsquo;environnement. Il suffit d&rsquo;ajouter le bon nom à la variable <span style="font-family: couriernew,courier,monospace;">LIBVA_DRIVER_NAME</span>, et le tour est joué :</p>
<p></p><pre class="crayon-plain-tag">$ LIBVA_DRIVER_NAME=iHD vainfo
vainfo: VA-API version: 1.5 (libva 2.5.0)
vainfo: Driver version: Intel iHD driver - 1.0.0
vainfo: Supported profile and entrypoints
(...)</pre><p></p>
<p style="text-align: justify;">Et quand on lance VLC avec :</p>
<p></p><pre class="crayon-plain-tag">[00007fe6e590ee90] avcodec decoder: Using Intel iHD driver - 1.0.0 for hardware decoding</pre><p></p>
<p style="text-align: justify;">Je recommande de la coller dans <span style="font-family: couriernew,courier,monospace;">/etc/environment</span>, ça permet d&rsquo;être le plus large possible dans sa prise en compte. Voilà, personne est foutu de se parler correctement pour s&rsquo;identifier afin d&rsquo;être exploité comme il faut. C&rsquo;est la magie du libre. Ah et non, ça suffit pas pour que ça fonctionne sous Firefox, là c&rsquo;est encore pire en terme de conso CPU, et j&rsquo;ai pas encore réussi malgré une fois encore la présence des paquets.</p>
<h3 style="text-align: justify;">Git : cloner une seule branche (pour un test)</h3>
<p style="text-align: justify;">Quand on veut gagner un peu de temps sur un simple test rapide autour d&rsquo;un code d&rsquo;un dépôt git, et que ce code se trouve dans une branche spécifique, on peut directement cloner cette branche-là uniquement :</p>
<p></p><pre class="crayon-plain-tag">git clone -b my-dev-branch --single-branch https://gitforge.domain/user/my_super_repo</pre><p></p>
<p style="text-align: justify;">En l&rsquo;occurrence, je testais la branche d&rsquo;un mec qui cherchait à dockeriser son appli et qui rencontrait des problèmes au build sous Manjaro <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /> (et moi une appli JS, en temps normal je m&rsquo;en approche pas, donc pas besoin de récupérer tout le dépôt pour un simple test, surtout sur la petite connexion de ma petite sœur).</p>
<h3 style="text-align: justify;">Une déconnexion automatique sur vos sessions SSH inactives</h3>
<p style="text-align: justify;">Découvert chez un client y&rsquo;a pas longtemps, si vous laissez une connexion SSH ouverte sans rien en faire, elle est déconnectée automatiquement au bout d&rsquo;un certain temps. J&rsquo;ai cherché comment ils faisaient, c&rsquo;est via une variable d&rsquo;environnement, soit dans le /etc/profile pour l&rsquo;appliquer de manière globale, soit dans votre bashrc, pour que ça ne concerne que l&rsquo;utilisateur :</p>
<p></p><pre class="crayon-plain-tag">export readonly TMOUT=900</pre><p></p>
<p style="text-align: justify;">Le temps est en secondes. Au passage, double astuce puisqu&rsquo;on voit ici qu&rsquo;on définit la variable en lecture seule.</p>
<h3 style="text-align: justify;">Mise à jour du paquet AUR ttf-sil-fonts sur ArchLinux/Manjaro</h3>
<p style="text-align: justify;">Ce paquet, qui avait été laissé à l&rsquo;abandon, a été repris récemment par un autre mainteneur. Mais le format a changé, avant il se chargeait directement de l&rsquo;installation, maintenant c&rsquo;est un meta-paquet qui installe chaque police qui se trouve dans un paquet indépendant. Ce qui cause des conflits avec des polices déjà installées. La solution la plus simple c&rsquo;est de désinstaller le paquet, et de le réinstaller dans la foulée :</p>
<p></p><pre class="crayon-plain-tag">yay -R ttf-sil-fonts
yay -S ttf-sil-fonts</pre><p></p>
<p style="text-align: justify;">Ça vous évitera comme moi de faire des trucs sales à base de déplacement des fichiers qui existent déjà dans les dossiers cible <img src="https://s.w.org/images/core/emoji/11/72x72/1f600.png" alt="😀" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<h3 style="text-align: justify;">Worms WMD et ArchLinux/Manjaro, c&rsquo;est compliqué (mais ça se soigne)</h3>
<p style="text-align: justify;">Le jeu est disponible nativement sous Linux mais la maintenance par Team17 n&rsquo;est pas vraiment au beau fixe. En particulier, avec les évolutions permanentes d&rsquo;ArchLinux, c&rsquo;est simple, par défaut le jeu ne démarre pas. Pour corriger, il faut modifier le script de lancement, pour qu&rsquo;il ressemble à ça :</p>
<p></p><pre class="crayon-plain-tag">#!/bin/bash

GAMEPATH="$(dirname "$(realpath $0)")"
export LC_ALL=C
export LD_LIBRARY_PATH="${GAMEPATH}/lib:${LD_LIBRARY_PATH}"
export DBUS_FATAL_WARNINGS=0

chmod a+x ./Worms\ W.M.Dx64
./Worms\ W.M.Dx64</pre><p></p>
<p style="text-align: justify;">C&rsquo;est plus fourni et surtout ça permet d&rsquo;utiliser les bibliothèques Steam plutôt que les bibliothèques natives. Dans tous les cas, n&rsquo;espérez pas faire des parties classées en ligne, la connexion aux serveurs Team17 ne fonctionne pas. Heureusement le multijoueur avec des amis fonctionne quand même, ouf.</p>
<h3 style="text-align: justify;">Franciser Sublime Text ? C&rsquo;est possible</h3>
<p style="text-align: justify;">Bon personnellement, ça ne m&#8217;empêche pas de continuer à bosser en anglais, mais en effet, pour ceux qui s&rsquo;en servent, un reproche qui lui est souvent fait est d&rsquo;être « english centric ». Par chance, avec la façon dont est construite l&rsquo;interface, elle est hautement personnalisable. Et pour ça, il suffit d&rsquo;installer le paquet LocalizedMenu avec Package Manager, et sélectionner la langue via le menu Preferences, et voilà :</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2019/12/sublime_localized.png" rel="lightbox[6107]"><img class="aligncenter size-medium wp-image-6220" src="https://blog.seboss666.info/wp-content/uploads/2019/12/sublime_localized-300x82.png" alt="" width="300" height="82" srcset="https://blog.seboss666.info/wp-content/uploads/2019/12/sublime_localized-300x82.png 300w, https://blog.seboss666.info/wp-content/uploads/2019/12/sublime_localized-768x209.png 768w, https://blog.seboss666.info/wp-content/uploads/2019/12/sublime_localized-1024x279.png 1024w, https://blog.seboss666.info/wp-content/uploads/2019/12/sublime_localized.png 1121w" sizes="(max-width: 300px) 100vw, 300px" /></a></p>
<p style="text-align: justify;">Pour le reste, je vous laisse regarder <a href="https://github.com/zam1024t/LocalizedMenu" target="_blank" rel="noopener">le dépôt Git</a>.</p>
<h3 style="text-align: justify;">Lancer une commande originale et pas son alias</h3>
<p style="text-align: justify;">Vous le savez j&rsquo;adore les alias de bash, j&rsquo;en utilise pas mal. Le problème c&rsquo;est que parfois on aurait besoin de comparer avec la commande « brute », fort heureusement, il n&rsquo;y a pas besoin de détruire l&rsquo;alias, il suffit de préfixer la commande avec un antislash :</p>
<p style="text-align: justify;"><a href="https://blog.seboss666.info/wp-content/uploads/2020/03/original_command.png" rel="lightbox[6107]"><img class="aligncenter size-medium wp-image-6225" src="https://blog.seboss666.info/wp-content/uploads/2020/03/original_command-300x26.png" alt="" width="300" height="26" srcset="https://blog.seboss666.info/wp-content/uploads/2020/03/original_command-300x26.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/03/original_command-768x65.png 768w, https://blog.seboss666.info/wp-content/uploads/2020/03/original_command-1024x87.png 1024w" sizes="(max-width: 300px) 100vw, 300px" /></a>Ça permet de voir parfois les problèmes visuels que les personnalisations engendrent <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<h3 style="text-align: justify;">Kubernetes, communications réseau inter-containers dans un même pod</h3>
<p style="text-align: justify;">Un collègue m&rsquo;a posé la question récemment, et j&rsquo;avais pas la réponse, alors j&rsquo;ai cherché. Il expérimentait k3s, et voulait déployer un ethercalc, qui utilise une appli nodejs et un serveur redis pour le stockage des classeurs. Hors il a mis les deux containers dans le même pod, donc pas de service pour le redis :</p>
<p></p><pre class="crayon-plain-tag">apiVersion: apps/v1
kind: Deployment
metadata:
  name: calc
spec:
  replicas: 1
  selector:
    matchLabels:
      app: calc
  template:
    metadata:
      labels:
        app: calc
    spec:
      containers:
        - name: ethercalc
          image: audreyt/ethercalc:latest
          ports:
            - containerPort: 8000
          env:
            - name: REDIS_PORT_6379_TCP_ADDR
              value: redis
            - name: REDIS_PORT_6379_TCP_PORT
              value: "6379"
          imagePullPolicy: Always
        - name: redis
          image: redis:latest
          volumeMounts:
            - name: redis-data
              mountPath: /data
          imagePullPolicy: Always</pre><p></p>
<p style="text-align: justify;">On voit qu&rsquo;il tente de mettre le nom du container dans la variable <span style="font-family: courier new, courier, monospace;">REDIS_PORT_6379_TCP_ADDR</span>, et ça ne fonctionne pas. Et bien j&rsquo;ai appris que dans ce cas, Kubernetes place les deux containers dans le même réseau, ce qui veut dire qu&rsquo;on peut contacter le container voisin sur son port en utilisant « localhost » directement !</p>
<hr />
<p style="text-align: justify;">Voilà, c&rsquo;est tout pour aujourd&rsquo;hui, vous l&rsquo;aurez compris, j&rsquo;abandonne pas la série mais faut pas s&rsquo;attendre à voir un nouvel épisode dans moins d&rsquo;un mois <img src="https://s.w.org/images/core/emoji/11/72x72/1f600.png" alt="😀" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
]]></content:encoded>
        </item>
        <item>
            <title>Powerline.bash, le retour !</title>
            <link>https://blog.seboss666.info/2020/03/powerline-bash-le-retour/</link>
            <comments>https://blog.seboss666.info/2020/03/powerline-bash-le-retour/#comments</comments>
            <pubDate>Mon, 30 Mar 2020 16:30:23 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Astuces]]></category>
            <category><![CDATA[Sysadmin]]></category>
            <category><![CDATA[bash]]></category>
            <category><![CDATA[lourdeur]]></category>
            <category><![CDATA[portabilité]]></category>
            <category><![CDATA[powerline]]></category>
            <category><![CDATA[python]]></category>
            <category><![CDATA[shell]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6217</guid>
            <description><![CDATA[Pour ceux qui lisent le blog depuis un moment, vous savez que j&#8217;utilise Powerline pour décorer mon shell, ainsi que celui de mes machines virtuelles [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Pour ceux qui lisent le blog depuis un moment, vous savez que j&rsquo;utilise Powerline <a href="https://blog.seboss666.info/2018/08/je-suis-passe-a-powerline-pour-mon-bash/" target="_blank" rel="noopener">pour décorer mon shell</a>, ainsi que celui de mes machines virtuelles à la maison. Dans l&rsquo;ensemble j&rsquo;en suis très content, mais le projet qui m&rsquo;avait lancé sur la personnalisation de mon shell, powerline.bash, est revenu sous mes yeux, et oui, j&rsquo;ai craqué, j&rsquo;ai décidé de basculer dessus. Voyons donc pourquoi.</p>
<p style="text-align: justify;"><span id="more-6217"></span></p>
<p style="text-align: justify;">Si vous avez relu mon billet d&rsquo;origine, l&rsquo;installation de Powerline, notamment pour avoir un statut git assez visuel est assez lourde, en gros, en plus des paquets powerline et powerline-fonts, il me faut en plus <a href="https://pypi.org/project/powerline-gitstatus/" target="_blank" rel="noopener">un paquet pip</a> et une configuration maison plutôt chargée à pousser. Autant dire que le contenu du playbook ansible pour déployer tout ça est assez fat, mais bon, c&rsquo;est pas non plus la mort.</p>
<p style="text-align: justify;">Powerline a ses propres problèmes, et certains m&rsquo;avaient d&rsquo;ailleurs été relevés. Le principal, c&rsquo;est la latence. Il arrive parfois qu&rsquo;il mette un temps visible à rendre la main, ouvrir un nouveau shell, et le problème empire quand votre CPU est déjà particulièrement chargé comme c&rsquo;est souvent le cas dernièrement sur mon laptop du boulot. J&rsquo;ai en plus eu des soucis à l&rsquo;époque de la bascule Python 3.7 &gt; 3.8 sous Manjaro, ce qui m&rsquo;avait poussé à devoir tout refaire (en gros j&rsquo;avais plus de prompt le temps que je corrige). Je n&rsquo;ai jamais réussi non plus à l&rsquo;avoir sur deux lignes, et plusieurs tentatives pour personnaliser plus avant se sont toujours soldées par des échecs. Je ne pense pas être plus bête qu&rsquo;un autre, mais là quand même&#8230; Il y a certainement d&rsquo;autres contrariétés qui ne me reviennent pas en tête là tout de suite, mais voilà, j&rsquo;ai été donc frustré plus d&rsquo;une fois avec son utilisation.</p>
<h3 style="text-align: justify;">« Ha, ha, ha, ha, staying alive&#8230; »</h3>
<p style="text-align: justify;">Et au gré de mes flux RSS, Etienne Bersac, le développeur de powerline.bash, a fait un <a href="https://linuxfr.org/users/bersace/journaux/actualite-de-powerline-bash-optimisations-icones-nouveaux-segments-et-plus" target="_blank" rel="noopener">journal sur linuxfr</a> pour discuter des mises à jour. C&rsquo;était l&rsquo;occasion de découvrir que contrairement à ce que je pensais, je n&rsquo;avais pas activé les notifications sur le dépôt, ça m&rsquo;apprendra à être plus vigilant. Donc, depuis le temps, il y a eu pas mal de petits raffinements et de corrections, de nouveaux segments, via des contributions externes, et celui sur git a bien évolué. C&rsquo;est beaucoup plus intéressant désormais.</p>
<p style="text-align: justify;">J&rsquo;ai donc retesté le bousin, l&rsquo;installation et la configuration sont toujours aussi simples, ça tient à un git clone et l&rsquo;ajout de deux lignes dans le bash_aliases. Dans mon cas évidemment, ça demande aussi de virer/commenter les lignes nécessaires à Powerline.</p>
<p style="text-align: justify;">Je vais la faire courte, j&rsquo;ai tout de suite été conquis. Certes, les détails concernant le statut du dépôt git sont un peu moins fournies (j&rsquo;avais le nombre de fichiers avec leur statut quand le dépôt n&rsquo;était pas à jour, ainsi que le nombre de commits à pousser), mais c&rsquo;est désormais plus parlant, les couleurs sont mieux choisies, on voit qu&rsquo;on a des trucs à pousser, il y a le support de plus d’icônes. Et c&rsquo;est finalement largement suffisant pour éviter de lancer des commandes sans avoir bien vérifié le statut du dépôt auparavant, ça économise pas mal de commandes git status, toujours bon à prendre.</p>
<div id="attachment_6218" style="width: 310px" class="wp-caption aligncenter"><a href="https://blog.seboss666.info/wp-content/uploads/2020/03/powerline_updated.png" rel="lightbox[6217]"><img class="wp-image-6218 size-medium" src="https://blog.seboss666.info/wp-content/uploads/2020/03/powerline_updated-300x45.png" alt="" width="300" height="45" srcset="https://blog.seboss666.info/wp-content/uploads/2020/03/powerline_updated-300x45.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/03/powerline_updated-768x116.png 768w, https://blog.seboss666.info/wp-content/uploads/2020/03/powerline_updated-900x139.png 900w, https://blog.seboss666.info/wp-content/uploads/2020/03/powerline_updated.png 923w" sizes="(max-width: 300px) 100vw, 300px" /></a><p class="wp-caption-text">Dossier, venv python, statut git, tout ce qu&rsquo;il faut quoi <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p></div>
<p style="text-align: justify;">Quant à la vitesse de chargement et de réponse, c&rsquo;est évidemment le jour et la nuit. J&rsquo;ai donc entrepris de rebasculer mon profil dessus sur tous mes serveurs. l&rsquo;occasion de reprendre mes playbooks pour les remettre au gout du jour, cela faisait un moment qu&rsquo;ils n&rsquo;avaient pas été lancés, et j&rsquo;ai également découvert plusieurs manques ou faiblesses (genre le playbook qui supprime la ligne pour charger acme.sh sur le bastion&#8230;). Petite particularité par rapport à la doc, j&rsquo;ai opté pour un déploiement du dépôt dans /opt, comme ça il n&rsquo;est cloné qu&rsquo;une fois pour tous les utilisateurs que je modifie. Le module git d&rsquo;ansible se chargera des pull la prochaine fois, et voilà.</p>
<p style="text-align: justify;">Et je pense que je vais envisager de le pousser aussi sur mes serveurs « publics », comme celui que j&rsquo;utilise pour ce blog (qui va vraiment avoir besoin qu&rsquo;on lui refasse une beauté, ça devient intenable).</p>
<p style="text-align: justify;">En tout cas, c&rsquo;est du beau boulot, encore merci à Etienne, ainsi qu&rsquo;aux contributeurs qui sont mentionnés dans le README. Je ne dis pas que j&rsquo;en ferai partie dans un futur proche, mais j&rsquo;avais déjà participé à l&rsquo;époque en terme de <a href="https://gitlab.com/bersace/powerline.bash/-/issues/3" target="_blank" rel="noopener">remontée de bug sur Ubuntu 16.04</a> &#8211; eh oui, tant qu&rsquo;il est supporté, on doit le prendre en compte, même s&rsquo;il sent vraiment la naphtaline maintenant-, et j&rsquo;ai le segment Kubernetes à tester sur le pc du boulot (pas encore à la maison, je pense qu&rsquo;en termes de priorité la VM du blog est prioritaire). Donc y&rsquo;a peut⁻être encore des trucs à remonter ou contribuer <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/03/powerline-bash-le-retour/feed/</wfw:commentRss>
            <slash:comments>2</slash:comments>
        </item>
        <item>
            <title>Youtube-dl sur un NAS Synology, c&#8217;est possible !</title>
            <link>https://blog.seboss666.info/2020/03/youtube-dl-sur-un-nas-synology-cest-possible/</link>
            <comments>https://blog.seboss666.info/2020/03/youtube-dl-sur-un-nas-synology-cest-possible/#comments</comments>
            <pubDate>Wed, 25 Mar 2020 17:30:01 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Astuces]]></category>
            <category><![CDATA[nas]]></category>
            <category><![CDATA[performances]]></category>
            <category><![CDATA[python]]></category>
            <category><![CDATA[ssh]]></category>
            <category><![CDATA[synology]]></category>
            <category><![CDATA[vidéo]]></category>
            <category><![CDATA[virtualenv]]></category>
            <category><![CDATA[youtube]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6211</guid>
            <description><![CDATA[En partant chez ma mère pour mieux vivre le confinement prolongé qui se profile devant nous, j&#8217;ai embarqué son NAS trop longtemps en maintenance avec [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">En partant chez ma mère pour mieux vivre le confinement prolongé qui se profile devant nous, j&rsquo;ai embarqué son NAS trop longtemps en maintenance avec un disque dur neuf pour le remettre en service. Et parmi ce que j&rsquo;ai prévu de lui faire faire, il y a la même chose que chez moi, sauf que le Download Station embarqué ne sait plus récupérer les vidéos sur YouTube. Qu&rsquo;à cela ne tienne il y a une solution !</p>
<p style="text-align: justify;"><span id="more-6211"></span></p>
<h3 style="text-align: justify;">Le NAS</h3>
<p style="text-align: justify;">Le NAS est un ancien Synology DS215j. C&rsquo;est un modèle pouvant accueillir deux disques, avec un processeur Armada 375 plus que poussif, et un système d&rsquo;exploitation basé sur Linux mais avec une interface web de gestion qui est d&rsquo;une lenteur hallucinante. Je l&rsquo;avais acheté après la mort de mon serveur perso monté avec des composants d&rsquo;occasion qui est en fait toujours en vie, seulement un des disques était mort, mais je n&rsquo;avais pas eu suffisamment confiance pour relancer cette machine dont la consommation ne me convenait plus.</p>
<p style="text-align: justify;">Ce NAS était équipé de deux disques de 2To, configurés en SHR, parce que Synology ne pose pas la question à l&rsquo;installation et utilise son RAID maison. Déjà ça m&rsquo;avait gonflé, et à l&rsquo;époque je n&rsquo;avais pas plus creusé que ça et je l&rsquo;avais laissé en l&rsquo;état. Mais avec la saturation des disques, et leur âge grandissant couplé au bruit plus important de leur mécanique, je l&rsquo;avais embarqué pour lui refaire une santé et une upgrade de disque.</p>
<p style="text-align: justify;">Cette période de maintenance s&rsquo;est donc terminée avec la remise en service sur un unique disque dur de 4To, le seul en état de marche à disposition, qui était destiné à mon propre NAS, qui pourra attendre pendant mon absence.</p>
<h3 style="text-align: justify;">DSM 6 sur ce NAS, c&rsquo;est l&rsquo;enfer</h3>
<p style="text-align: justify;">Et c&rsquo;est peu de le dire. Si visuellement peu de choses ont changé dans l&rsquo;interface du système d&rsquo;exploitation de Synology, la gourmandise en performance est là : la moindre action fait grimper le CPU dans les tours, un simple listing des trois pauvres dossiers partagés créés suffit, c&rsquo;est bien simple, chaque action prend plusieurs secondes pour voir son résultat. Et ce n&rsquo;est pas que côté serveur, le navigateur en prend aussi pour son grade, je ne sais pas avec quels pieds de lépreux l&rsquo;interface a été codée, mais c&rsquo;est une catastrophe.</p>
<p style="text-align: justify;">Malgré tout, les fonctionnalités sont là, à part que le Download Station ne sait plus récupérer les vidéos YouTube. Apparemment il ne repose pas sur youtube-dl comme Takeasy sur Asustor (mais qui n&rsquo;a pas été mis à jour depuis plus d&rsquo;un mois, ce qui fait que certains sites auparavant supportés ne fonctionnent plus).</p>
<h3 style="text-align: justify;">« Oh mais y&rsquo;a Python 3 ! »</h3>
<p style="text-align: justify;">La lumière au bout du tunnel <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /> En effet, dans le gestionnaire de paquets de DSM, il est possible d&rsquo;installer Python 3, en pus de Python 2 qui est déjà installé. L&rsquo;installation via l&rsquo;interface est simple, comme n&rsquo;importe quel paquet. Reste ensuite à activer SSH et les home directory, pour ensuite se connecter à son compte en ligne de commande.</p>
<p style="text-align: justify;">Youtube-dl s&rsquo;installe via pip. Mais par défaut, pip ne semble pas disponible. Arf. Mais c&rsquo;est partiellement faux. De toute façon, pour tout projet qui nécessite d&rsquo;utiliser pip, il est recommandé de passer par un virtualenv, un environnement virtuel adapté à un projet en particulier. Et ça tombe bien, python 3 permet d&rsquo;en créer d&rsquo;une manière particulièrement simple :</p>
<p></p><pre class="crayon-plain-tag">seboss666@Mariz_NAS:~$ python3 -m venv yt</pre><p></p>
<p style="text-align: justify;">Et hop, quelques longues secondes après, on a un dossier yt qui contient notre virtualenv :</p>
<p></p><pre class="crayon-plain-tag">seboss666@Mariz_NAS:~/yt$ ll
total 36
drwxr-xr-x 7 seboss666 users 4096 Mar 22 22:53 .
drwxr-xr-x 5 seboss666 users 4096 Mar 22 22:51 ..
drwxr-xr-x 2 seboss666 users 4096 Mar 22 22:53 bin
drwxr-xr-x 4 seboss666 users 4096 Mar 22 22:53 etc
drwxr-xr-x 2 seboss666 users 4096 Mar 22 22:51 include
drwxr-xr-x 3 seboss666 users 4096 Mar 22 22:51 lib
-rw-r--r-- 1 seboss666 users   61 Mar 22 22:52 pip-selfcheck.json
-rw-r--r-- 1 seboss666 users   75 Mar 22 22:51 pyvenv.cfg
drwxr-xr-x 4 seboss666 users 4096 Mar 22 22:53 share</pre><p></p>
<p style="text-align: justify;">Ensuite on l&rsquo;active comme n&rsquo;importe quel venv :</p>
<p></p><pre class="crayon-plain-tag">seboss666@Mariz_NAS:~/yt$ source bin/activate
(yt) seboss666@Mariz_NAS:~$ pip --version
pip 7.1.2 from /volume1/homes/seboss666/yt/lib/python3.5/site-packages (python 3.5)</pre><p></p>
<p style="text-align: justify;">Notez le petit (yt) qui permet de visualiser qu&rsquo;on est dans un virtualenv python. Et surprise, pip est bien présent ! Par contre il sent fort la napthaline. On va donc en profiter pour le mettre à jour, et tenter d&rsquo;installer youtube-dl :</p>
<p></p><pre class="crayon-plain-tag">(yt) seboss666@Mariz_NAS:~$ pip install --upgrade pip
Collecting pip
  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)
    100% |████████████████████████████████| 1.4MB 45kB/s
Installing collected packages: pip
  Found existing installation: pip 7.1.2
    Uninstalling pip-7.1.2:
      Successfully uninstalled pip-7.1.2
Successfully installed pip-20.0.2
(yt) seboss666@Mariz_NAS:~$ pip install youtube-dl
Collecting youtube-dl
  Downloading youtube_dl-2020.3.8-py2.py3-none-any.whl (1.8 MB)
     |████████████████████████████████| 1.8 MB 3.7 MB/s
Installing collected packages: youtube-dl
Successfully installed youtube-dl-2020.3.8</pre><p></p>
<p style="text-align: justify;">Eh ben, ça semble parfait ! Il faut juste s&rsquo;assurer d&rsquo;un dernier détail. En effet, sur plusieurs sites pratiquant le HLS ou le DASH, la vidéo et l&rsquo;audio sont séparés en flux distincts, et youtube-dl a l&rsquo;habitude d&rsquo;utiliser ffmpeg pour recoller les morceaux :</p>
<p></p><pre class="crayon-plain-tag">(yt) seboss666@Mariz_NAS:~/yt$ which ffmpeg
/bin/ffmpeg</pre><p></p>
<p style="text-align: justify;">Cool <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Je ne sais par contre pas si c&rsquo;est installé de base sur le NAS, ou si ça provient d&rsquo;un autre paquet comme le serveur multimédia, installé afin de fournir du DLNA au lecteur Bluray, et qui a une option de transcodage vidéo, d&rsquo;où le recours potentiel à ffmpeg. Dans le doute, vous pourrez vérifier par vous-même, moi c&rsquo;est déjà installé et configuré je touche plus à rien.</p>
<h3 style="text-align: justify;">Le problème de l&rsquo;indexation multimédia</h3>
<p style="text-align: justify;">Eh oui, si ce n&rsquo;est pas une astuce en vrac, c&rsquo;est pas juste pour pouvoir vous faire l&rsquo;historique du NAS et une critique de ses performances, vous le voyez à la simplicité ça aurait pu tenir en un seul paragraphe ou presque. Quand on télécharge un fichier avec Download Station, ou qu&rsquo;on pousse un fichier par SMB (le partage réseau), le fichier est presque immédiatement disponible pour le lecteur Bluray. Malheureusement, pour une raison que j&rsquo;ignore, ce n&rsquo;est pas le cas pour les vidéos récupérées par youtube-dl, et de mémoire les vidéos poussées via rsync/ssh non plus.</p>
<p style="text-align: justify;">Il faut donc, dans ce cas, forcer une réindexation qui va prendre plus ou moins de temps en fonction de la taille de la bibliothèque, et qui se déclenche avec la commande suivante :</p>
<p></p><pre class="crayon-plain-tag">(yt) seboss666@Mariz_NAS:/volume1/Download$ sudo synoindex -R all</pre><p></p>
<p style="text-align: justify;">Bon après, l&rsquo;interface du lecteur Bluray LG est une honte et le rafraîchissement provoque une erreur qui demande de retourner à l&rsquo;accueil pour refaire tout le chemin vers le dossier voulu. Mais ça fonctionne <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<h3 style="text-align: justify;">Les NAS maison me manquent (et les vrais lecteurs multimedia aussi)</h3>
<p style="text-align: justify;">J&rsquo;avoue, entre la puissance famélique, l&rsquo;indexation sélective, et l&rsquo;interface pénible du bluray, je regrette vraiment OpenMediaVault, minidlna et Kodi. Disposer d&rsquo;un lecteur Bluray disposant d&rsquo;une interface aussi propre que Kodi est illusoire, ne serait-ce que parce que ce dernier ne dispose pas de toutes les technologies pour lire des bluray pourris par des DRM qui imposent de payer des licences à sept chiffres, dont on devrait pourtant avoir les clés pour des raisons d&rsquo;interopérabilité. <a href="https://www.nextinpact.com/news/78893-vlc-hadopi-na-pas-clef-pour-ouvrir-porte-blu-ray.htm" target="_blank" rel="noopener">VLC s&rsquo;y est cassé les dents</a>, notamment grâce aux <a href="https://www.nextinpact.com/news/93861-wikileaks-l-intervention-geants-blu-ray-dans-dossier-hadopi-vlc.htm" target="_blank" rel="noopener">pressions de Sony</a> qui se gave en licences, et rien n&rsquo;a bougé depuis (il faut dire que le marché stagne, voire baisse quand la VOD en streaming explose, donc sont pas pressés de filer les clés de la bagnole). Mon raspberry Pi <a href="https://blog.seboss666.info/2016/12/openelec-libreelec-osmc-mais-cest-devenu-le-bordel-ma-pauvre-dame/" target="_blank" rel="noopener">sous LibreELEC</a> me donne toujours entière satisfaction, sauf pour le plugin YouTube qui m&rsquo;a poussé à me tourner vers d&rsquo;autres solutions.</p>
<p style="text-align: justify;">Quant à <a href="https://www.openmediavault.org/" target="_blank" rel="noopener">Openmediavault</a>, le projet est toujours maintenu et toujours aussi intéressant, le problème, c&rsquo;est que le matériel pour le faire tourner sera forcément plus volumineux, consommateur de ressources, et potentiellement beaucoup plus cher. Même si en termes de consommation on sera proche avec <a href="https://blog.seboss666.info/2017/01/le-futur-de-mon-infrastructure-personnelle/" target="_blank" rel="noopener">mon microserveur</a>, atteindre un tarif de 180€ pour la base sans les disques relève du miracle, puisque c&rsquo;est juste le prix de la carte mère avec CPU soudé sans la RAM, sans le boitier, sans l&rsquo;alimentation, autant d&rsquo;éléments inclus pour le prix. Avec un CPU x86 toutefois, on aurait accès à beaucoup plus de puissance et d&rsquo;usages, ce que j&rsquo;avais fini par faire à l&rsquo;époque sur mon NAS maison, avec l&rsquo;ajout d&rsquo;une machine virtuelle en plus du reste.La problématique du CPU dans les NAS a parfaitement été analysée par David, je vous laisse <a href="https://www.inpact-hardware.com/article/1129/atom-c-ou-pentium-d-quelles-differences-sur-performances-dun-nas" target="_blank" rel="noopener">lire son dossier</a> si vous souhaitez creuser le sujet. Minidlna fonctionne quelque soit la méthode pour ajouter un fichier, puisque c&rsquo;est le noyau et uniquement lui qui prévenait de l&rsquo;arrivée d&rsquo;un fichier, peu importe qu&rsquo;il soit déposé via une application, un partage réseau, un transfert SSH.</p>
<p style="text-align: justify;">Bref, comme trop souvent avec l&rsquo;informatique, la liberté et le confort ont un prix, et pour les usages de ma mère, la liberté et la performance ne sont pas des priorités absolues, donc on va s&rsquo;en contenter. Par contre, son lecteur Bluray/home cinema donne quelques signes de fatigue, et ça coûte cher à remplacer, j&rsquo;espère que ça tiendra encore quelques années.</p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/03/youtube-dl-sur-un-nas-synology-cest-possible/feed/</wfw:commentRss>
            <slash:comments>6</slash:comments>
        </item>
        <item>
            <title>Brider les services vidéo sur le Web, une très mauvaise idée !</title>
            <link>https://blog.seboss666.info/2020/03/brider-les-services-video-sur-le-web-une-tres-mauvaise-idee/</link>
            <comments>https://blog.seboss666.info/2020/03/brider-les-services-video-sur-le-web-une-tres-mauvaise-idee/#comments</comments>
            <pubDate>Sun, 22 Mar 2020 09:30:31 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Humeur]]></category>
            <category><![CDATA[bridage]]></category>
            <category><![CDATA[conflit]]></category>
            <category><![CDATA[lobbying]]></category>
            <category><![CDATA[neutralité]]></category>
            <category><![CDATA[piratage]]></category>
            <category><![CDATA[réalité]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6205</guid>
            <description><![CDATA[J&#8217;ai été particulièrement énervé par tous les discours alarmistes sur la possible « saturation d&#8217;Internet », et des demandes débiles de nos dirigeants auprès de certains acteurs [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">J&rsquo;ai été particulièrement énervé par tous les discours alarmistes sur la possible « saturation d&rsquo;Internet », et des demandes débiles de nos dirigeants auprès de certains acteurs de se brider volontairement pour l&rsquo;éviter. D&rsquo;une part parce que c&rsquo;est faux, et d&rsquo;autre part parce que nos dirigeant profitent une fois de plus d&rsquo;un contexte exceptionnel pour mettre à mal notre outil préféré. Et ça commence à être pénible.</p>
<p style="text-align: justify;"><span id="more-6205"></span></p>
<p style="text-align: justify;">Ça n&rsquo;aura échappé à personne : impossible de dépasser le 480p sur YouTube, Netflix « n&rsquo;existe plus » en 4K, ni même voire en FullHD (les résolutions sont certainement toujours là, mais vu la gueule de la compression ça fait pas envie). Et là, dernière connerie demandée par Thierry Breton, <a href="https://www.nextinpact.com/news/108820-le-lancement-disney-repousse-au-7-avril-a-demande-gouvernement-et-dorange.htm" target="_blank" rel="noopener">le report du lancement de Disney+</a>, service de streaming vidéo à la demande par abonnement du géant de la production audiovisuelle américain, lancement qui se faire le 24 mars et qui est repoussé de deux semaines.</p>
<p style="text-align: justify;">C&rsquo;est une énorme connerie pour plusieurs raisons. Déjà, parce que comme l&rsquo;a déjà <a href="https://framablog.org/2020/03/21/linternet-pendant-le-confinement/" target="_blank" rel="noopener">très bien écrit Stéphane Bortzmeyer</a> (cet homme écrit décidément très peu d&rsquo;âneries comparé à moi, donc vous gênez pas pour le lire), la raison invoquée est le risque de saturation des réseaux, ce qui est complètement faux actuellement, même si certains symptômes pourront le laisser penser. Comme un nez qui coule ou une légère toux, en ces temps de paranoïa liée au virus, ne signifie pas qu&rsquo;on l&rsquo;a chopé, les autres maladies n&rsquo;ont pas décidé de prendre des vacances. Une sensation de « lenteur » du réseau à un niveau local pourra se produire sans que le réseau dans sa globalité soit souffrant. D&rsquo;ailleurs dire LE réseau n&rsquo;a pas de sens, Internet est un assemblage de nombreux réseaux, actuellement entre 40 000 et 50 000, là où ça peut pêcher par moments c&rsquo;est dans les points d&rsquo;interconnexion de ces réseaux. Mais d&rsquo;une part chaque réseau à plusieurs interconnexions, et d&rsquo;autre part, augmenter ces capacités est beaucoup plus facile que ne le croient nos dirigeants. Vraiment, lisez le billet de Stéphane, vous comprendrez.</p>
<p style="text-align: justify;">À la limite, si vraiment on pense que les services de vidéo à la demande font chier, ce ne sont pas juste Netflix et YouTube qu&rsquo;il faut coincer, mais tout le monde, et à tous les niveaux. Normalement dans un monde neutre, si on veut dire qu&rsquo;un type de service n&rsquo;est pas prioritaire, ce sont tous les acteurs qui doivent être touchés, pour la bonne et simple raison qu&rsquo;il ne faut pas créer de distorsion de concurrence. Hors, aucune annonce auprès de Dailymotion, de Whatsapp, TikTok, Snap, des services de replays des chaînes françaises (qui passent tous par le Web), et en gros, tous les services de communications ou de diffusion vidéo (Twitch, Mixer, etc). Tous ces acteurs sont soit non essentiels (et encore une fous de plus, quand ont voit les initiatives des profs qui partagent ou commencent à créer du contenu pour les gamins, on comprend qu&rsquo;il y a un problème à demander à brider youtube), soit peuvent brider la qualité de leur service sans que ça ne change fondamentalement la fonction. Un live snap en SD, vu l&rsquo;intérêt de base du service, ça tuera personne, et ça n&#8217;empêche pas de comprendre ce qui se dit. Idem pour les outils de visio-conférence, de toute façon vu la qualité déplorable des webcams y compris dans les laptops les plus chers du marché, je pense qu&rsquo;on peut dire qu&rsquo;il n&rsquo;est pas grave que la définition soit un peu réduite pour la vidéo. C&rsquo;est un peu plus chiant sur les partages d&rsquo;écran par contre parce que la compression tue la lisibilité des textes.</p>
<p style="text-align: justify;">Pareil, on n&rsquo;y pense pas mais avec les live Facebook qui se multiplient de la part des artistes qui ne peuvent plus se produire sur scène mais qui veulent quand même partager (comme quoi il n&rsquo;est pas seulement question d&rsquo;argent et de droit d&rsquo;auteur, n&rsquo;est-ce pas Pascal Rogard ?), vu le trafic drainé par Facebook, ça fait un peu mal au cul en théorie aussi, alors pourquoi ne pas avoir également demandé à Marky Mark de brider son service ? Enfin bref, vous avez l&rsquo;idée, pour moi si on doit brider un type de service, c&rsquo;est pour tout le monde pareil, quel que soit la taille de l&rsquo;acteur, aucune discrimination. C&rsquo;est ce qu&rsquo;on appelle la neutralité.</p>
<p style="text-align: justify;">Retarder Disney+ est aussi une énorme connerie à l&rsquo;heure du confinement des gamins chez eux. Alors que certains parents commencent déjà à affûter leur pelle, et que Disney a consciencieusement retiré ses contenus, dont tous ceux qu&rsquo;il possède grâce aux multiples rachats de ces dernières années : Marvel, Fox, etc, de tous les services concurrents, Netflix en tête (ce qui a provoqué d&rsquo;ailleurs la fin des productions conjointes au niveau des séries TV, dommage pour Punisher et Daredevil), des services concurrents, ceux qui attendent de pied ferme de pouvoir enfin redonner des doses de Reine des neiges aux gamins pendant qu&rsquo;ils essaient de bosser vont devoir ronger leur frein. Ou alors relancer le téléchargement illégal via Bittorrent, ce qui est donc l&rsquo;inverse de l&rsquo;objectif visé par ces services qui est que d&rsquo;une manière ou d&rsquo;une autre, les utilisateurs paient pour visionner le contenu, ce que ce cher Pascal souhaite.</p>
<p style="text-align: justify;">Aucun journaliste ne s&rsquo;est interrogé sur la possibilité que ce ne soit que du pur lobbying, ou du pur protectionnisme économique, voire pire du copinage à la limite du conflit d&rsquo;intérêt. Tous les services touchés par la demande de bridage sont américains et pas européens, et on sait à quel point les dirigeants européens sont embêtés de voir ces entreprises respecter les règles d&rsquo;optimisation fiscales qu&rsquo;ils ont votés pendant plus de vingt ans. Et on sait aussi que les opérateurs européens aimeraient grandement faire payer aussi les services américains pour que le trafic passe par eux, en mode « Canalsat » où les abonnés paient pour le visionnage, mais de l&rsquo;autre côté les chaînes paient aussi pour être diffusées. Le problème c&rsquo;est que ce n&rsquo;est pas le même type de réseau, mais passons. Personne ne semble aussi s&rsquo;émouvoir du passé de <a href="https://fr.wikipedia.org/wiki/Thierry_Breton" target="_blank" rel="noopener">Thierry Breton</a>, qui a passé quelques années à la tête d&rsquo;un certain France Télécom, qui s&rsquo;est depuis définitivement renommé en Orange. Je n&rsquo;ai aucun doute sur la compétence du personnage au poste qu&rsquo;il occupe actuellement et qui lui a permis de lancer ses demandes, vu le profil c&rsquo;est d&rsquo;ailleurs probablement un très bon choix. Mais ça me gène un peu quand même du coup dans ce contexte, un ancien copain chez l&rsquo;opérateur aurait pu lui souffler l&rsquo;idée que ça ne m&rsquo;étonnerait pas plus que ça.</p>
<p style="text-align: justify;">Surtout que techniquement, les opérateurs savent eux-même brider les flux, ils savent même brider des protocoles depuis très longtemps. Qui n&rsquo;a pas été surpris à une époque, chez Free en non-dégroupé, de ne plus pouvoir faire de bittorrent ou d&rsquo;e-mule du jour au lendemain ? protocoles qui se sont mis à refonctionner soit via vpn ou via des fonctions d&rsquo;obfuscation des protocoles ? Une fois de plus, c&rsquo;est économique. À l&rsquo;image du confinement physique que personne ne semble vouloir respecter en région parisienne, haut lieu du nombrilisme à la française qui commence à provoquer des sueurs dans les hôpitaux proches des régions où ces connards ont fui, pourquoi on ne « confinerait pas » les connexions internet dans leur ensemble ? Il n&rsquo;est absolument pas nécessaire actuellement que chaque foyer dispose d&rsquo;un Gigabit voire plus de bande passante, la moitié voire le tiers suffit amplement pour plusieurs personnes en parallèle. Mais si les opérateurs le font d&rsquo;eux-même, les utilisateurs vont se tourner alors massivement vers les services clients, qui ne savent déjà pas gérer les demandes habituelles des utilisateurs, et donc coûter cher.</p>
<p style="text-align: justify;">En termes d&rsquo;images c&rsquo;est génial aussi, « regardez, on peut faire plier les ricains », qui évidemment n&rsquo;ont pas envie de passer pour les méchants dans le contexte, même si c&rsquo;est entièrement faux. Après tout ils mettent le service à disposition, ils ne forcent pas les utilisateurs à s&rsquo;en servir, ni l&rsquo;appareil ou le réseau depuis lequel ils y accèdent. Le problème, c&rsquo;est que les opérateurs ne veulent pas non plus qu&rsquo;on sache à quel point ils sont mauvais en gestion de réseau, enfin surtout en gestion d&rsquo;interconnexion. Ce sont tous des services américains, et les interconnexions avec les USA passent par l&rsquo;Atlantique, ce qui coûte cher. Historiquement les opérateurs français paient le minimum syndical, et on a un historique de problèmes notamment le soir qui est long comme le bras. Moi-même pendant plus d&rsquo;un an et demi, j&rsquo;ai expérimenté ces problèmes d&rsquo;accès à des services Hors France chez Free. Quand la signature et le déploiement d&rsquo;une interconnexion directe du réseau de Free avec Google a eu lieu, le lien qui était utilisé pour tous les services US semble-t-il a eu du mieux, et là où Twitter avait pas mal de problèmes le soir, miracle tout allait mieux. Mais ça n&rsquo;allait pas toujours parfaitement, et Netflix avait régulièrement des soucis le soir, ça pixellisait pas mal, le lecteur réduisant la qualité pour tenter d&rsquo;éviter la coupure dans la lecture. Mais ça ne suffisait pas. Quand Netflix a annoncé des signatures de partenariat avec plusieurs opérateurs Français, dont Free, comme c&rsquo;est surprenant les problèmes ont disparu. C&rsquo;est con ça fait plus d&rsquo;un an j&rsquo;ai pas les graphes smokeping pour vous montrer les niveaux monstrueux de pertes de paquets que j&rsquo;avais à l&rsquo;époque.</p>
<div id="attachment_6209" style="width: 310px" class="wp-caption aligncenter"><a href="https://blog.seboss666.info/wp-content/uploads/2020/03/smokeping_neflix.png" rel="lightbox[6205]"><img class="size-medium wp-image-6209" src="https://blog.seboss666.info/wp-content/uploads/2020/03/smokeping_neflix-300x201.png" alt="" width="300" height="201" srcset="https://blog.seboss666.info/wp-content/uploads/2020/03/smokeping_neflix-300x201.png 300w, https://blog.seboss666.info/wp-content/uploads/2020/03/smokeping_neflix.png 760w" sizes="(max-width: 300px) 100vw, 300px" /></a><p class="wp-caption-text">L&rsquo;augmentation de la latence de Netflix sur ma connexion ADSL hier, alors que je suis pas chez moi. Et c&rsquo;est normal, y&rsquo;a pas de problème.</p></div>
<p style="text-align: justify;">Les opérateurs savent donc s&rsquo;adapter sans avoir besoin de demander à un encostardé de gesticuler pour demander aux américains de se brider d&rsquo;eux-même. Le problème n&rsquo;est donc pas technique, et ces gesticulations sont à la limite de la honte. Mais de la même façon qu&rsquo;on voit bien que la gestion de la crise sanitaire a toujours eu une priorité économique (pas très surprenant de la part d&rsquo;un président ancien banquier et copains des grands patrons), ces gesticulations ne sont qu&rsquo;un indice de plus qui montre bien à quel point la population est bien le dernier cadet des soucis que veulent traiter les dirigeants.</p>
<p style="text-align: justify;">En attendant, les utilisateurs, eux, vont subir ces décisions, et s&rsquo;adapter, très souvent de la pire des manières, comme c&rsquo;est le cas actuellement pour les gamins et profs qui s&rsquo;organisent autour de Youtube, whatsapp, Google apps plutôt que les ENT de leurs écoles qui ne fonctionnent déjà pas bien en temps normal, et plus du tout en cette période de crise. Et il faudra que nos dirigeants expliquent à Disney pourquoi il n&rsquo;engrange pas les utilisateurs qu&rsquo;il pensait avoir après les avoir affamé, quand ils auront repris goût au téléchargement illégal, goût qui avait pris des années pour leur faire en partie oublier, car ce sera le seul moyen de retrouver à la fois les titre et la qualité qu&rsquo;on s&rsquo;attend à avoir, y compris en temps de crise ?</p>
<p style="text-align: justify;">Bref ça me gonfle. En attendant, je vais remettre en place le NAS chez ma maman, elle aussi n&rsquo;a pas tous ses contenus et y&rsquo;a du taf. Bon dimanche, bon courage, et <strong>RESTEZ CHEZ VOUS BORDEL !!!</strong></p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/03/brider-les-services-video-sur-le-web-une-tres-mauvaise-idee/feed/</wfw:commentRss>
            <slash:comments>3</slash:comments>
        </item>
        <item>
            <title>Zstd : c&#8217;est quoi ce format de compression ?</title>
            <link>https://blog.seboss666.info/2020/03/zstd-cest-quoi-ce-format-de-compression/</link>
            <comments>https://blog.seboss666.info/2020/03/zstd-cest-quoi-ce-format-de-compression/#comments</comments>
            <pubDate>Fri, 06 Mar 2020 17:30:07 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Applications]]></category>
            <category><![CDATA[Sysadmin]]></category>
            <category><![CDATA[algorithme]]></category>
            <category><![CDATA[compression]]></category>
            <category><![CDATA[performance]]></category>
            <category><![CDATA[test]]></category>
            <category><![CDATA[zstd]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6169</guid>
            <description><![CDATA[Certains diront que je débarque, mais le fait est qu&#8217;il y a eu une récente actualité autour de ce format relativement récent de compression sans [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">Certains diront que je débarque, mais le fait est qu&rsquo;il y a eu une récente actualité autour de ce format relativement récent de compression sans perte, car il commence à être utilisé par défaut sur Arch Linux, et par conséquent, Manjaro. On s&rsquo;est déjà intéressé à la compression sous plusieurs formes <a href="https://blog.seboss666.info/2018/02/nous-vivons-dans-un-monde-compresse/" target="_blank" rel="noopener">par le passé</a>, ça fait longtemps, voyons pourquoi ce format gagne en popularité.</p>
<p style="text-align: justify;"><span id="more-6169"></span></p>
<p style="text-align: justify;">C&rsquo;est en effet suite à une note de mise à jour du 20 janvier dernier que j&rsquo;ai entendu réellement parler de zstd :</p>
<blockquote><p>Upstream notice</p>
<p>:</p>
<p>&nbsp;</p>
<p>Arch updated their default compression to zstd 18. We adopted to the same standard. More and more packages will have the zst extension from now on.</p></blockquote>
<p style="text-align: justify;">Bon, OK, un nouveau format que je ne connaissais pas. C&rsquo;est pas si choquant, ma veille n&rsquo;est pas spécialement orientée sur ces sujets, donc on va un peu s&rsquo;intéresser à ce nouveau venu qui semble avoir beaucoup de succès auprès de différentes distributions Linux comme on va le voir.</p>
<h3 style="text-align: justify;">Here comes a new challenger</h3>
<p style="text-align: justify;">Zstandard, parce que c&rsquo;est son vrai nom, est tout récent dans l&rsquo;univers des algorithmes de compression sans perte, car il n&rsquo;est développé que depuis 2015. Enfin presque, car un de ses principes fondamentaux remonte à&#8230; 1977. L&rsquo;utilisation d&rsquo;un dictionnaire n&rsquo;est donc pas nouveau pour la compression, il est même d&rsquo;ailleurs au cœur du format LZMA qui a gagné en popularité grâce à un outil que vous devez connaître, 7-zip. Autant dire qu&rsquo;on connaît bien les maths derrière ça; pas moi personnellement hein, je suis pas encore assez bon, mais y&rsquo;a des furieux qui maîtrisent bien le sujet, et si vous voulez en savoir plus, <a href="https://fr.wikipedia.org/wiki/LZ77_et_LZ78" target="_blank" rel="noopener">Wikipedia est votre ami</a>.</p>
<p style="text-align: justify;">Mais alors quel est l&rsquo;attrait de ce petit nouveau pas si nouveau d&rsquo;un point de vue conceptuel ? Pourquoi est-il soutenu par Facebook ? Eh bien, sa grande promesse n&rsquo;est pas lié à sa performance de compression, mais sa rapidité. Rapidité à la fois pour la compression mais aussi la décompression, peut-être encore plus pour la décompression d&rsquo;ailleurs, car ses performances varient peu quelque soit le niveau de compression choisi au départ. Quant au niveau de compression, il est censé être comparable à gzip, tout en étant plus rapide que celui-ci.</p>
<h3 style="text-align: justify;">Et si on testait nous-même ?</h3>
<p style="text-align: justify;">Pour vérifier ça, j&rsquo;ai fait deux petits tests afin de mesurer cette promesse. Le premier est sur un unique fichier WAV, qui ne devrait pas donner de très bons résultats sur le taux de compression, l&rsquo;autre sur un dossier composite à savoir une copie du blog, donc un mix entre fichiers textes et images, plus intéressant. Ce dossier sera « concaténé » dans un fichier tar, même si zstd est capable d&rsquo;itérer sur un dossier en mode récursif, ce que ne savent pas nécessairement faire ses cousins.</p>
<p style="text-align: justify;">Pour chaque test, j&rsquo;ai fait une copie distincte du fichier d&rsquo;origine pour limiter les impacts du cache noyau par une lecture répétée. J&rsquo;utilise time pour mesurer le temps de traitement, compression et décompression, et les paramètres par défaut pour chaque commande. Voilà, les conditions sont posées, passons aux résultats.</p>
<p style="text-align: justify;"><strong>Fichier WAV</strong></p>
<p></p><pre class="crayon-plain-tag">$ time gzip Alestorm\ -\ Sunset\ On\ The\ Golden\ Age.gz.wav

real	0m22,659s
user	0m22,001s
sys	0m0,566s
$ time xz Alestorm\ -\ Sunset\ On\ The\ Golden\ Age.xz.wav

real	1m16,755s
user	4m40,875s
sys	0m1,676s
$ time zstd Alestorm\ -\ Sunset\ On\ The\ Golden\ Age.zst.wav
Alestorm - Sunset On The Golden Age.zst.wav : 97.96%   (514968188 =&gt; 504438852 bytes, Alestorm - Sunset On The Golden Age.zst.wav.zst)

real	0m1,096s
user	0m1,169s
sys	0m0,550s</pre><p></p>
<p style="text-align: justify;">Eh bien le moins qu&rsquo;on puisse dire, c&rsquo;est que c&rsquo;est effectivement très rapide. Et quid de la taille ?</p>
<p></p><pre class="crayon-plain-tag">$&amp;nbsp;l
total 2,8G
drwxr-xr-x 2 seboss666 seboss666 4,0K 02.03.2020 17:34  ./
drwxr-xr-x 8 seboss666 seboss666 4,0K 02.03.2020 17:22  ../
-rw-r--r-- 1 seboss666 seboss666 477M 02.03.2020 17:28 'Alestorm - Sunset On The Golden Age.gz.wav.gz'
-rw-r--r-- 1 seboss666 seboss666 492M 02.03.2020 17:27 'Alestorm - Sunset On The Golden Age.wav'
-rw-r--r-- 1 seboss666 seboss666 472M 02.03.2020 17:28 'Alestorm - Sunset On The Golden Age.xz.wav.xz'
-rw-r--r-- 1 seboss666 seboss666 492M 02.03.2020 17:28 'Alestorm - Sunset On The Golden Age.zst.wav'
-rw-r--r-- 1 seboss666 seboss666 482M 02.03.2020 17:28 'Alestorm - Sunset On The Golden Age.zst.wav.zst'</pre><p></p>
<p style="text-align: justify;">On voit que le xz est largement au dessus des deux autres concurrents, mais le prix en temps de compression est très élevé. Ici, on voit que le zstd est moins performant par défaut que gzip, mais comme je l&rsquo;ai dit, ce n&rsquo;est pas nécessairement représentatif car le format de fichier ne se prête pas vraiment à l&rsquo;objectif, de ce côté les formats liés à <a href="https://blog.seboss666.info/2017/08/petites-differences-entre-wav-flac-mp3/" target="_blank" rel="noopener">la compression audio</a> ont de meilleurs résultats. Et le temps de compression est vingt fois plus court, donc facile d&rsquo;être séduit par le petit dernier de la bande.</p>
<p style="text-align: justify;">Ça, c&rsquo;est pour la compression, voyons donc les résultats de décompression :</p>
<p></p><pre class="crayon-plain-tag">$ time gzip -d Alestorm\ -\ Sunset\ On\ The\ Golden\ Age.gz.wav.gz

real	0m5,306s
user	0m4,822s
sys	0m0,445s
$ time xz -d Alestorm\ -\ Sunset\ On\ The\ Golden\ Age.xz.wav.xz

real	0m43,681s
user	0m42,892s
sys	0m0,659s

$ time zstd -d Alestorm\ -\ Sunset\ On\ The\ Golden\ Age.zst.wav.zst
Alestorm - Sunset On The Golden Age.zst.wav.zst: 514968188 bytes

real	0m0,797s
user	0m0,339s
sys	0m0,435s</pre><p></p>
<p style="text-align: justify;">Une fois encore, on voit que xz est loin derrière en termes de rapidité, alors que zstd caracole en tête.  Il semble donc tenir une grande partie de ses promesses.</p>
<p style="text-align: justify;"><strong>Dossier du blog</strong></p>
<p style="text-align: justify;">Passons à quelque chose de plus représentatif des pratiques d&rsquo;archivage. Déjà ce qui est marrant, c&rsquo;est la différence entre le dossier d&rsquo;origine, et le fichier tar utilisé pour le test :</p>
<p></p><pre class="crayon-plain-tag">$ du -shc blog*
822M	blog
799M	blog.tar</pre><p></p>
<p style="text-align: justify;">Il y a donc près de 30Mo de perdus en petits fichiers qui prennent plus de place dans le système de fichiers que leur taille réelle. Mais on est pas là pour en faire l&rsquo;analyse, revenons à nos moutons. Même motif que précédemment, copie du fichier tar pour chaque algorithme, voilà le résultat de compression :</p>
<p></p><pre class="crayon-plain-tag">$ time gzip blog.gz.tar

real	0m38,189s
user	0m36,724s
sys	0m1,170s
$ time xz blog.xz.tar

real	2m0,761s
user	7m24,399s
sys	0m2,488s
$ time zstd --rm blog.zst.tar
blog.zst.tar         : 90.08%   (836802560 =&gt; 753810165 bytes, blog.zst.tar.zst)

real	0m5,070s
user	0m4,118s
sys	0m1,317s</pre><p></p>
<p style="text-align: justify;">Euh, ok, là encore, zstd est loin devant en termes de rapidité, xz est hors concours de par sa lenteur, et ça donne quoi sur les tailles résultantes ?</p>
<p></p><pre class="crayon-plain-tag">$ l
-rw-r--r--  1 seboss666 seboss666 720M 02.03.2020 18:02  blog.gz.tar.gz
-rw-r--r--  1 seboss666 seboss666 799M 02.03.2020 17:58  blog.tar
-rw-r--r--  1 seboss666 seboss666 702M 02.03.2020 18:03  blog.xz.tar.xz
-rw-r--r--  1 seboss666 seboss666 719M 02.03.2020 18:03  blog.zst.tar.zst</pre><p></p>
<p style="text-align: justify;">Ah ! Effectivement, cette fois le résultat est proche de gzip, mais donc pour un traitement huit fois plus rapide. Et ça en compression. Et en décompression ?</p>
<p></p><pre class="crayon-plain-tag">$ time gzip -d blog.gz.tar.gz

real	0m8,573s
user	0m7,003s
sys	0m0,988s
$ time xz -d blog.xz.tar.xz

real	0m43,338s
user	0m41,663s
sys	0m1,268s
$ time zstd -d --rm blog.zst.tar.zst
blog.zst.tar.zst    : 836802560 bytes

real	0m3,048s
user	0m0,529s
sys	0m1,146s</pre><p></p>
<p style="text-align: justify;">Bon, les temps de décompression sont un peu moins impressionnants, mais tout de même, près de trois fois plus rapides. J&rsquo;arrête là les manipulations, je pense qu&rsquo;on a nos réponses.</p>
<h3 style="text-align: justify;">Pas étonnant qu&rsquo;il soit populaire</h3>
<p style="text-align: justify;">À voir les chiffres, on comprend un peu mieux le choix d&rsquo;abord d&rsquo;Ubuntu, puis d&rsquo;Arch Linux et donc de Manjaro, de basculer sur ce format plutôt qu&rsquo;un autre. Arch Linux utilisait xz jusqu&rsquo;ici, et on voit que si ça fonctionne bien d&rsquo;un point de vue stockage, et donc économie en transfert de données via Internet, le coût en termes de performances à la fois en compression et décompression ne vaut finalement pas la chandelle. Autant consommer un peu plus d&rsquo;espace disque, un peu plus de réseau, pour finalement gagner en temps de travail aussi bien à la création qu&rsquo;à l&rsquo;installation. Ça serait intéressant de comparer le coût énergétique entre le transfert additionnel sur le réseau, et les calculs nécessaires pour générer les archives, mais c&rsquo;est un peu compliqué et hors scope ici.</p>
<p style="text-align: justify;">Reste que le format est soutenu par Facebook, et naturellement ça fait un peu peur, mais vu la finalité, il y a peu à craindre quant à sa pérennité, contrairement au support PHP d&rsquo;HHVM qui a pris fin il y a un an. Si l&rsquo;utilitaire zstd n&rsquo;est pas dispo nativement sur votre système, vous pouvez vous tourner <a href="https://github.com/facebook/zstd" target="_blank" rel="noopener">vers le dépôt Github</a> qui regorge d&rsquo;informations à son sujet, avec d&rsquo;autres chiffres de performances, effectués sur une machine hors de portée du commun des mortels.</p>
<p style="text-align: justify;">En tout cas, je pense que c&rsquo;est une bonne décision d&rsquo;y être passé sur Arch Linux, et pour avoir souffert avec quelques créations de paquets AUR qui prennent beaucoup de temps même avec xz en multiithread, j&rsquo;espère que la plupart des recettes basculeront sur ce format rapidement.</p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/03/zstd-cest-quoi-ce-format-de-compression/feed/</wfw:commentRss>
            <slash:comments>6</slash:comments>
        </item>
        <item>
            <title>Debian, VMware, Terraform sont dans un bateau&#8230;</title>
            <link>https://blog.seboss666.info/2020/03/debian-vmware-terraform-sont-dans-un-bateau/</link>
            <comments>https://blog.seboss666.info/2020/03/debian-vmware-terraform-sont-dans-un-bateau/#comments</comments>
            <pubDate>Mon, 02 Mar 2020 17:30:50 +0000</pubDate>
            <dc:creator><![CDATA[Seboss666]]></dc:creator>
            <category><![CDATA[Astuces]]></category>
            <category><![CDATA[Sysadmin]]></category>
            <category><![CDATA[debian]]></category>
            <category><![CDATA[infrastructure as code]]></category>
            <category><![CDATA[mensonge]]></category>
            <category><![CDATA[personnalisation]]></category>
            <category><![CDATA[private cloud]]></category>
            <category><![CDATA[template]]></category>
            <category><![CDATA[terraform]]></category>
            <category><![CDATA[Ubuntu]]></category>
            <category><![CDATA[vmware]]></category>

            <guid isPermaLink="false">https://blog.seboss666.info/?p=6179</guid>
            <description><![CDATA[J&#8217;ai eu récemment à déployer une vingtaine de machines sur un cluster Private Cloud Vmware fourni par OVH. J&#8217;ai pour ça testé le code qu&#8217;un [...]]]></description>
            <content:encoded><![CDATA[<p style="text-align: justify;">J&rsquo;ai eu récemment à déployer une vingtaine de machines sur un cluster Private Cloud Vmware fourni par OVH. J&rsquo;ai pour ça testé le code qu&rsquo;un de leurs ingénieurs a <a href="https://www.ovh.com/blog/private_cloud_and_hashicorp_terraform_part1/" target="_blank" rel="noopener">partagé sur le blog d&rsquo;OVH</a>, mais ça ne s&rsquo;est pas déroulé comme prévu. Et la solution a pris du temps, et c&rsquo;est dégueulasse&#8230;</p>
<p style="text-align: justify;"><span id="more-6179"></span></p>
<h3 style="text-align: justify;">Un vrai parcours du combattant</h3>
<p style="text-align: justify;">Mes machines doivent être déployées en Debian 9 (on pleure pas trop vite s&rsquo;il vous plait), pas le choix parce qu&rsquo;il nous manque encore des prérequis internes pour la bonne gestion de Debian 10 chez nous. Qui dit déploiement par terraform dit d&rsquo;abord création d&rsquo;un template Debian 9.</p>
<p style="text-align: justify;"><em>Au passage je vous recommande vivement de vous intéresser à <a href="https://www.terraform.io/" target="_blank" rel="noopener">Terraform</a> si vous comptez bosser de l&rsquo;infrastructure « cloud », y&rsquo;a une quantité hallucinante de providers et c&rsquo;est vraiment un outil sympa à utiliser, qui s&rsquo;intègre assez facilement dans un flux de déploiement automatisé de bout en bout.</em></p>
<p style="text-align: justify;">Au début mon manager m&rsquo;a filé un dépôt avec une configuration Packer, autre outil développé par Hashicorp, qu&rsquo;il avait utilisé pour du CentOS 7. Après avoir passé une après-midi à essayer de comprendre comment fonctionne le preseed de l&rsquo;installateur Debian, et échoué à le faire utiliser avec Packer (au passage, si on compare preseed à kickstart, preseed c&rsquo;est de la merde en barre), j&rsquo;ai décidé de créer mon template à la main à partir de l&rsquo;iso officielle 64bit, avec installation d&rsquo;open-vm-tools, comme recommandé <a href="https://github.com/vmware/open-vm-tools#will-there-be-continued-support-for-vmware-tools-and-osp" target="_blank" rel="noopener">par la documentation de VMware</a>.</p>
<p style="text-align: justify;">Puis, une fois le template prêt et rangé dans son dossier, je prépare le code rapidement et procède à une première tentative de création d&rsquo;une machine virtuelle à partir du template. Comme on l&rsquo;imagine, puisqu&rsquo;on en parle aujourd&rsquo;hui, ça ne s&rsquo;est pas vraiment déroulé comme je l&rsquo;attendais :</p>
<p></p><pre class="crayon-plain-tag">Error: error sending customization spec: Customization of the guest operating system 'debian9_64Guest' is not supported in this configuration. Microsoft Vista (TM) and Linux guests with Logical Volume Manager are supported only for recent ESX host and VMware Tools versions. Refer to vCenter documentation for supported configurations.</pre><p></p>
<p style="text-align: justify;">Et il supprime la machine virtuelle. Arf. Il se trouve que j&rsquo;ai le même message après une tentative manuelle depuis l&rsquo;interface web en cochant l&rsquo;option qui correspond à la personnalisation de l&rsquo;OS. Damned. Déjà, le message est sympathique car il parle de Vista, cancer nécessaire de Microsoft qui aura quand même permis à terme d&rsquo;avoir le génial Windows 7 (qui vient de prendre sa retraite), mais aussi et plus surprenant, de LVM. Surprenant car je sais que VMware supporte parfaitement LVM dans ses différents outils, pour avoir bouffé du VMware Converter sur un projet précédent. Sans plus de conviction, je perds donc du temps à recréer un second template partitionné sans LVM cette fois; même punition, même message, l&rsquo;erreur est donc générique et débile.</p>
<p style="text-align: justify;">Je me tourne alors vers le support OVH, en leur donnant tous les détails de mes manipulations et tests. Leur réponse, en substance :</p>
<blockquote><p>On reproduit, mais on comprend pas non plus</p></blockquote>
<p style="text-align: justify;">Et en effet, en cherchant partout sur les docs VMware ça devrait pas bloquer. Mais des réponses comme celle-ci ne m&rsquo;avancent pas à grand chose.</p>
<p style="text-align: justify;">Il fallait que j&rsquo;avance donc j&rsquo;ai déployé mes machines de pré-production à la main, fourni les accès à l&rsquo;agence de développement et j&rsquo;ai un peu laissé de côté, pendant que je relançais à intervalle régulier le support pour avoir des nouvelles.</p>
<p style="text-align: justify;">Réponse quelques dizaines de jours et partage de traces terraform &amp; co plus tard : il faut modifier le type de machine virtuelle qu&rsquo;on crée à Ubuntu, même si on installe Debian dedans. Mentir à l&rsquo;hyperviseur, bravo, il est vrai que je l&rsquo;avais vu passer dans mes recherches Google, mais ça ne me plaît pas vraiment et donc, j&rsquo;ai pas testé. Mais maintenant et au point où on en est, pourquoi pas. Le support me dit que je peux tester avec leur template, mais ça échoue sur la même erreur, bravo.</p>
<p style="text-align: justify;">J&rsquo;entreprends donc de refaire un nouveau template, en mentant, avec LVM, et je réinstalle les mêmes packages. Nouvelle tentative de déploiement : ça semble fonctionner, je n&rsquo;ai plus le message d&rsquo;erreur de personnalisation, mais pas de bol, ça échoue une étape plus tard. Ce coup-ci cependant, Terraform me laisse la machine pour débug, et affiche ce message :</p>
<p></p><pre class="crayon-plain-tag">An error occurred while customizing VM client-test1-preprod1. For details reference the log file &lt;no_log&gt; in the guest OS.</pre><p></p>
<p style="text-align: justify;">j&rsquo;ai vraiment pas de bol, il devrait y avoir un fichier de log, il n&rsquo;existe pas. Je découvre malgré tout un truc bizarre : la machine virtuelle est bien démarrée, mais la carte réseau n&rsquo;est pas connectée, alors que la case est bien cochée dans le template. Je refouille sur Google, et là, je tombe sur un message récent, qui n&rsquo;existait pas au début de mon problème, qui parle d&rsquo;<a href="https://github.com/terraform-providers/terraform-provider-vsphere/issues/388" target="_blank" rel="noopener">un souci avec l&rsquo;unit systemd d&rsquo;open-vm-tools</a>.</p>
<p style="text-align: justify;">Je retourne donc dans le template (qu&rsquo;on convertit en machine virtuelle pour pouvoir en modifier le contenu), et plutôt que de modifier le fichier original qui pourrait être écrasé par une éventuelle mise à jour, j&rsquo;exploite les capacités d&rsquo;override de systemd dont vient de parler Cascador <a href="https://www.blog-libre.org/2020/03/01/demarrer-un-service-selon-une-condition-avec-systemd/" target="_blank" rel="noopener">sur le Blog Libre</a> :</p>
<p></p><pre class="crayon-plain-tag">$ export EDITOR=vim
$ sudo systemctl edit open-vm-tools.service
#Contenu de l'override
[Unit]
After=dbus.service</pre><p></p>
<p style="text-align: justify;">On repasse en template, et on relance terraform, et là, 1m30s après :</p>
<p></p><pre class="crayon-plain-tag">Apply complete! Resources: 1 added, 0 changed, 0 destroyed.</pre><p></p>
<p style="text-align: justify;">Et tout ça, ça a pratiquement pris encore une après-midi qui n&rsquo;a pas pu être consacrée à d&rsquo;autres sujets (dont une investigation sur une corruption fréquente de base RPM sur du Redhat 7 qui semble causée par une configuration qu&rsquo;on déploie chez tous les clients&#8230;).</p>
<p style="text-align: justify;">Comme d&rsquo;habitude, je cherche et constate que personne n&rsquo;a remonté le problème chez Debian. J&rsquo;ai failli le faire, avant de comparer au paquet Debian 10, et je me suis ravisé, car de toute façon, Debian 9 n&rsquo;a plus qu&rsquo;un an et demi devant lui, et le nombre de projets qu&rsquo;on sera amené à mener dans un environnement similaire fait qu&rsquo;on pourra supporter cette petite bidouille. J&rsquo;ai tout de même partagé au support OVH qui pourra, au besoin, transmettre aux futurs infortunés qui seraient contraints au même déploiement sans avoir lu cet article.</p>
<h3 style="text-align: justify;">VMware, c&rsquo;est de la merde ?</h3>
<p style="text-align: justify;">En vrai pas tant que ça, mais effectivement sur ce point, Debian et Ubuntu partageant une base commune, je ne comprend pas pourquoi il ne « supporterait » pas le fait de déclarer correctement qu&rsquo;on utilise une Debian, surtout qu&rsquo;il bosse parfaitement derrière : hostname, fichier interfaces, tout est là, proprement configuré. On rage d&rsquo;autant plus du coup d&rsquo;avoir perdus plusieurs après-midi et patienté plusieurs jours sur un truc aussi bête.</p>
<p style="text-align: justify;">Et dans le dépôt d&rsquo;open-vm-tools, il n&rsquo;y a pas de fichier d&rsquo;unit systemd, je pense donc que c&rsquo;est une faiblesse introduite par le mainteneur du paquet pour Debian. D&rsquo;ailleurs, quand on voit le nombre de différences entre celui pour Debian 9 et celui pour Debian 10, c&rsquo;est qu&rsquo;il a dû être plus longuement testé et donc les problèmes mieux identifiés. Donc là non plus on ne peut pas entièrement blâmer les développeurs, même si un petit coup de pouce documentaire n&rsquo;aurait pas été de trop de la part de l&rsquo;éditeur. On salue par contre sans problème le choix des licences rattachées au code publié, pas évident puisque VMware est un éditeur de logiciel majoritairement propriétaire à la base.</p>
<p style="text-align: justify;">De mon côté, j&rsquo;aimerai tester Terraform sur un autre hyperviseur, en l&rsquo;occurrence Proxmox puisque je l&rsquo;utilise chez moi et sur le serveur physique qui héberge entre autre ce blog, mais il n&rsquo;y a pas de provider officiel, juste <a href="https://github.com/Telmate/terraform-provider-proxmox" target="_blank" rel="noopener">un provider indépendant</a> qui semble du coup avoir ses propres contraintes qu&rsquo;il faudra apprivoiser. Par contre vu le rythme actuel de publication, ça sera dans deux ans hein ^^&rsquo;</p>
]]></content:encoded>
            <wfw:commentRss>https://blog.seboss666.info/2020/03/debian-vmware-terraform-sont-dans-un-bateau/feed/</wfw:commentRss>
            <slash:comments>9</slash:comments>
        </item>
    </channel>
</rss>